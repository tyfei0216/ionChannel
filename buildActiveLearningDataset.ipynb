{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test train mle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tyfei/anaconda3/envs/esm3/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import json\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import trainUtils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = \"/data2/tyfei/trainresults/ionChannels/ESMC/final3/\"\n",
    "path = \"/home/tyfei/ionChannel/ckptsesm3/YangsConfig\"\n",
    "with open(os.path.join(path, \"config.json\"), \"r\") as f:\n",
    "    configs = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"params\" in configs[\"model\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initized model for base_learning stage\n"
     ]
    }
   ],
   "source": [
    "pretrain_model = trainUtils.loadPretrainModel(configs)\n",
    "model = trainUtils.buildModel(configs, pretrain_model)\n",
    "# ds = trainUtils.loadDataset(configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "additional_label_weights False\n",
      "pos_weights False\n",
      "clf.l1.weight True\n",
      "clf.l1.bias True\n",
      "clf.l2.weight True\n",
      "clf.l2.bias True\n",
      "clf.l3.weight True\n",
      "clf.l3.bias True\n",
      "clf.ln1.weight True\n",
      "clf.ln1.bias True\n",
      "clf.ln2.weight True\n",
      "clf.ln2.bias True\n",
      "dis.l1.weight True\n",
      "dis.l1.bias True\n",
      "dis.l2.weight True\n",
      "dis.l2.bias True\n",
      "dis.l3.weight True\n",
      "dis.l3.bias True\n",
      "dis.ln1.weight True\n",
      "dis.ln1.bias True\n",
      "dis.ln2.weight True\n",
      "dis.ln2.bias True\n",
      "additional_clf.l1.weight True\n",
      "additional_clf.l1.bias True\n",
      "additional_clf.l2.weight True\n",
      "additional_clf.l2.bias True\n",
      "additional_clf.l3.weight True\n",
      "additional_clf.l3.bias True\n",
      "additional_clf.ln1.weight True\n",
      "additional_clf.ln1.bias True\n",
      "additional_clf.ln2.weight True\n",
      "additional_clf.ln2.bias True\n",
      "esm_model.encoder.sequence_embed.weight False\n",
      "esm_model.encoder.plddt_projection.weight False\n",
      "esm_model.encoder.plddt_projection.bias False\n",
      "esm_model.encoder.structure_per_res_plddt_projection.weight False\n",
      "esm_model.encoder.structure_per_res_plddt_projection.bias False\n",
      "esm_model.encoder.structure_tokens_embed.weight False\n",
      "esm_model.encoder.ss8_embed.weight False\n",
      "esm_model.encoder.sasa_embed.weight False\n",
      "esm_model.encoder.function_embed.0.weight False\n",
      "esm_model.encoder.function_embed.1.weight False\n",
      "esm_model.encoder.function_embed.2.weight False\n",
      "esm_model.encoder.function_embed.3.weight False\n",
      "esm_model.encoder.function_embed.4.weight False\n",
      "esm_model.encoder.function_embed.5.weight False\n",
      "esm_model.encoder.function_embed.6.weight False\n",
      "esm_model.encoder.function_embed.7.weight False\n",
      "esm_model.encoder.residue_embed.weight False\n",
      "esm_model.transformer.blocks.0.attn.layernorm_qkv.0.weight False\n",
      "esm_model.transformer.blocks.0.attn.layernorm_qkv.0.bias False\n",
      "esm_model.transformer.blocks.0.attn.layernorm_qkv.1.weight False\n",
      "esm_model.transformer.blocks.0.attn.out_proj.weight False\n",
      "esm_model.transformer.blocks.0.attn.q_ln.weight False\n",
      "esm_model.transformer.blocks.0.attn.k_ln.weight False\n",
      "esm_model.transformer.blocks.0.geom_attn.distance_scale_per_head False\n",
      "esm_model.transformer.blocks.0.geom_attn.rotation_scale_per_head False\n",
      "esm_model.transformer.blocks.0.geom_attn.s_norm.weight False\n",
      "esm_model.transformer.blocks.0.geom_attn.proj.weight False\n",
      "esm_model.transformer.blocks.0.geom_attn.out_proj.weight False\n",
      "esm_model.transformer.blocks.0.ffn.0.weight False\n",
      "esm_model.transformer.blocks.0.ffn.0.bias False\n",
      "esm_model.transformer.blocks.0.ffn.1.weight False\n",
      "esm_model.transformer.blocks.0.ffn.3.weight False\n",
      "esm_model.transformer.blocks.1.attn.layernorm_qkv.0.weight False\n",
      "esm_model.transformer.blocks.1.attn.layernorm_qkv.0.bias False\n",
      "esm_model.transformer.blocks.1.attn.layernorm_qkv.1.weight False\n",
      "esm_model.transformer.blocks.1.attn.out_proj.weight False\n",
      "esm_model.transformer.blocks.1.attn.q_ln.weight False\n",
      "esm_model.transformer.blocks.1.attn.k_ln.weight False\n",
      "esm_model.transformer.blocks.1.ffn.0.weight False\n",
      "esm_model.transformer.blocks.1.ffn.0.bias False\n",
      "esm_model.transformer.blocks.1.ffn.1.weight False\n",
      "esm_model.transformer.blocks.1.ffn.3.weight False\n",
      "esm_model.transformer.blocks.2.attn.layernorm_qkv.0.weight False\n",
      "esm_model.transformer.blocks.2.attn.layernorm_qkv.0.bias False\n",
      "esm_model.transformer.blocks.2.attn.layernorm_qkv.1.weight False\n",
      "esm_model.transformer.blocks.2.attn.out_proj.weight False\n",
      "esm_model.transformer.blocks.2.attn.q_ln.weight False\n",
      "esm_model.transformer.blocks.2.attn.k_ln.weight False\n",
      "esm_model.transformer.blocks.2.ffn.0.weight False\n",
      "esm_model.transformer.blocks.2.ffn.0.bias False\n",
      "esm_model.transformer.blocks.2.ffn.1.weight False\n",
      "esm_model.transformer.blocks.2.ffn.3.weight False\n",
      "esm_model.transformer.blocks.3.attn.layernorm_qkv.0.weight False\n",
      "esm_model.transformer.blocks.3.attn.layernorm_qkv.0.bias False\n",
      "esm_model.transformer.blocks.3.attn.layernorm_qkv.1.weight False\n",
      "esm_model.transformer.blocks.3.attn.out_proj.weight False\n",
      "esm_model.transformer.blocks.3.attn.q_ln.weight False\n",
      "esm_model.transformer.blocks.3.attn.k_ln.weight False\n",
      "esm_model.transformer.blocks.3.ffn.0.weight False\n",
      "esm_model.transformer.blocks.3.ffn.0.bias False\n",
      "esm_model.transformer.blocks.3.ffn.1.weight False\n",
      "esm_model.transformer.blocks.3.ffn.3.weight False\n",
      "esm_model.transformer.blocks.4.attn.layernorm_qkv.0.weight False\n",
      "esm_model.transformer.blocks.4.attn.layernorm_qkv.0.bias False\n",
      "esm_model.transformer.blocks.4.attn.layernorm_qkv.1.weight False\n",
      "esm_model.transformer.blocks.4.attn.out_proj.weight False\n",
      "esm_model.transformer.blocks.4.attn.q_ln.weight False\n",
      "esm_model.transformer.blocks.4.attn.k_ln.weight False\n",
      "esm_model.transformer.blocks.4.ffn.0.weight False\n",
      "esm_model.transformer.blocks.4.ffn.0.bias False\n",
      "esm_model.transformer.blocks.4.ffn.1.weight False\n",
      "esm_model.transformer.blocks.4.ffn.3.weight False\n",
      "esm_model.transformer.blocks.5.attn.layernorm_qkv.0.weight False\n",
      "esm_model.transformer.blocks.5.attn.layernorm_qkv.0.bias False\n",
      "esm_model.transformer.blocks.5.attn.layernorm_qkv.1.weight False\n",
      "esm_model.transformer.blocks.5.attn.out_proj.weight False\n",
      "esm_model.transformer.blocks.5.attn.q_ln.weight False\n",
      "esm_model.transformer.blocks.5.attn.k_ln.weight False\n",
      "esm_model.transformer.blocks.5.ffn.0.weight False\n",
      "esm_model.transformer.blocks.5.ffn.0.bias False\n",
      "esm_model.transformer.blocks.5.ffn.1.weight False\n",
      "esm_model.transformer.blocks.5.ffn.3.weight False\n",
      "esm_model.transformer.blocks.6.attn.layernorm_qkv.0.weight False\n",
      "esm_model.transformer.blocks.6.attn.layernorm_qkv.0.bias False\n",
      "esm_model.transformer.blocks.6.attn.layernorm_qkv.1.weight False\n",
      "esm_model.transformer.blocks.6.attn.out_proj.weight False\n",
      "esm_model.transformer.blocks.6.attn.q_ln.weight False\n",
      "esm_model.transformer.blocks.6.attn.k_ln.weight False\n",
      "esm_model.transformer.blocks.6.ffn.0.weight False\n",
      "esm_model.transformer.blocks.6.ffn.0.bias False\n",
      "esm_model.transformer.blocks.6.ffn.1.weight False\n",
      "esm_model.transformer.blocks.6.ffn.3.weight False\n",
      "esm_model.transformer.blocks.7.attn.layernorm_qkv.0.weight False\n",
      "esm_model.transformer.blocks.7.attn.layernorm_qkv.0.bias False\n",
      "esm_model.transformer.blocks.7.attn.layernorm_qkv.1.weight False\n",
      "esm_model.transformer.blocks.7.attn.out_proj.weight False\n",
      "esm_model.transformer.blocks.7.attn.q_ln.weight False\n",
      "esm_model.transformer.blocks.7.attn.k_ln.weight False\n",
      "esm_model.transformer.blocks.7.ffn.0.weight False\n",
      "esm_model.transformer.blocks.7.ffn.0.bias False\n",
      "esm_model.transformer.blocks.7.ffn.1.weight False\n",
      "esm_model.transformer.blocks.7.ffn.3.weight False\n",
      "esm_model.transformer.blocks.8.attn.layernorm_qkv.0.weight False\n",
      "esm_model.transformer.blocks.8.attn.layernorm_qkv.0.bias False\n",
      "esm_model.transformer.blocks.8.attn.layernorm_qkv.1.weight False\n",
      "esm_model.transformer.blocks.8.attn.out_proj.weight False\n",
      "esm_model.transformer.blocks.8.attn.q_ln.weight False\n",
      "esm_model.transformer.blocks.8.attn.k_ln.weight False\n",
      "esm_model.transformer.blocks.8.ffn.0.weight False\n",
      "esm_model.transformer.blocks.8.ffn.0.bias False\n",
      "esm_model.transformer.blocks.8.ffn.1.weight False\n",
      "esm_model.transformer.blocks.8.ffn.3.weight False\n",
      "esm_model.transformer.blocks.9.attn.layernorm_qkv.0.weight False\n",
      "esm_model.transformer.blocks.9.attn.layernorm_qkv.0.bias False\n",
      "esm_model.transformer.blocks.9.attn.layernorm_qkv.1.weight False\n",
      "esm_model.transformer.blocks.9.attn.out_proj.weight False\n",
      "esm_model.transformer.blocks.9.attn.q_ln.weight False\n",
      "esm_model.transformer.blocks.9.attn.k_ln.weight False\n",
      "esm_model.transformer.blocks.9.ffn.0.weight False\n",
      "esm_model.transformer.blocks.9.ffn.0.bias False\n",
      "esm_model.transformer.blocks.9.ffn.1.weight False\n",
      "esm_model.transformer.blocks.9.ffn.3.weight False\n",
      "esm_model.transformer.blocks.10.attn.layernorm_qkv.0.weight False\n",
      "esm_model.transformer.blocks.10.attn.layernorm_qkv.0.bias False\n",
      "esm_model.transformer.blocks.10.attn.layernorm_qkv.1.weight False\n",
      "esm_model.transformer.blocks.10.attn.out_proj.weight False\n",
      "esm_model.transformer.blocks.10.attn.q_ln.weight False\n",
      "esm_model.transformer.blocks.10.attn.k_ln.weight False\n",
      "esm_model.transformer.blocks.10.ffn.0.weight False\n",
      "esm_model.transformer.blocks.10.ffn.0.bias False\n",
      "esm_model.transformer.blocks.10.ffn.1.weight False\n",
      "esm_model.transformer.blocks.10.ffn.3.weight False\n",
      "esm_model.transformer.blocks.11.attn.layernorm_qkv.0.weight False\n",
      "esm_model.transformer.blocks.11.attn.layernorm_qkv.0.bias False\n",
      "esm_model.transformer.blocks.11.attn.layernorm_qkv.1.weight False\n",
      "esm_model.transformer.blocks.11.attn.out_proj.weight False\n",
      "esm_model.transformer.blocks.11.attn.q_ln.weight False\n",
      "esm_model.transformer.blocks.11.attn.k_ln.weight False\n",
      "esm_model.transformer.blocks.11.ffn.0.weight False\n",
      "esm_model.transformer.blocks.11.ffn.0.bias False\n",
      "esm_model.transformer.blocks.11.ffn.1.weight False\n",
      "esm_model.transformer.blocks.11.ffn.3.weight False\n",
      "esm_model.transformer.blocks.12.attn.layernorm_qkv.0.weight False\n",
      "esm_model.transformer.blocks.12.attn.layernorm_qkv.0.bias False\n",
      "esm_model.transformer.blocks.12.attn.layernorm_qkv.1.weight False\n",
      "esm_model.transformer.blocks.12.attn.out_proj.weight False\n",
      "esm_model.transformer.blocks.12.attn.q_ln.weight False\n",
      "esm_model.transformer.blocks.12.attn.k_ln.weight False\n",
      "esm_model.transformer.blocks.12.ffn.0.weight False\n",
      "esm_model.transformer.blocks.12.ffn.0.bias False\n",
      "esm_model.transformer.blocks.12.ffn.1.weight False\n",
      "esm_model.transformer.blocks.12.ffn.3.weight False\n",
      "esm_model.transformer.blocks.13.attn.layernorm_qkv.0.weight False\n",
      "esm_model.transformer.blocks.13.attn.layernorm_qkv.0.bias False\n",
      "esm_model.transformer.blocks.13.attn.layernorm_qkv.1.weight False\n",
      "esm_model.transformer.blocks.13.attn.out_proj.weight False\n",
      "esm_model.transformer.blocks.13.attn.q_ln.weight False\n",
      "esm_model.transformer.blocks.13.attn.k_ln.weight False\n",
      "esm_model.transformer.blocks.13.ffn.0.weight False\n",
      "esm_model.transformer.blocks.13.ffn.0.bias False\n",
      "esm_model.transformer.blocks.13.ffn.1.weight False\n",
      "esm_model.transformer.blocks.13.ffn.3.weight False\n",
      "esm_model.transformer.blocks.14.attn.layernorm_qkv.0.weight False\n",
      "esm_model.transformer.blocks.14.attn.layernorm_qkv.0.bias False\n",
      "esm_model.transformer.blocks.14.attn.layernorm_qkv.1.weight False\n",
      "esm_model.transformer.blocks.14.attn.out_proj.weight False\n",
      "esm_model.transformer.blocks.14.attn.q_ln.weight False\n",
      "esm_model.transformer.blocks.14.attn.k_ln.weight False\n",
      "esm_model.transformer.blocks.14.ffn.0.weight False\n",
      "esm_model.transformer.blocks.14.ffn.0.bias False\n",
      "esm_model.transformer.blocks.14.ffn.1.weight False\n",
      "esm_model.transformer.blocks.14.ffn.3.weight False\n",
      "esm_model.transformer.blocks.15.attn.layernorm_qkv.0.weight False\n",
      "esm_model.transformer.blocks.15.attn.layernorm_qkv.0.bias False\n",
      "esm_model.transformer.blocks.15.attn.layernorm_qkv.1.weight False\n",
      "esm_model.transformer.blocks.15.attn.out_proj.weight False\n",
      "esm_model.transformer.blocks.15.attn.q_ln.weight False\n",
      "esm_model.transformer.blocks.15.attn.k_ln.weight False\n",
      "esm_model.transformer.blocks.15.ffn.0.weight False\n",
      "esm_model.transformer.blocks.15.ffn.0.bias False\n",
      "esm_model.transformer.blocks.15.ffn.1.weight False\n",
      "esm_model.transformer.blocks.15.ffn.3.weight False\n",
      "esm_model.transformer.blocks.16.attn.layernorm_qkv.0.weight False\n",
      "esm_model.transformer.blocks.16.attn.layernorm_qkv.0.bias False\n",
      "esm_model.transformer.blocks.16.attn.layernorm_qkv.1.weight False\n",
      "esm_model.transformer.blocks.16.attn.out_proj.weight False\n",
      "esm_model.transformer.blocks.16.attn.q_ln.weight False\n",
      "esm_model.transformer.blocks.16.attn.k_ln.weight False\n",
      "esm_model.transformer.blocks.16.ffn.0.weight False\n",
      "esm_model.transformer.blocks.16.ffn.0.bias False\n",
      "esm_model.transformer.blocks.16.ffn.1.weight False\n",
      "esm_model.transformer.blocks.16.ffn.3.weight False\n",
      "esm_model.transformer.blocks.17.attn.layernorm_qkv.0.weight False\n",
      "esm_model.transformer.blocks.17.attn.layernorm_qkv.0.bias False\n",
      "esm_model.transformer.blocks.17.attn.layernorm_qkv.1.weight False\n",
      "esm_model.transformer.blocks.17.attn.out_proj.weight False\n",
      "esm_model.transformer.blocks.17.attn.q_ln.weight False\n",
      "esm_model.transformer.blocks.17.attn.k_ln.weight False\n",
      "esm_model.transformer.blocks.17.ffn.0.weight False\n",
      "esm_model.transformer.blocks.17.ffn.0.bias False\n",
      "esm_model.transformer.blocks.17.ffn.1.weight False\n",
      "esm_model.transformer.blocks.17.ffn.3.weight False\n",
      "esm_model.transformer.blocks.18.attn.layernorm_qkv.0.weight False\n",
      "esm_model.transformer.blocks.18.attn.layernorm_qkv.0.bias False\n",
      "esm_model.transformer.blocks.18.attn.layernorm_qkv.1.weight False\n",
      "esm_model.transformer.blocks.18.attn.out_proj.weight False\n",
      "esm_model.transformer.blocks.18.attn.q_ln.weight False\n",
      "esm_model.transformer.blocks.18.attn.k_ln.weight False\n",
      "esm_model.transformer.blocks.18.ffn.0.weight False\n",
      "esm_model.transformer.blocks.18.ffn.0.bias False\n",
      "esm_model.transformer.blocks.18.ffn.1.weight False\n",
      "esm_model.transformer.blocks.18.ffn.3.weight False\n",
      "esm_model.transformer.blocks.19.attn.layernorm_qkv.0.weight False\n",
      "esm_model.transformer.blocks.19.attn.layernorm_qkv.0.bias False\n",
      "esm_model.transformer.blocks.19.attn.layernorm_qkv.1.weight False\n",
      "esm_model.transformer.blocks.19.attn.out_proj.weight False\n",
      "esm_model.transformer.blocks.19.attn.q_ln.weight False\n",
      "esm_model.transformer.blocks.19.attn.k_ln.weight False\n",
      "esm_model.transformer.blocks.19.ffn.0.weight False\n",
      "esm_model.transformer.blocks.19.ffn.0.bias False\n",
      "esm_model.transformer.blocks.19.ffn.1.weight False\n",
      "esm_model.transformer.blocks.19.ffn.3.weight False\n",
      "esm_model.transformer.blocks.20.attn.layernorm_qkv.0.weight False\n",
      "esm_model.transformer.blocks.20.attn.layernorm_qkv.0.bias False\n",
      "esm_model.transformer.blocks.20.attn.layernorm_qkv.1.weight False\n",
      "esm_model.transformer.blocks.20.attn.out_proj.weight False\n",
      "esm_model.transformer.blocks.20.attn.q_ln.weight False\n",
      "esm_model.transformer.blocks.20.attn.k_ln.weight False\n",
      "esm_model.transformer.blocks.20.ffn.0.weight False\n",
      "esm_model.transformer.blocks.20.ffn.0.bias False\n",
      "esm_model.transformer.blocks.20.ffn.1.weight False\n",
      "esm_model.transformer.blocks.20.ffn.3.weight False\n",
      "esm_model.transformer.blocks.21.attn.layernorm_qkv.0.weight False\n",
      "esm_model.transformer.blocks.21.attn.layernorm_qkv.0.bias False\n",
      "esm_model.transformer.blocks.21.attn.layernorm_qkv.1.weight False\n",
      "esm_model.transformer.blocks.21.attn.out_proj.weight False\n",
      "esm_model.transformer.blocks.21.attn.q_ln.weight False\n",
      "esm_model.transformer.blocks.21.attn.k_ln.weight False\n",
      "esm_model.transformer.blocks.21.ffn.0.weight False\n",
      "esm_model.transformer.blocks.21.ffn.0.bias False\n",
      "esm_model.transformer.blocks.21.ffn.1.weight False\n",
      "esm_model.transformer.blocks.21.ffn.3.weight False\n",
      "esm_model.transformer.blocks.22.attn.layernorm_qkv.0.weight False\n",
      "esm_model.transformer.blocks.22.attn.layernorm_qkv.0.bias False\n",
      "esm_model.transformer.blocks.22.attn.layernorm_qkv.1.weight False\n",
      "esm_model.transformer.blocks.22.attn.out_proj.weight False\n",
      "esm_model.transformer.blocks.22.attn.q_ln.weight False\n",
      "esm_model.transformer.blocks.22.attn.k_ln.weight False\n",
      "esm_model.transformer.blocks.22.ffn.0.weight False\n",
      "esm_model.transformer.blocks.22.ffn.0.bias False\n",
      "esm_model.transformer.blocks.22.ffn.1.weight False\n",
      "esm_model.transformer.blocks.22.ffn.3.weight False\n",
      "esm_model.transformer.blocks.23.attn.layernorm_qkv.0.weight False\n",
      "esm_model.transformer.blocks.23.attn.layernorm_qkv.0.bias False\n",
      "esm_model.transformer.blocks.23.attn.layernorm_qkv.1.weight False\n",
      "esm_model.transformer.blocks.23.attn.out_proj.weight False\n",
      "esm_model.transformer.blocks.23.attn.q_ln.weight False\n",
      "esm_model.transformer.blocks.23.attn.k_ln.weight False\n",
      "esm_model.transformer.blocks.23.ffn.0.weight False\n",
      "esm_model.transformer.blocks.23.ffn.0.bias False\n",
      "esm_model.transformer.blocks.23.ffn.1.weight False\n",
      "esm_model.transformer.blocks.23.ffn.3.weight False\n",
      "esm_model.transformer.blocks.24.attn.layernorm_qkv.0.weight False\n",
      "esm_model.transformer.blocks.24.attn.layernorm_qkv.0.bias False\n",
      "esm_model.transformer.blocks.24.attn.layernorm_qkv.1.weight False\n",
      "esm_model.transformer.blocks.24.attn.out_proj.weight False\n",
      "esm_model.transformer.blocks.24.attn.q_ln.weight False\n",
      "esm_model.transformer.blocks.24.attn.k_ln.weight False\n",
      "esm_model.transformer.blocks.24.ffn.0.weight False\n",
      "esm_model.transformer.blocks.24.ffn.0.bias False\n",
      "esm_model.transformer.blocks.24.ffn.1.weight False\n",
      "esm_model.transformer.blocks.24.ffn.3.weight False\n",
      "esm_model.transformer.blocks.25.attn.layernorm_qkv.0.weight False\n",
      "esm_model.transformer.blocks.25.attn.layernorm_qkv.0.bias False\n",
      "esm_model.transformer.blocks.25.attn.layernorm_qkv.1.weight False\n",
      "esm_model.transformer.blocks.25.attn.out_proj.weight False\n",
      "esm_model.transformer.blocks.25.attn.q_ln.weight False\n",
      "esm_model.transformer.blocks.25.attn.k_ln.weight False\n",
      "esm_model.transformer.blocks.25.ffn.0.weight False\n",
      "esm_model.transformer.blocks.25.ffn.0.bias False\n",
      "esm_model.transformer.blocks.25.ffn.1.weight False\n",
      "esm_model.transformer.blocks.25.ffn.3.weight False\n",
      "esm_model.transformer.blocks.26.attn.layernorm_qkv.0.weight False\n",
      "esm_model.transformer.blocks.26.attn.layernorm_qkv.0.bias False\n",
      "esm_model.transformer.blocks.26.attn.layernorm_qkv.1.weight False\n",
      "esm_model.transformer.blocks.26.attn.out_proj.weight False\n",
      "esm_model.transformer.blocks.26.attn.q_ln.weight False\n",
      "esm_model.transformer.blocks.26.attn.k_ln.weight False\n",
      "esm_model.transformer.blocks.26.ffn.0.weight False\n",
      "esm_model.transformer.blocks.26.ffn.0.bias False\n",
      "esm_model.transformer.blocks.26.ffn.1.weight False\n",
      "esm_model.transformer.blocks.26.ffn.3.weight False\n",
      "esm_model.transformer.blocks.27.attn.layernorm_qkv.0.weight False\n",
      "esm_model.transformer.blocks.27.attn.layernorm_qkv.0.bias False\n",
      "esm_model.transformer.blocks.27.attn.layernorm_qkv.1.weight False\n",
      "esm_model.transformer.blocks.27.attn.out_proj.weight False\n",
      "esm_model.transformer.blocks.27.attn.q_ln.weight False\n",
      "esm_model.transformer.blocks.27.attn.k_ln.weight False\n",
      "esm_model.transformer.blocks.27.ffn.0.weight False\n",
      "esm_model.transformer.blocks.27.ffn.0.bias False\n",
      "esm_model.transformer.blocks.27.ffn.1.weight False\n",
      "esm_model.transformer.blocks.27.ffn.3.weight False\n",
      "esm_model.transformer.blocks.28.attn.layernorm_qkv.0.weight False\n",
      "esm_model.transformer.blocks.28.attn.layernorm_qkv.0.bias False\n",
      "esm_model.transformer.blocks.28.attn.layernorm_qkv.1.weight False\n",
      "esm_model.transformer.blocks.28.attn.out_proj.weight False\n",
      "esm_model.transformer.blocks.28.attn.q_ln.weight False\n",
      "esm_model.transformer.blocks.28.attn.k_ln.weight False\n",
      "esm_model.transformer.blocks.28.ffn.0.weight False\n",
      "esm_model.transformer.blocks.28.ffn.0.bias False\n",
      "esm_model.transformer.blocks.28.ffn.1.weight False\n",
      "esm_model.transformer.blocks.28.ffn.3.weight False\n",
      "esm_model.transformer.blocks.29.attn.layernorm_qkv.0.weight False\n",
      "esm_model.transformer.blocks.29.attn.layernorm_qkv.0.bias False\n",
      "esm_model.transformer.blocks.29.attn.layernorm_qkv.1.weight False\n",
      "esm_model.transformer.blocks.29.attn.out_proj.weight False\n",
      "esm_model.transformer.blocks.29.attn.q_ln.weight False\n",
      "esm_model.transformer.blocks.29.attn.k_ln.weight False\n",
      "esm_model.transformer.blocks.29.ffn.0.weight False\n",
      "esm_model.transformer.blocks.29.ffn.0.bias False\n",
      "esm_model.transformer.blocks.29.ffn.1.weight False\n",
      "esm_model.transformer.blocks.29.ffn.3.weight False\n",
      "esm_model.transformer.blocks.30.attn.layernorm_qkv.0.weight False\n",
      "esm_model.transformer.blocks.30.attn.layernorm_qkv.0.bias False\n",
      "esm_model.transformer.blocks.30.attn.layernorm_qkv.1.weight False\n",
      "esm_model.transformer.blocks.30.attn.out_proj.weight False\n",
      "esm_model.transformer.blocks.30.attn.q_ln.weight False\n",
      "esm_model.transformer.blocks.30.attn.k_ln.weight False\n",
      "esm_model.transformer.blocks.30.ffn.0.weight False\n",
      "esm_model.transformer.blocks.30.ffn.0.bias False\n",
      "esm_model.transformer.blocks.30.ffn.1.weight False\n",
      "esm_model.transformer.blocks.30.ffn.3.weight False\n",
      "esm_model.transformer.blocks.31.attn.layernorm_qkv.0.weight False\n",
      "esm_model.transformer.blocks.31.attn.layernorm_qkv.0.bias False\n",
      "esm_model.transformer.blocks.31.attn.layernorm_qkv.1.weight False\n",
      "esm_model.transformer.blocks.31.attn.out_proj.weight False\n",
      "esm_model.transformer.blocks.31.attn.q_ln.weight False\n",
      "esm_model.transformer.blocks.31.attn.k_ln.weight False\n",
      "esm_model.transformer.blocks.31.ffn.0.weight False\n",
      "esm_model.transformer.blocks.31.ffn.0.bias False\n",
      "esm_model.transformer.blocks.31.ffn.1.weight False\n",
      "esm_model.transformer.blocks.31.ffn.3.weight False\n",
      "esm_model.transformer.blocks.32.attn.layernorm_qkv.0.weight False\n",
      "esm_model.transformer.blocks.32.attn.layernorm_qkv.0.bias False\n",
      "esm_model.transformer.blocks.32.attn.layernorm_qkv.1.weight False\n",
      "esm_model.transformer.blocks.32.attn.out_proj.weight False\n",
      "esm_model.transformer.blocks.32.attn.q_ln.weight False\n",
      "esm_model.transformer.blocks.32.attn.k_ln.weight False\n",
      "esm_model.transformer.blocks.32.ffn.0.weight False\n",
      "esm_model.transformer.blocks.32.ffn.0.bias False\n",
      "esm_model.transformer.blocks.32.ffn.1.weight False\n",
      "esm_model.transformer.blocks.32.ffn.3.weight False\n",
      "esm_model.transformer.blocks.33.attn.layernorm_qkv.0.weight False\n",
      "esm_model.transformer.blocks.33.attn.layernorm_qkv.0.bias False\n",
      "esm_model.transformer.blocks.33.attn.layernorm_qkv.1.weight False\n",
      "esm_model.transformer.blocks.33.attn.out_proj.weight False\n",
      "esm_model.transformer.blocks.33.attn.q_ln.weight False\n",
      "esm_model.transformer.blocks.33.attn.k_ln.weight False\n",
      "esm_model.transformer.blocks.33.ffn.0.weight False\n",
      "esm_model.transformer.blocks.33.ffn.0.bias False\n",
      "esm_model.transformer.blocks.33.ffn.1.weight False\n",
      "esm_model.transformer.blocks.33.ffn.3.weight False\n",
      "esm_model.transformer.blocks.34.attn.layernorm_qkv.0.weight False\n",
      "esm_model.transformer.blocks.34.attn.layernorm_qkv.0.bias False\n",
      "esm_model.transformer.blocks.34.attn.layernorm_qkv.1.weight False\n",
      "esm_model.transformer.blocks.34.attn.out_proj.weight False\n",
      "esm_model.transformer.blocks.34.attn.q_ln.weight False\n",
      "esm_model.transformer.blocks.34.attn.k_ln.weight False\n",
      "esm_model.transformer.blocks.34.ffn.0.weight False\n",
      "esm_model.transformer.blocks.34.ffn.0.bias False\n",
      "esm_model.transformer.blocks.34.ffn.1.weight False\n",
      "esm_model.transformer.blocks.34.ffn.3.weight False\n",
      "esm_model.transformer.blocks.35.attn.layernorm_qkv.0.weight False\n",
      "esm_model.transformer.blocks.35.attn.layernorm_qkv.0.bias False\n",
      "esm_model.transformer.blocks.35.attn.layernorm_qkv.1.weight False\n",
      "esm_model.transformer.blocks.35.attn.out_proj.weight False\n",
      "esm_model.transformer.blocks.35.attn.q_ln.weight False\n",
      "esm_model.transformer.blocks.35.attn.k_ln.weight False\n",
      "esm_model.transformer.blocks.35.ffn.0.weight False\n",
      "esm_model.transformer.blocks.35.ffn.0.bias False\n",
      "esm_model.transformer.blocks.35.ffn.1.weight False\n",
      "esm_model.transformer.blocks.35.ffn.3.weight False\n",
      "esm_model.transformer.blocks.36.attn.layernorm_qkv.0.weight False\n",
      "esm_model.transformer.blocks.36.attn.layernorm_qkv.0.bias False\n",
      "esm_model.transformer.blocks.36.attn.layernorm_qkv.1.weight False\n",
      "esm_model.transformer.blocks.36.attn.out_proj.weight False\n",
      "esm_model.transformer.blocks.36.attn.q_ln.weight False\n",
      "esm_model.transformer.blocks.36.attn.k_ln.weight False\n",
      "esm_model.transformer.blocks.36.ffn.0.weight False\n",
      "esm_model.transformer.blocks.36.ffn.0.bias False\n",
      "esm_model.transformer.blocks.36.ffn.1.weight False\n",
      "esm_model.transformer.blocks.36.ffn.3.weight False\n",
      "esm_model.transformer.blocks.37.attn.layernorm_qkv.0.weight False\n",
      "esm_model.transformer.blocks.37.attn.layernorm_qkv.0.bias False\n",
      "esm_model.transformer.blocks.37.attn.layernorm_qkv.1.weight False\n",
      "esm_model.transformer.blocks.37.attn.out_proj.weight False\n",
      "esm_model.transformer.blocks.37.attn.q_ln.weight False\n",
      "esm_model.transformer.blocks.37.attn.k_ln.weight False\n",
      "esm_model.transformer.blocks.37.ffn.0.weight False\n",
      "esm_model.transformer.blocks.37.ffn.0.bias False\n",
      "esm_model.transformer.blocks.37.ffn.1.weight False\n",
      "esm_model.transformer.blocks.37.ffn.3.weight False\n",
      "esm_model.transformer.blocks.38.attn.layernorm_qkv.0.weight False\n",
      "esm_model.transformer.blocks.38.attn.layernorm_qkv.0.bias False\n",
      "esm_model.transformer.blocks.38.attn.layernorm_qkv.1.weight False\n",
      "esm_model.transformer.blocks.38.attn.out_proj.weight False\n",
      "esm_model.transformer.blocks.38.attn.q_ln.weight False\n",
      "esm_model.transformer.blocks.38.attn.k_ln.weight False\n",
      "esm_model.transformer.blocks.38.ffn.0.weight False\n",
      "esm_model.transformer.blocks.38.ffn.0.bias False\n",
      "esm_model.transformer.blocks.38.ffn.1.weight False\n",
      "esm_model.transformer.blocks.38.ffn.3.weight False\n",
      "esm_model.transformer.blocks.39.attn.layernorm_qkv.0.weight False\n",
      "esm_model.transformer.blocks.39.attn.layernorm_qkv.0.bias False\n",
      "esm_model.transformer.blocks.39.attn.layernorm_qkv.1.weight False\n",
      "esm_model.transformer.blocks.39.attn.out_proj.weight False\n",
      "esm_model.transformer.blocks.39.attn.q_ln.weight False\n",
      "esm_model.transformer.blocks.39.attn.k_ln.weight False\n",
      "esm_model.transformer.blocks.39.ffn.0.weight False\n",
      "esm_model.transformer.blocks.39.ffn.0.bias False\n",
      "esm_model.transformer.blocks.39.ffn.1.weight False\n",
      "esm_model.transformer.blocks.39.ffn.3.weight False\n",
      "esm_model.transformer.blocks.40.attn.layernorm_qkv.0.weight False\n",
      "esm_model.transformer.blocks.40.attn.layernorm_qkv.0.bias False\n",
      "esm_model.transformer.blocks.40.attn.layernorm_qkv.1.linear.weight False\n",
      "esm_model.transformer.blocks.40.attn.layernorm_qkv.1.lora.A True\n",
      "esm_model.transformer.blocks.40.attn.layernorm_qkv.1.lora.B True\n",
      "esm_model.transformer.blocks.40.attn.out_proj.linear.weight False\n",
      "esm_model.transformer.blocks.40.attn.out_proj.lora.A True\n",
      "esm_model.transformer.blocks.40.attn.out_proj.lora.B True\n",
      "esm_model.transformer.blocks.40.attn.q_ln.weight False\n",
      "esm_model.transformer.blocks.40.attn.k_ln.weight False\n",
      "esm_model.transformer.blocks.40.ffn.0.weight False\n",
      "esm_model.transformer.blocks.40.ffn.0.bias False\n",
      "esm_model.transformer.blocks.40.ffn.1.linear.weight False\n",
      "esm_model.transformer.blocks.40.ffn.1.lora.A True\n",
      "esm_model.transformer.blocks.40.ffn.1.lora.B True\n",
      "esm_model.transformer.blocks.40.ffn.3.linear.weight False\n",
      "esm_model.transformer.blocks.40.ffn.3.lora.A True\n",
      "esm_model.transformer.blocks.40.ffn.3.lora.B True\n",
      "esm_model.transformer.blocks.41.attn.layernorm_qkv.0.weight False\n",
      "esm_model.transformer.blocks.41.attn.layernorm_qkv.0.bias False\n",
      "esm_model.transformer.blocks.41.attn.layernorm_qkv.1.linear.weight False\n",
      "esm_model.transformer.blocks.41.attn.layernorm_qkv.1.lora.A True\n",
      "esm_model.transformer.blocks.41.attn.layernorm_qkv.1.lora.B True\n",
      "esm_model.transformer.blocks.41.attn.out_proj.linear.weight False\n",
      "esm_model.transformer.blocks.41.attn.out_proj.lora.A True\n",
      "esm_model.transformer.blocks.41.attn.out_proj.lora.B True\n",
      "esm_model.transformer.blocks.41.attn.q_ln.weight False\n",
      "esm_model.transformer.blocks.41.attn.k_ln.weight False\n",
      "esm_model.transformer.blocks.41.ffn.0.weight False\n",
      "esm_model.transformer.blocks.41.ffn.0.bias False\n",
      "esm_model.transformer.blocks.41.ffn.1.linear.weight False\n",
      "esm_model.transformer.blocks.41.ffn.1.lora.A True\n",
      "esm_model.transformer.blocks.41.ffn.1.lora.B True\n",
      "esm_model.transformer.blocks.41.ffn.3.linear.weight False\n",
      "esm_model.transformer.blocks.41.ffn.3.lora.A True\n",
      "esm_model.transformer.blocks.41.ffn.3.lora.B True\n",
      "esm_model.transformer.blocks.42.attn.layernorm_qkv.0.weight False\n",
      "esm_model.transformer.blocks.42.attn.layernorm_qkv.0.bias False\n",
      "esm_model.transformer.blocks.42.attn.layernorm_qkv.1.linear.weight False\n",
      "esm_model.transformer.blocks.42.attn.layernorm_qkv.1.lora.A True\n",
      "esm_model.transformer.blocks.42.attn.layernorm_qkv.1.lora.B True\n",
      "esm_model.transformer.blocks.42.attn.out_proj.linear.weight False\n",
      "esm_model.transformer.blocks.42.attn.out_proj.lora.A True\n",
      "esm_model.transformer.blocks.42.attn.out_proj.lora.B True\n",
      "esm_model.transformer.blocks.42.attn.q_ln.weight False\n",
      "esm_model.transformer.blocks.42.attn.k_ln.weight False\n",
      "esm_model.transformer.blocks.42.ffn.0.weight False\n",
      "esm_model.transformer.blocks.42.ffn.0.bias False\n",
      "esm_model.transformer.blocks.42.ffn.1.linear.weight False\n",
      "esm_model.transformer.blocks.42.ffn.1.lora.A True\n",
      "esm_model.transformer.blocks.42.ffn.1.lora.B True\n",
      "esm_model.transformer.blocks.42.ffn.3.linear.weight False\n",
      "esm_model.transformer.blocks.42.ffn.3.lora.A True\n",
      "esm_model.transformer.blocks.42.ffn.3.lora.B True\n",
      "esm_model.transformer.blocks.43.attn.layernorm_qkv.0.weight False\n",
      "esm_model.transformer.blocks.43.attn.layernorm_qkv.0.bias False\n",
      "esm_model.transformer.blocks.43.attn.layernorm_qkv.1.linear.weight False\n",
      "esm_model.transformer.blocks.43.attn.layernorm_qkv.1.lora.A True\n",
      "esm_model.transformer.blocks.43.attn.layernorm_qkv.1.lora.B True\n",
      "esm_model.transformer.blocks.43.attn.out_proj.linear.weight False\n",
      "esm_model.transformer.blocks.43.attn.out_proj.lora.A True\n",
      "esm_model.transformer.blocks.43.attn.out_proj.lora.B True\n",
      "esm_model.transformer.blocks.43.attn.q_ln.weight False\n",
      "esm_model.transformer.blocks.43.attn.k_ln.weight False\n",
      "esm_model.transformer.blocks.43.ffn.0.weight False\n",
      "esm_model.transformer.blocks.43.ffn.0.bias False\n",
      "esm_model.transformer.blocks.43.ffn.1.linear.weight False\n",
      "esm_model.transformer.blocks.43.ffn.1.lora.A True\n",
      "esm_model.transformer.blocks.43.ffn.1.lora.B True\n",
      "esm_model.transformer.blocks.43.ffn.3.linear.weight False\n",
      "esm_model.transformer.blocks.43.ffn.3.lora.A True\n",
      "esm_model.transformer.blocks.43.ffn.3.lora.B True\n",
      "esm_model.transformer.blocks.44.attn.layernorm_qkv.0.weight False\n",
      "esm_model.transformer.blocks.44.attn.layernorm_qkv.0.bias False\n",
      "esm_model.transformer.blocks.44.attn.layernorm_qkv.1.linear.weight False\n",
      "esm_model.transformer.blocks.44.attn.layernorm_qkv.1.lora.A True\n",
      "esm_model.transformer.blocks.44.attn.layernorm_qkv.1.lora.B True\n",
      "esm_model.transformer.blocks.44.attn.out_proj.linear.weight False\n",
      "esm_model.transformer.blocks.44.attn.out_proj.lora.A True\n",
      "esm_model.transformer.blocks.44.attn.out_proj.lora.B True\n",
      "esm_model.transformer.blocks.44.attn.q_ln.weight False\n",
      "esm_model.transformer.blocks.44.attn.k_ln.weight False\n",
      "esm_model.transformer.blocks.44.ffn.0.weight False\n",
      "esm_model.transformer.blocks.44.ffn.0.bias False\n",
      "esm_model.transformer.blocks.44.ffn.1.linear.weight False\n",
      "esm_model.transformer.blocks.44.ffn.1.lora.A True\n",
      "esm_model.transformer.blocks.44.ffn.1.lora.B True\n",
      "esm_model.transformer.blocks.44.ffn.3.linear.weight False\n",
      "esm_model.transformer.blocks.44.ffn.3.lora.A True\n",
      "esm_model.transformer.blocks.44.ffn.3.lora.B True\n",
      "esm_model.transformer.blocks.45.attn.layernorm_qkv.0.weight False\n",
      "esm_model.transformer.blocks.45.attn.layernorm_qkv.0.bias False\n",
      "esm_model.transformer.blocks.45.attn.layernorm_qkv.1.linear.weight False\n",
      "esm_model.transformer.blocks.45.attn.layernorm_qkv.1.lora.A True\n",
      "esm_model.transformer.blocks.45.attn.layernorm_qkv.1.lora.B True\n",
      "esm_model.transformer.blocks.45.attn.out_proj.linear.weight False\n",
      "esm_model.transformer.blocks.45.attn.out_proj.lora.A True\n",
      "esm_model.transformer.blocks.45.attn.out_proj.lora.B True\n",
      "esm_model.transformer.blocks.45.attn.q_ln.weight False\n",
      "esm_model.transformer.blocks.45.attn.k_ln.weight False\n",
      "esm_model.transformer.blocks.45.ffn.0.weight False\n",
      "esm_model.transformer.blocks.45.ffn.0.bias False\n",
      "esm_model.transformer.blocks.45.ffn.1.linear.weight False\n",
      "esm_model.transformer.blocks.45.ffn.1.lora.A True\n",
      "esm_model.transformer.blocks.45.ffn.1.lora.B True\n",
      "esm_model.transformer.blocks.45.ffn.3.linear.weight False\n",
      "esm_model.transformer.blocks.45.ffn.3.lora.A True\n",
      "esm_model.transformer.blocks.45.ffn.3.lora.B True\n",
      "esm_model.transformer.blocks.46.attn.layernorm_qkv.0.weight False\n",
      "esm_model.transformer.blocks.46.attn.layernorm_qkv.0.bias False\n",
      "esm_model.transformer.blocks.46.attn.layernorm_qkv.1.linear.weight False\n",
      "esm_model.transformer.blocks.46.attn.layernorm_qkv.1.lora.A True\n",
      "esm_model.transformer.blocks.46.attn.layernorm_qkv.1.lora.B True\n",
      "esm_model.transformer.blocks.46.attn.out_proj.linear.weight False\n",
      "esm_model.transformer.blocks.46.attn.out_proj.lora.A True\n",
      "esm_model.transformer.blocks.46.attn.out_proj.lora.B True\n",
      "esm_model.transformer.blocks.46.attn.q_ln.weight False\n",
      "esm_model.transformer.blocks.46.attn.k_ln.weight False\n",
      "esm_model.transformer.blocks.46.ffn.0.weight False\n",
      "esm_model.transformer.blocks.46.ffn.0.bias False\n",
      "esm_model.transformer.blocks.46.ffn.1.linear.weight False\n",
      "esm_model.transformer.blocks.46.ffn.1.lora.A True\n",
      "esm_model.transformer.blocks.46.ffn.1.lora.B True\n",
      "esm_model.transformer.blocks.46.ffn.3.linear.weight False\n",
      "esm_model.transformer.blocks.46.ffn.3.lora.A True\n",
      "esm_model.transformer.blocks.46.ffn.3.lora.B True\n",
      "esm_model.transformer.blocks.47.attn.layernorm_qkv.0.weight False\n",
      "esm_model.transformer.blocks.47.attn.layernorm_qkv.0.bias False\n",
      "esm_model.transformer.blocks.47.attn.layernorm_qkv.1.linear.weight False\n",
      "esm_model.transformer.blocks.47.attn.layernorm_qkv.1.lora.A True\n",
      "esm_model.transformer.blocks.47.attn.layernorm_qkv.1.lora.B True\n",
      "esm_model.transformer.blocks.47.attn.out_proj.linear.weight False\n",
      "esm_model.transformer.blocks.47.attn.out_proj.lora.A True\n",
      "esm_model.transformer.blocks.47.attn.out_proj.lora.B True\n",
      "esm_model.transformer.blocks.47.attn.q_ln.weight False\n",
      "esm_model.transformer.blocks.47.attn.k_ln.weight False\n",
      "esm_model.transformer.blocks.47.ffn.0.weight False\n",
      "esm_model.transformer.blocks.47.ffn.0.bias False\n",
      "esm_model.transformer.blocks.47.ffn.1.linear.weight False\n",
      "esm_model.transformer.blocks.47.ffn.1.lora.A True\n",
      "esm_model.transformer.blocks.47.ffn.1.lora.B True\n",
      "esm_model.transformer.blocks.47.ffn.3.linear.weight False\n",
      "esm_model.transformer.blocks.47.ffn.3.lora.A True\n",
      "esm_model.transformer.blocks.47.ffn.3.lora.B True\n",
      "esm_model.transformer.norm.weight False\n",
      "esm_model.output_heads.sequence_head.0.weight False\n",
      "esm_model.output_heads.sequence_head.0.bias False\n",
      "esm_model.output_heads.sequence_head.2.weight False\n",
      "esm_model.output_heads.sequence_head.2.bias False\n",
      "esm_model.output_heads.sequence_head.3.weight False\n",
      "esm_model.output_heads.sequence_head.3.bias False\n",
      "esm_model.output_heads.structure_head.0.weight False\n",
      "esm_model.output_heads.structure_head.0.bias False\n",
      "esm_model.output_heads.structure_head.2.weight False\n",
      "esm_model.output_heads.structure_head.2.bias False\n",
      "esm_model.output_heads.structure_head.3.weight False\n",
      "esm_model.output_heads.structure_head.3.bias False\n",
      "esm_model.output_heads.ss8_head.0.weight False\n",
      "esm_model.output_heads.ss8_head.0.bias False\n",
      "esm_model.output_heads.ss8_head.2.weight False\n",
      "esm_model.output_heads.ss8_head.2.bias False\n",
      "esm_model.output_heads.ss8_head.3.weight False\n",
      "esm_model.output_heads.ss8_head.3.bias False\n",
      "esm_model.output_heads.sasa_head.0.weight False\n",
      "esm_model.output_heads.sasa_head.0.bias False\n",
      "esm_model.output_heads.sasa_head.2.weight False\n",
      "esm_model.output_heads.sasa_head.2.bias False\n",
      "esm_model.output_heads.sasa_head.3.weight False\n",
      "esm_model.output_heads.sasa_head.3.bias False\n",
      "esm_model.output_heads.function_head.0.weight False\n",
      "esm_model.output_heads.function_head.0.bias False\n",
      "esm_model.output_heads.function_head.2.weight False\n",
      "esm_model.output_heads.function_head.2.bias False\n",
      "esm_model.output_heads.function_head.3.weight False\n",
      "esm_model.output_heads.function_head.3.bias False\n",
      "esm_model.output_heads.residue_head.0.weight False\n",
      "esm_model.output_heads.residue_head.0.bias False\n",
      "esm_model.output_heads.residue_head.2.weight False\n",
      "esm_model.output_heads.residue_head.2.bias False\n",
      "esm_model.output_heads.residue_head.3.weight False\n",
      "esm_model.output_heads.residue_head.3.bias False\n"
     ]
    }
   ],
   "source": [
    "for i, j in model.named_parameters():\n",
    "    print(i, j.requires_grad)\n",
    "    # if j.requires_grad:\n",
    "    #     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get val loader\n",
      "called new epoch\n"
     ]
    }
   ],
   "source": [
    "dl = ds.val_dataloader() \n",
    "for b, data in enumerate(dl):\n",
    "    # print(x.shape, y.shape)\n",
    "    # break\n",
    "    pass\n",
    "data = data[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeds = [] \n",
    "with torch.no_grad():\n",
    "    for i in data:\n",
    "        embeds.append(model.getEmbedding(i)[0, 0])\n",
    "embeds = torch.stack(embeds, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0194, -0.0585, -0.0101,  ...,  0.0017,  0.0020,  0.0520],\n",
       "        [-0.0221, -0.0045, -0.0094,  ...,  0.0113, -0.0008,  0.0428],\n",
       "        [-0.0037, -0.0628, -0.0068,  ...,  0.0018, -0.0051,  0.0293],\n",
       "        ...,\n",
       "        [ 0.0645, -0.0462, -0.0138,  ...,  0.0043, -0.0055,  0.0442],\n",
       "        [-0.0057, -0.0111, -0.0052,  ...,  0.0007, -0.0075,  0.0222],\n",
       "        [ 0.0452, -0.0555, -0.0097,  ...,  0.0008,  0.0002,  0.0428]],\n",
       "       device='cuda:6')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([85, 1152])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "clsmodel = models.Linearcls(1152, dropout=0.2, p0=0.2, take_embed=\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(186.8812, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "186.88116455078125\n",
      "tensor(194.4602, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "194.4601593017578\n",
      "tensor(193.8147, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "193.814697265625\n",
      "tensor(192.1247, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "192.12472534179688\n",
      "tensor(193.7268, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "193.72677612304688\n",
      "tensor(195.2809, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "195.28085327148438\n",
      "tensor(191.1854, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "191.1854248046875\n",
      "tensor(186.7961, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "186.79605102539062\n",
      "tensor(199.3803, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "199.3802947998047\n",
      "tensor(183.5143, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "183.51434326171875\n",
      "tensor(181.0327, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "181.03271484375\n",
      "tensor(191.5052, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "191.50521850585938\n",
      "tensor(186.5496, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "186.549560546875\n",
      "tensor(178.9835, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "178.9835205078125\n",
      "tensor(194.4560, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "194.45603942871094\n",
      "tensor(188.1657, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "188.16567993164062\n",
      "tensor(193.4260, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "193.426025390625\n",
      "tensor(190.2678, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "190.26783752441406\n",
      "tensor(182.4524, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "182.452392578125\n",
      "tensor(188.9237, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "188.92373657226562\n",
      "tensor(189.4861, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "189.486083984375\n",
      "tensor(188.9164, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "188.9163818359375\n",
      "tensor(179.3625, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "179.36253356933594\n",
      "tensor(186.8865, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "186.886474609375\n",
      "tensor(196.1399, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "196.13986206054688\n",
      "tensor(205.9596, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "205.95962524414062\n",
      "tensor(194.4141, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "194.41409301757812\n",
      "tensor(188.5396, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "188.53961181640625\n",
      "tensor(189.7874, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "189.78744506835938\n",
      "tensor(182.0814, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "182.08143615722656\n",
      "tensor(187.8572, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "187.85720825195312\n",
      "tensor(180.5676, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "180.56759643554688\n",
      "tensor(183.5662, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "183.5662384033203\n",
      "tensor(186.0309, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "186.03094482421875\n",
      "tensor(180.5508, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "180.55078125\n",
      "tensor(184.6789, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "184.6789093017578\n",
      "tensor(192.6535, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "192.65347290039062\n",
      "tensor(194.3947, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "194.39468383789062\n",
      "tensor(180.3535, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "180.35345458984375\n",
      "tensor(187.4848, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "187.48477172851562\n",
      "tensor(187.6941, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "187.69412231445312\n",
      "tensor(178.4069, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "178.40689086914062\n",
      "tensor(186.8712, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "186.8711700439453\n",
      "tensor(183.0212, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "183.021240234375\n",
      "tensor(179.7024, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "179.7024383544922\n",
      "tensor(187.2110, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "187.21104431152344\n",
      "tensor(181.8500, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "181.85003662109375\n",
      "tensor(184.4039, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "184.40390014648438\n",
      "tensor(183.2204, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "183.22039794921875\n",
      "tensor(187.7277, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "187.7276611328125\n",
      "tensor(193.2544, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "193.2544403076172\n",
      "tensor(185.7385, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "185.73846435546875\n",
      "tensor(179.0779, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "179.07794189453125\n",
      "tensor(191.1502, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "191.15020751953125\n",
      "tensor(191.8422, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "191.84219360351562\n",
      "tensor(188.4285, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "188.428466796875\n",
      "tensor(184.2118, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "184.21176147460938\n",
      "tensor(185.1756, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "185.17556762695312\n",
      "tensor(181.2435, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "181.24349975585938\n",
      "tensor(193.5081, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "193.50814819335938\n",
      "tensor(187.0435, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "187.04354858398438\n",
      "tensor(180.2315, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "180.23147583007812\n",
      "tensor(187.3816, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "187.3816375732422\n",
      "tensor(185.5624, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "185.56239318847656\n",
      "tensor(183.5549, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "183.5548553466797\n",
      "tensor(179.7239, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "179.72386169433594\n",
      "tensor(191.8283, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "191.82833862304688\n",
      "tensor(191.8168, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "191.81683349609375\n",
      "tensor(185.4517, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "185.45172119140625\n",
      "tensor(184.6176, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "184.61761474609375\n",
      "tensor(185.2831, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "185.2830810546875\n",
      "tensor(193.3658, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "193.36582946777344\n",
      "tensor(197.9593, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "197.95932006835938\n",
      "tensor(194.1941, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "194.194091796875\n",
      "tensor(183.4756, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "183.47555541992188\n",
      "tensor(191.5777, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "191.5777130126953\n",
      "tensor(188.6583, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "188.6583251953125\n",
      "tensor(186.3710, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "186.3709716796875\n",
      "tensor(190.0166, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "190.01663208007812\n",
      "tensor(190.3375, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "190.33749389648438\n",
      "tensor(188.1733, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "188.1732635498047\n",
      "tensor(179.8184, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "179.818359375\n",
      "tensor(181.5853, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "181.58526611328125\n",
      "tensor(181.2647, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "181.26473999023438\n",
      "tensor(196.1540, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "196.15396118164062\n",
      "tensor(183.2623, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "183.26234436035156\n",
      "tensor(181.1203, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "181.12034606933594\n",
      "tensor(180.9273, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "180.92727661132812\n",
      "tensor(180.8105, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "180.81051635742188\n",
      "tensor(185.4808, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "185.4808349609375\n",
      "tensor(180.7625, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "180.76248168945312\n",
      "tensor(175.8632, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "175.8632354736328\n",
      "tensor(184.2126, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "184.212646484375\n",
      "tensor(188.3157, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "188.31573486328125\n",
      "tensor(190.0596, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "190.05958557128906\n",
      "tensor(179.2664, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "179.26638793945312\n",
      "tensor(183.8872, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "183.88723754882812\n",
      "tensor(183.4684, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "183.46839904785156\n",
      "tensor(179.6560, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "179.65602111816406\n",
      "tensor(179.1071, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "179.1070556640625\n",
      "tensor(185.5156, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "185.51559448242188\n",
      "tensor(186.4872, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "186.48721313476562\n",
      "tensor(198.9074, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "198.90744018554688\n",
      "tensor(188.9193, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "188.91925048828125\n",
      "tensor(183.1429, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "183.14285278320312\n",
      "tensor(183.8147, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "183.81466674804688\n",
      "tensor(182.6377, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "182.63772583007812\n",
      "tensor(186.6885, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "186.6884765625\n",
      "tensor(182.9949, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "182.99490356445312\n",
      "tensor(179.2299, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "179.22988891601562\n",
      "tensor(183.1693, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "183.1692657470703\n",
      "tensor(178.3774, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "178.37742614746094\n",
      "tensor(191.5306, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "191.5306396484375\n",
      "tensor(175.1455, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "175.14547729492188\n",
      "tensor(184.4996, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "184.49960327148438\n",
      "tensor(192.2224, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "192.222412109375\n",
      "tensor(186.6169, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "186.616943359375\n",
      "tensor(184.9898, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "184.98983764648438\n",
      "tensor(195.3287, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "195.32872009277344\n",
      "tensor(191.1494, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "191.14944458007812\n",
      "tensor(180.8158, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "180.8157501220703\n",
      "tensor(181.2868, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "181.28677368164062\n",
      "tensor(197.5495, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "197.54945373535156\n",
      "tensor(195.8656, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "195.86563110351562\n",
      "tensor(189.5249, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "189.5249481201172\n",
      "tensor(185.4942, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "185.49424743652344\n",
      "tensor(183.3764, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "183.37643432617188\n",
      "tensor(191.9168, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "191.91683959960938\n",
      "tensor(191.5080, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "191.50804138183594\n",
      "tensor(186.9056, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "186.9055633544922\n",
      "tensor(174.5321, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "174.5321044921875\n",
      "tensor(195.7542, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "195.7541961669922\n",
      "tensor(174.7431, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "174.74305725097656\n",
      "tensor(200.3130, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "200.31301879882812\n",
      "tensor(179.9616, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "179.9616241455078\n",
      "tensor(184.4098, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "184.40980529785156\n",
      "tensor(188.2486, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "188.24864196777344\n",
      "tensor(185.4972, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "185.49720764160156\n",
      "tensor(188.6806, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "188.68057250976562\n",
      "tensor(188.2877, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "188.2877197265625\n",
      "tensor(181.9366, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "181.93658447265625\n",
      "tensor(194.3261, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "194.32608032226562\n",
      "tensor(194.5067, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "194.50668334960938\n",
      "tensor(190.9571, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "190.95706176757812\n",
      "tensor(189.3587, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "189.35873413085938\n",
      "tensor(183.4635, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "183.4634552001953\n",
      "tensor(183.9635, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "183.96353149414062\n",
      "tensor(182.8098, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "182.80984497070312\n",
      "tensor(190.0880, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "190.0879669189453\n",
      "tensor(187.9739, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "187.97393798828125\n",
      "tensor(188.7755, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "188.77545166015625\n",
      "tensor(180.3418, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "180.34182739257812\n",
      "tensor(188.0901, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "188.09014892578125\n",
      "tensor(179.4728, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "179.4728240966797\n",
      "tensor(187.5359, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "187.53587341308594\n",
      "tensor(183.2808, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "183.28076171875\n",
      "tensor(185.5240, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "185.5240478515625\n",
      "tensor(181.0831, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "181.08306884765625\n",
      "tensor(181.0042, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "181.00418090820312\n",
      "tensor(177.6085, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "177.60845947265625\n",
      "tensor(179.4129, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "179.41287231445312\n",
      "tensor(184.9067, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "184.90670776367188\n",
      "tensor(182.9064, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "182.90643310546875\n",
      "tensor(186.9471, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "186.94708251953125\n",
      "tensor(207.5709, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "207.57090759277344\n",
      "tensor(181.1978, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "181.19775390625\n",
      "tensor(179.1165, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "179.116455078125\n",
      "tensor(184.5232, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "184.523193359375\n",
      "tensor(181.7301, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "181.73013305664062\n",
      "tensor(185.0099, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "185.0098876953125\n",
      "tensor(186.7021, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "186.7021484375\n",
      "tensor(178.6734, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "178.67337036132812\n",
      "tensor(179.6548, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "179.65476989746094\n",
      "tensor(177.8200, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "177.81997680664062\n",
      "tensor(196.3266, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "196.3266143798828\n",
      "tensor(180.9711, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "180.97109985351562\n",
      "tensor(182.0421, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "182.0421142578125\n",
      "tensor(187.5563, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "187.55633544921875\n",
      "tensor(181.7888, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "181.7887725830078\n",
      "tensor(183.6201, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "183.62005615234375\n",
      "tensor(183.4353, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "183.43533325195312\n",
      "tensor(177.7795, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "177.779541015625\n",
      "tensor(183.8977, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "183.8976593017578\n",
      "tensor(201.0189, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "201.01893615722656\n",
      "tensor(201.4161, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "201.4161376953125\n",
      "tensor(183.8278, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "183.82778930664062\n",
      "tensor(192.0934, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "192.09344482421875\n",
      "tensor(185.3080, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "185.3079833984375\n",
      "tensor(176.6716, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "176.67160034179688\n",
      "tensor(192.9934, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "192.99339294433594\n",
      "tensor(182.7480, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "182.748046875\n",
      "tensor(182.7189, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "182.71893310546875\n",
      "tensor(183.0915, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "183.09146118164062\n",
      "tensor(186.9877, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "186.9877471923828\n",
      "tensor(181.9426, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "181.94264221191406\n",
      "tensor(188.2700, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "188.26995849609375\n",
      "tensor(180.3452, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "180.3451690673828\n",
      "tensor(189.4086, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "189.4086151123047\n",
      "tensor(178.6467, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "178.64669799804688\n",
      "tensor(184.6797, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "184.6797332763672\n",
      "tensor(183.2849, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "183.28485107421875\n",
      "tensor(183.4965, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "183.49649047851562\n",
      "tensor(179.2348, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "179.23477172851562\n",
      "tensor(184.6618, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "184.66180419921875\n",
      "tensor(193.1656, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "193.16561889648438\n",
      "tensor(179.2328, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "179.23275756835938\n",
      "tensor(185.4110, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "185.41104125976562\n",
      "tensor(185.9908, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "185.99081420898438\n",
      "tensor(183.1481, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "183.14810180664062\n",
      "tensor(183.9536, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "183.95361328125\n",
      "tensor(190.9123, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "190.91233825683594\n",
      "tensor(188.1440, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "188.14402770996094\n",
      "tensor(185.4890, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "185.4889678955078\n",
      "tensor(183.3303, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "183.33030700683594\n",
      "tensor(178.9805, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "178.98052978515625\n",
      "tensor(183.2777, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "183.27772521972656\n",
      "tensor(182.8667, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "182.86669921875\n",
      "tensor(192.6748, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "192.6748046875\n",
      "tensor(186.6142, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "186.61422729492188\n",
      "tensor(180.3068, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "180.30682373046875\n",
      "tensor(182.5496, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "182.549560546875\n",
      "tensor(184.4266, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "184.4266357421875\n",
      "tensor(184.6004, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "184.60043334960938\n",
      "tensor(184.7256, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "184.7255859375\n",
      "tensor(176.6819, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "176.68194580078125\n",
      "tensor(183.6899, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "183.68991088867188\n",
      "tensor(186.6994, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "186.69944763183594\n",
      "tensor(178.0666, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "178.06658935546875\n",
      "tensor(186.3604, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "186.36041259765625\n",
      "tensor(178.0962, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "178.09617614746094\n",
      "tensor(197.1232, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "197.12322998046875\n",
      "tensor(186.2998, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "186.29983520507812\n",
      "tensor(193.4160, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "193.41595458984375\n",
      "tensor(177.5202, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "177.52017211914062\n",
      "tensor(181.0313, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "181.03134155273438\n",
      "tensor(187.7399, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "187.73989868164062\n",
      "tensor(181.5200, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "181.52000427246094\n",
      "tensor(182.4008, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "182.4007568359375\n",
      "tensor(188.3087, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "188.30865478515625\n",
      "tensor(172.9563, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "172.956298828125\n",
      "tensor(176.3818, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "176.38177490234375\n",
      "tensor(182.9659, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "182.96592712402344\n",
      "tensor(182.5158, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "182.5157928466797\n",
      "tensor(190.3788, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "190.3787841796875\n",
      "tensor(185.3819, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "185.38186645507812\n",
      "tensor(178.5744, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "178.57440185546875\n",
      "tensor(183.6756, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "183.67559814453125\n",
      "tensor(194.7485, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "194.74847412109375\n",
      "tensor(178.2036, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "178.20364379882812\n",
      "tensor(182.4297, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "182.42971801757812\n",
      "tensor(173.6344, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "173.6343994140625\n",
      "tensor(186.8683, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "186.86831665039062\n",
      "tensor(176.6442, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "176.6442413330078\n",
      "tensor(186.9814, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "186.9814453125\n",
      "tensor(174.7154, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "174.71536254882812\n",
      "tensor(184.0683, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "184.06832885742188\n",
      "tensor(180.9915, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "180.99148559570312\n",
      "tensor(179.1502, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "179.15017700195312\n",
      "tensor(176.9369, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "176.93690490722656\n",
      "tensor(176.3952, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "176.39520263671875\n",
      "tensor(186.0696, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "186.06961059570312\n",
      "tensor(189.3931, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "189.39308166503906\n",
      "tensor(181.8004, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "181.80043029785156\n",
      "tensor(183.1613, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "183.1612548828125\n",
      "tensor(187.9415, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "187.9414520263672\n",
      "tensor(178.2716, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "178.27157592773438\n",
      "tensor(173.7653, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "173.76531982421875\n",
      "tensor(182.1325, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "182.13253784179688\n",
      "tensor(179.1777, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "179.17771911621094\n",
      "tensor(171.7292, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "171.72921752929688\n",
      "tensor(176.7021, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "176.70205688476562\n",
      "tensor(190.6303, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "190.63034057617188\n",
      "tensor(171.2410, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "171.24102783203125\n",
      "tensor(183.7813, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "183.78131103515625\n",
      "tensor(178.1837, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "178.18368530273438\n",
      "tensor(190.3709, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "190.37094116210938\n",
      "tensor(175.7886, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "175.78863525390625\n",
      "tensor(178.8736, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "178.87356567382812\n",
      "tensor(185.5727, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "185.57272338867188\n",
      "tensor(174.9201, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "174.92007446289062\n",
      "tensor(189.4722, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "189.47216796875\n",
      "tensor(171.6102, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "171.61021423339844\n",
      "tensor(201.1703, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "201.17031860351562\n",
      "tensor(194.4646, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "194.4645538330078\n",
      "tensor(189.7798, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "189.77978515625\n",
      "tensor(180.7737, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "180.773681640625\n",
      "tensor(177.8807, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "177.8806610107422\n",
      "tensor(179.2519, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "179.2519073486328\n",
      "tensor(175.5014, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "175.5014190673828\n",
      "tensor(178.2649, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "178.264892578125\n",
      "tensor(177.9936, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "177.99362182617188\n",
      "tensor(192.3495, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "192.34954833984375\n",
      "tensor(172.7662, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "172.7662353515625\n",
      "tensor(185.0679, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "185.06790161132812\n",
      "tensor(183.3226, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "183.32257080078125\n",
      "tensor(185.5329, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "185.53286743164062\n",
      "tensor(178.3477, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "178.34765625\n",
      "tensor(208.0510, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "208.051025390625\n",
      "tensor(211.0063, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "211.00625610351562\n",
      "tensor(179.2840, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "179.2839813232422\n",
      "tensor(181.0586, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "181.05859375\n",
      "tensor(183.9272, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "183.92718505859375\n",
      "tensor(185.3322, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "185.33218383789062\n",
      "tensor(191.5083, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "191.50828552246094\n",
      "tensor(183.3539, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "183.3538818359375\n",
      "tensor(192.8497, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "192.84967041015625\n",
      "tensor(191.5605, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "191.56045532226562\n",
      "tensor(191.3443, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "191.34432983398438\n",
      "tensor(189.4397, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "189.43972778320312\n",
      "tensor(184.9667, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "184.96673583984375\n",
      "tensor(183.8145, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "183.81454467773438\n",
      "tensor(184.7552, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "184.7552490234375\n",
      "tensor(182.8231, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "182.82310485839844\n",
      "tensor(179.0403, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "179.04025268554688\n",
      "tensor(178.9079, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "178.90792846679688\n",
      "tensor(183.6355, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "183.635498046875\n",
      "tensor(174.1633, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "174.163330078125\n",
      "tensor(184.8080, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "184.80804443359375\n",
      "tensor(195.5012, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "195.501220703125\n",
      "tensor(183.9670, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "183.967041015625\n",
      "tensor(179.4510, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "179.4510498046875\n",
      "tensor(177.8303, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "177.83026123046875\n",
      "tensor(180.6881, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "180.68809509277344\n",
      "tensor(181.0119, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "181.01187133789062\n",
      "tensor(176.0003, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "176.00027465820312\n",
      "tensor(173.7350, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "173.73495483398438\n",
      "tensor(181.6807, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "181.68069458007812\n",
      "tensor(180.2359, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "180.23590087890625\n",
      "tensor(176.5849, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "176.58494567871094\n",
      "tensor(177.1395, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "177.13946533203125\n",
      "tensor(191.1591, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "191.1590576171875\n",
      "tensor(177.9224, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "177.92236328125\n",
      "tensor(176.7560, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "176.75595092773438\n",
      "tensor(183.8767, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "183.87672424316406\n",
      "tensor(178.9083, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "178.90830993652344\n",
      "tensor(182.5152, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "182.51516723632812\n",
      "tensor(185.0254, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "185.025390625\n",
      "tensor(184.2885, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "184.28848266601562\n",
      "tensor(198.3928, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "198.392822265625\n",
      "tensor(180.8400, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "180.8400421142578\n",
      "tensor(184.5839, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "184.5838623046875\n",
      "tensor(186.5860, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "186.58596801757812\n",
      "tensor(174.7912, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "174.79116821289062\n",
      "tensor(176.1675, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "176.16754150390625\n",
      "tensor(186.8623, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "186.86231994628906\n",
      "tensor(177.2456, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "177.24557495117188\n",
      "tensor(181.6910, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "181.69097900390625\n",
      "tensor(189.1679, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "189.16790771484375\n",
      "tensor(179.3777, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "179.3777313232422\n",
      "tensor(177.8857, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "177.88565063476562\n",
      "tensor(185.0512, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "185.05123901367188\n",
      "tensor(179.9974, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "179.99740600585938\n",
      "tensor(178.4510, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "178.45101928710938\n",
      "tensor(176.4748, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "176.47482299804688\n",
      "tensor(177.7109, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "177.71090698242188\n",
      "tensor(187.5158, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "187.5157928466797\n",
      "tensor(192.6893, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "192.68930053710938\n",
      "tensor(186.5580, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "186.5579833984375\n",
      "tensor(183.9724, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "183.97244262695312\n",
      "tensor(175.9937, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "175.99374389648438\n",
      "tensor(185.0915, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "185.09152221679688\n",
      "tensor(180.5604, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "180.56039428710938\n",
      "tensor(176.8500, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "176.84999084472656\n",
      "tensor(182.9653, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "182.96534729003906\n",
      "tensor(176.6307, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "176.63070678710938\n",
      "tensor(185.1764, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "185.17637634277344\n",
      "tensor(190.8691, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "190.869140625\n",
      "tensor(179.5580, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "179.5580291748047\n",
      "tensor(177.5090, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "177.50897216796875\n",
      "tensor(179.5650, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "179.56500244140625\n",
      "tensor(192.9316, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "192.9315948486328\n",
      "tensor(182.7737, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "182.7737274169922\n",
      "tensor(190.6030, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "190.6029815673828\n",
      "tensor(184.1293, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "184.1293182373047\n",
      "tensor(170.3642, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "170.36422729492188\n",
      "tensor(189.3337, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "189.333740234375\n",
      "tensor(182.7684, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "182.7684326171875\n",
      "tensor(180.1870, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "180.18704223632812\n",
      "tensor(177.7050, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "177.70498657226562\n",
      "tensor(177.5059, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "177.50588989257812\n",
      "tensor(181.5287, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "181.52874755859375\n",
      "tensor(175.2126, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "175.21261596679688\n",
      "tensor(189.2939, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "189.2939453125\n",
      "tensor(179.2820, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "179.28201293945312\n",
      "tensor(191.5689, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "191.5689239501953\n",
      "tensor(174.7420, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "174.74203491210938\n",
      "tensor(174.0033, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "174.00328063964844\n",
      "tensor(177.3685, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "177.36846923828125\n",
      "tensor(176.6674, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "176.66741943359375\n",
      "tensor(180.7750, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "180.7750244140625\n",
      "tensor(178.1480, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "178.14804077148438\n",
      "tensor(173.3079, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "173.30789184570312\n",
      "tensor(178.1213, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "178.121337890625\n",
      "tensor(192.7751, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "192.775146484375\n",
      "tensor(183.0428, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "183.04278564453125\n",
      "tensor(192.1846, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "192.18463134765625\n",
      "tensor(183.2841, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "183.2841033935547\n",
      "tensor(176.0098, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "176.009765625\n",
      "tensor(175.4413, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "175.4412841796875\n",
      "tensor(186.3793, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "186.3792724609375\n",
      "tensor(181.5813, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "181.58126831054688\n",
      "tensor(181.1984, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "181.19842529296875\n",
      "tensor(178.4005, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "178.4005126953125\n",
      "tensor(177.1513, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "177.15133666992188\n",
      "tensor(170.0145, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "170.0144805908203\n",
      "tensor(183.7251, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "183.7251434326172\n",
      "tensor(188.5608, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "188.56076049804688\n",
      "tensor(179.4736, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "179.47357177734375\n",
      "tensor(171.2281, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "171.22805786132812\n",
      "tensor(175.4914, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "175.49143981933594\n",
      "tensor(182.3904, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "182.39036560058594\n",
      "tensor(179.6573, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "179.6573028564453\n",
      "tensor(170.6917, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "170.691650390625\n",
      "tensor(193.4506, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "193.4505615234375\n",
      "tensor(175.7134, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "175.71337890625\n",
      "tensor(178.4713, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "178.47132873535156\n",
      "tensor(193.2759, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "193.27593994140625\n",
      "tensor(183.4738, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "183.4738006591797\n",
      "tensor(177.6909, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "177.69085693359375\n",
      "tensor(181.4673, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "181.46730041503906\n",
      "tensor(173.5431, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "173.5430908203125\n",
      "tensor(188.5585, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "188.55850219726562\n",
      "tensor(181.5842, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "181.5841827392578\n",
      "tensor(172.0619, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "172.0618896484375\n",
      "tensor(190.6989, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "190.69894409179688\n",
      "tensor(182.4771, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "182.47705078125\n",
      "tensor(185.6791, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "185.6790771484375\n",
      "tensor(190.3268, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "190.32684326171875\n",
      "tensor(178.8606, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "178.860595703125\n",
      "tensor(175.6126, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "175.61256408691406\n",
      "tensor(182.3688, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "182.36880493164062\n",
      "tensor(183.5161, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "183.51608276367188\n",
      "tensor(186.1110, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "186.11099243164062\n",
      "tensor(191.4398, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "191.43975830078125\n",
      "tensor(186.7261, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "186.72610473632812\n",
      "tensor(187.6422, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "187.64218139648438\n",
      "tensor(181.9510, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "181.95098876953125\n",
      "tensor(184.1801, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "184.1800537109375\n",
      "tensor(182.8644, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "182.86444091796875\n",
      "tensor(184.8141, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "184.8140869140625\n",
      "tensor(171.6612, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "171.66116333007812\n",
      "tensor(178.3624, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "178.3623809814453\n",
      "tensor(174.0078, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "174.00784301757812\n",
      "tensor(183.2437, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "183.24365234375\n",
      "tensor(173.5696, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "173.56961059570312\n",
      "tensor(169.4913, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "169.4913330078125\n",
      "tensor(179.1479, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "179.14794921875\n",
      "tensor(170.6364, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "170.63641357421875\n",
      "tensor(179.2629, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "179.26290893554688\n",
      "tensor(177.3568, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "177.35684204101562\n",
      "tensor(174.5215, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "174.521484375\n",
      "tensor(188.4603, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "188.46031188964844\n",
      "tensor(179.7887, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "179.78866577148438\n",
      "tensor(182.5833, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "182.58334350585938\n",
      "tensor(181.2280, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "181.22804260253906\n",
      "tensor(199.4959, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "199.49594116210938\n",
      "tensor(179.4073, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "179.40733337402344\n",
      "tensor(171.3091, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "171.30908203125\n",
      "tensor(185.5898, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "185.58984375\n",
      "tensor(187.7458, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "187.7458038330078\n",
      "tensor(174.7110, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "174.71099853515625\n",
      "tensor(177.4298, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "177.4298095703125\n",
      "tensor(183.1718, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "183.17178344726562\n",
      "tensor(177.6488, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "177.6487579345703\n",
      "tensor(181.4728, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "181.47280883789062\n",
      "tensor(191.9256, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "191.9255828857422\n",
      "tensor(185.3690, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "185.3690185546875\n",
      "tensor(177.4598, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "177.45977783203125\n",
      "tensor(183.1471, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "183.14712524414062\n",
      "tensor(182.5933, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "182.59327697753906\n",
      "tensor(175.3537, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "175.35366821289062\n",
      "tensor(182.2592, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "182.25918579101562\n",
      "tensor(179.6816, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "179.68157958984375\n",
      "tensor(178.1104, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "178.11044311523438\n",
      "tensor(191.3722, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "191.37216186523438\n",
      "tensor(181.2226, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "181.22264099121094\n",
      "tensor(177.1506, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "177.15057373046875\n",
      "tensor(185.6289, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "185.62893676757812\n",
      "tensor(173.3873, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "173.38729858398438\n",
      "tensor(174.9962, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "174.99620056152344\n",
      "tensor(175.6599, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "175.65988159179688\n",
      "tensor(182.1633, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "182.163330078125\n",
      "tensor(184.2301, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "184.23013305664062\n",
      "tensor(178.5576, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "178.55764770507812\n",
      "tensor(186.4384, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "186.4384307861328\n",
      "tensor(169.5288, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "169.52883911132812\n",
      "tensor(184.4786, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "184.47857666015625\n",
      "tensor(178.7590, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "178.7589874267578\n",
      "tensor(173.6795, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "173.67947387695312\n",
      "tensor(176.8146, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "176.81463623046875\n",
      "tensor(183.8252, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "183.8251953125\n",
      "tensor(173.2246, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "173.2245635986328\n",
      "tensor(174.4092, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "174.40921020507812\n",
      "tensor(176.1744, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "176.17440795898438\n",
      "tensor(179.3556, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "179.3555908203125\n",
      "tensor(176.2566, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "176.256591796875\n",
      "tensor(180.8553, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "180.85528564453125\n",
      "tensor(177.0442, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "177.04415893554688\n",
      "tensor(182.2623, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "182.26229858398438\n",
      "tensor(179.5271, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "179.527099609375\n",
      "tensor(174.2094, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "174.20938110351562\n",
      "tensor(175.2723, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "175.2722625732422\n",
      "tensor(171.7146, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "171.71463012695312\n",
      "tensor(177.5785, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "177.5784912109375\n",
      "tensor(179.2517, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "179.2516632080078\n",
      "tensor(187.9353, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "187.93531799316406\n",
      "tensor(199.1204, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "199.1204376220703\n",
      "tensor(184.9810, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "184.98098754882812\n",
      "tensor(172.1398, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "172.13975524902344\n",
      "tensor(187.5374, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "187.5373992919922\n",
      "tensor(186.7767, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "186.77670288085938\n",
      "tensor(176.7332, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "176.733154296875\n",
      "tensor(179.3224, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "179.32240295410156\n",
      "tensor(177.6228, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "177.62281799316406\n",
      "tensor(176.7605, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "176.7605438232422\n",
      "tensor(171.4672, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "171.46719360351562\n",
      "tensor(176.3020, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "176.302001953125\n",
      "tensor(177.9753, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "177.97528076171875\n",
      "tensor(182.4651, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "182.46514892578125\n",
      "tensor(177.0387, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "177.03868103027344\n",
      "tensor(193.0651, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "193.0651092529297\n",
      "tensor(187.7990, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "187.7989501953125\n",
      "tensor(200.5221, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "200.5220947265625\n",
      "tensor(183.0443, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "183.04434204101562\n",
      "tensor(188.3439, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "188.34393310546875\n",
      "tensor(173.9727, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "173.97271728515625\n",
      "tensor(176.2036, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "176.20359802246094\n",
      "tensor(178.3279, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "178.32791137695312\n",
      "tensor(182.2417, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "182.24169921875\n",
      "tensor(186.0211, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "186.02113342285156\n",
      "tensor(185.9050, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "185.90499877929688\n",
      "tensor(178.7981, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "178.79808044433594\n",
      "tensor(180.9754, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "180.97544860839844\n",
      "tensor(181.9227, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "181.92266845703125\n",
      "tensor(180.7264, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "180.7264404296875\n",
      "tensor(176.0994, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "176.09942626953125\n",
      "tensor(178.2001, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "178.20010375976562\n",
      "tensor(181.7312, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "181.731201171875\n",
      "tensor(188.4414, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "188.4413604736328\n",
      "tensor(171.8330, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "171.83299255371094\n",
      "tensor(192.7768, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "192.77679443359375\n",
      "tensor(169.1861, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "169.18609619140625\n",
      "tensor(176.5148, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "176.51480102539062\n",
      "tensor(175.6689, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "175.6689453125\n",
      "tensor(181.5306, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "181.53057861328125\n",
      "tensor(192.5985, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "192.59848022460938\n",
      "tensor(180.1353, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "180.13525390625\n",
      "tensor(178.4480, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "178.44796752929688\n",
      "tensor(181.5117, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "181.51174926757812\n",
      "tensor(182.3675, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "182.3675079345703\n",
      "tensor(186.4903, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "186.4902801513672\n",
      "tensor(187.9037, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "187.9036865234375\n",
      "tensor(168.5014, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "168.5014190673828\n",
      "tensor(171.6168, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "171.61679077148438\n",
      "tensor(178.9105, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "178.91046142578125\n",
      "tensor(185.4462, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "185.44619750976562\n",
      "tensor(182.9976, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "182.99757385253906\n",
      "tensor(181.2026, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "181.20260620117188\n",
      "tensor(189.7149, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "189.71487426757812\n",
      "tensor(180.0868, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "180.08680725097656\n",
      "tensor(183.1236, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "183.12364196777344\n",
      "tensor(180.9545, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "180.95448303222656\n",
      "tensor(171.5739, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "171.5738983154297\n",
      "tensor(175.9071, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "175.90711975097656\n",
      "tensor(188.7958, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "188.7957763671875\n",
      "tensor(185.8640, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "185.86398315429688\n",
      "tensor(189.7148, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "189.71475219726562\n",
      "tensor(174.7243, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "174.72430419921875\n",
      "tensor(168.8021, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "168.8021240234375\n",
      "tensor(181.3432, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "181.34317016601562\n",
      "tensor(177.3567, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "177.3567352294922\n",
      "tensor(176.3778, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "176.37779235839844\n",
      "tensor(175.7064, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "175.70639038085938\n",
      "tensor(173.3122, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "173.31216430664062\n",
      "tensor(180.2499, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "180.24993896484375\n",
      "tensor(168.9872, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "168.98715209960938\n",
      "tensor(190.4379, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "190.4378662109375\n",
      "tensor(179.4586, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "179.4586181640625\n",
      "tensor(172.0350, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "172.0349578857422\n",
      "tensor(178.9997, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "178.99972534179688\n",
      "tensor(175.7017, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "175.70166015625\n",
      "tensor(174.3108, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "174.3108367919922\n",
      "tensor(179.4759, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "179.47589111328125\n",
      "tensor(176.7700, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "176.77001953125\n",
      "tensor(180.5459, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "180.5459442138672\n",
      "tensor(177.8974, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "177.89743041992188\n",
      "tensor(185.1703, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "185.17025756835938\n",
      "tensor(169.6882, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "169.68817138671875\n",
      "tensor(183.0610, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "183.06100463867188\n",
      "tensor(179.2817, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "179.28172302246094\n",
      "tensor(170.9649, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "170.96493530273438\n",
      "tensor(187.5668, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "187.5668487548828\n",
      "tensor(173.7923, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "173.79226684570312\n",
      "tensor(182.3847, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "182.38470458984375\n",
      "tensor(174.2693, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "174.26931762695312\n",
      "tensor(180.9315, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "180.9314727783203\n",
      "tensor(179.8132, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "179.813232421875\n",
      "tensor(180.8670, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "180.8670196533203\n",
      "tensor(193.2063, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "193.20626831054688\n",
      "tensor(178.6082, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "178.6082000732422\n",
      "tensor(180.1741, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "180.17410278320312\n",
      "tensor(173.2769, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "173.27687072753906\n",
      "tensor(177.7624, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "177.76242065429688\n",
      "tensor(175.6536, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "175.653564453125\n",
      "tensor(181.3630, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "181.36297607421875\n",
      "tensor(177.1049, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "177.10488891601562\n",
      "tensor(170.3866, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "170.38662719726562\n",
      "tensor(176.6454, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "176.64544677734375\n",
      "tensor(171.2776, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "171.27755737304688\n",
      "tensor(173.9055, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "173.90548706054688\n",
      "tensor(175.0307, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "175.03070068359375\n",
      "tensor(188.8082, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "188.8081512451172\n",
      "tensor(172.9307, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "172.93072509765625\n",
      "tensor(168.3802, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "168.38015747070312\n",
      "tensor(175.6545, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "175.65447998046875\n",
      "tensor(164.5390, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "164.53900146484375\n",
      "tensor(178.6704, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "178.67041015625\n",
      "tensor(168.0601, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "168.06011962890625\n",
      "tensor(174.6193, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "174.61932373046875\n",
      "tensor(176.3426, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "176.34262084960938\n",
      "tensor(183.0683, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "183.06826782226562\n",
      "tensor(180.2777, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "180.27774047851562\n",
      "tensor(177.7741, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "177.7741241455078\n",
      "tensor(166.1261, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "166.12606811523438\n",
      "tensor(178.7359, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "178.7359161376953\n",
      "tensor(194.8471, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "194.84713745117188\n",
      "tensor(184.7681, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "184.76806640625\n",
      "tensor(178.3227, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "178.3226776123047\n",
      "tensor(185.0540, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "185.053955078125\n",
      "tensor(179.3415, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "179.34153747558594\n",
      "tensor(182.2585, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "182.258544921875\n",
      "tensor(173.3978, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "173.39779663085938\n",
      "tensor(169.1719, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "169.17190551757812\n",
      "tensor(201.3603, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "201.36026000976562\n",
      "tensor(167.0543, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "167.0543212890625\n",
      "tensor(170.0428, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "170.0428466796875\n",
      "tensor(172.8799, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "172.87991333007812\n",
      "tensor(172.4499, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "172.44992065429688\n",
      "tensor(180.4214, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "180.4214324951172\n",
      "tensor(168.0860, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "168.08599853515625\n",
      "tensor(181.0824, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "181.0823974609375\n",
      "tensor(177.6258, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "177.62583923339844\n",
      "tensor(172.5568, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "172.55679321289062\n",
      "tensor(188.7005, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "188.70050048828125\n",
      "tensor(179.9935, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "179.9934844970703\n",
      "tensor(170.2419, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "170.24188232421875\n",
      "tensor(186.6494, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "186.64938354492188\n",
      "tensor(181.1552, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "181.1552276611328\n",
      "tensor(178.9428, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "178.94277954101562\n",
      "tensor(175.6386, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "175.63864135742188\n",
      "tensor(172.1879, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "172.18792724609375\n",
      "tensor(163.9871, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "163.9871063232422\n",
      "tensor(239.7447, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "239.74465942382812\n",
      "tensor(169.0286, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "169.0286407470703\n",
      "tensor(175.4135, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "175.4134521484375\n",
      "tensor(183.5179, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "183.51785278320312\n",
      "tensor(188.0329, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "188.0328826904297\n",
      "tensor(181.3651, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "181.36505126953125\n",
      "tensor(184.5470, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "184.5470428466797\n",
      "tensor(173.6679, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "173.66793823242188\n",
      "tensor(175.3286, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "175.32862854003906\n",
      "tensor(173.6688, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "173.6688232421875\n",
      "tensor(176.3242, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "176.32415771484375\n",
      "tensor(173.7124, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "173.71243286132812\n",
      "tensor(170.5363, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "170.53631591796875\n",
      "tensor(185.6805, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "185.68045043945312\n",
      "tensor(169.2162, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "169.21615600585938\n",
      "tensor(176.5161, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "176.51605224609375\n",
      "tensor(175.7248, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "175.72479248046875\n",
      "tensor(169.6650, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "169.6649932861328\n",
      "tensor(179.4900, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "179.48995971679688\n",
      "tensor(171.7933, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "171.7933349609375\n",
      "tensor(183.4525, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "183.45254516601562\n",
      "tensor(175.2279, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "175.2278594970703\n",
      "tensor(191.8624, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "191.8623809814453\n",
      "tensor(170.1230, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "170.12295532226562\n",
      "tensor(182.3007, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "182.3007354736328\n",
      "tensor(178.5173, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "178.517333984375\n",
      "tensor(169.7207, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "169.72067260742188\n",
      "tensor(182.5702, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "182.57020568847656\n",
      "tensor(174.1715, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "174.17149353027344\n",
      "tensor(191.3804, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "191.3804473876953\n",
      "tensor(173.9779, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "173.9779052734375\n",
      "tensor(179.9452, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "179.9451904296875\n",
      "tensor(173.9240, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "173.92398071289062\n",
      "tensor(181.7267, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "181.72674560546875\n",
      "tensor(175.3211, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "175.32107543945312\n",
      "tensor(173.7787, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "173.77874755859375\n",
      "tensor(176.8623, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "176.86227416992188\n",
      "tensor(189.1081, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "189.1081085205078\n",
      "tensor(173.8197, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "173.81967163085938\n",
      "tensor(169.1932, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "169.19322204589844\n",
      "tensor(174.2780, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "174.27804565429688\n",
      "tensor(172.5096, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "172.50958251953125\n",
      "tensor(171.7317, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "171.73171997070312\n",
      "tensor(173.8876, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "173.88755798339844\n",
      "tensor(179.3044, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "179.30438232421875\n",
      "tensor(166.8822, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "166.88217163085938\n",
      "tensor(184.6600, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "184.6599578857422\n",
      "tensor(178.0906, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "178.09060668945312\n",
      "tensor(177.2533, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "177.2532501220703\n",
      "tensor(178.3686, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "178.36856079101562\n",
      "tensor(169.8181, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "169.818115234375\n",
      "tensor(169.8140, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "169.81399536132812\n",
      "tensor(183.4774, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "183.4774169921875\n",
      "tensor(178.0048, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "178.00479125976562\n",
      "tensor(169.1749, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "169.17489624023438\n",
      "tensor(180.3519, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "180.35191345214844\n",
      "tensor(172.0049, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "172.0048828125\n",
      "tensor(173.9999, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "173.99990844726562\n",
      "tensor(170.0645, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "170.064453125\n",
      "tensor(180.4767, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "180.47674560546875\n",
      "tensor(177.4281, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "177.42813110351562\n",
      "tensor(165.1111, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "165.11109924316406\n",
      "tensor(172.0544, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "172.05441284179688\n",
      "tensor(173.0715, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "173.07150268554688\n",
      "tensor(176.9534, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "176.953369140625\n",
      "tensor(185.5357, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "185.53567504882812\n",
      "tensor(188.6360, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "188.63601684570312\n",
      "tensor(184.4324, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "184.43235778808594\n",
      "tensor(176.9325, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "176.93247985839844\n",
      "tensor(182.3660, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "182.36599731445312\n",
      "tensor(191.8388, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "191.83877563476562\n",
      "tensor(173.8606, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "173.86056518554688\n",
      "tensor(179.8875, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "179.88754272460938\n",
      "tensor(167.3829, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "167.38290405273438\n",
      "tensor(176.3997, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "176.399658203125\n",
      "tensor(184.8895, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "184.8894500732422\n",
      "tensor(175.5041, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "175.50408935546875\n",
      "tensor(187.0861, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "187.0860595703125\n",
      "tensor(176.6197, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "176.61968994140625\n",
      "tensor(165.3274, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "165.32737731933594\n",
      "tensor(165.2048, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "165.20480346679688\n",
      "tensor(171.1799, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "171.179931640625\n",
      "tensor(178.4018, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "178.40182495117188\n",
      "tensor(169.8125, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "169.8125\n",
      "tensor(173.2894, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "173.28936767578125\n",
      "tensor(188.0990, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "188.0989532470703\n",
      "tensor(174.1496, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "174.14959716796875\n",
      "tensor(176.8562, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "176.85617065429688\n",
      "tensor(175.4873, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "175.48727416992188\n",
      "tensor(176.3271, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "176.32708740234375\n",
      "tensor(175.9845, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "175.98451232910156\n",
      "tensor(171.3957, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "171.39573669433594\n",
      "tensor(172.7644, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "172.764404296875\n",
      "tensor(180.4070, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "180.40696716308594\n",
      "tensor(165.3129, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "165.3128662109375\n",
      "tensor(166.4966, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "166.49658203125\n",
      "tensor(167.3028, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "167.30276489257812\n",
      "tensor(181.1388, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "181.13882446289062\n",
      "tensor(176.8979, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "176.89788818359375\n",
      "tensor(165.5881, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "165.58807373046875\n",
      "tensor(176.2812, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "176.28121948242188\n",
      "tensor(168.5371, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "168.53707885742188\n",
      "tensor(203.2248, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "203.2247772216797\n",
      "tensor(172.7225, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "172.72251892089844\n",
      "tensor(172.6841, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "172.68408203125\n",
      "tensor(172.1633, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "172.16329956054688\n",
      "tensor(182.5757, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "182.57569885253906\n",
      "tensor(182.3780, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "182.3779754638672\n",
      "tensor(181.9853, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "181.98529052734375\n",
      "tensor(203.9965, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "203.99652099609375\n",
      "tensor(178.5691, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "178.569091796875\n",
      "tensor(184.5439, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "184.54388427734375\n",
      "tensor(177.9023, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "177.90234375\n",
      "tensor(167.2236, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "167.22360229492188\n",
      "tensor(183.4581, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "183.4581298828125\n",
      "tensor(176.7746, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "176.77455139160156\n",
      "tensor(171.3045, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "171.30453491210938\n",
      "tensor(175.2244, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "175.22439575195312\n",
      "tensor(172.3147, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "172.31472778320312\n",
      "tensor(170.5119, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "170.5119171142578\n",
      "tensor(170.6206, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "170.62057495117188\n",
      "tensor(188.7520, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "188.7519989013672\n",
      "tensor(182.9634, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "182.9634246826172\n",
      "tensor(173.9904, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "173.99041748046875\n",
      "tensor(179.6501, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "179.65008544921875\n",
      "tensor(189.8669, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "189.866943359375\n",
      "tensor(176.5387, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "176.53871154785156\n",
      "tensor(178.2846, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "178.28463745117188\n",
      "tensor(169.7887, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "169.78872680664062\n",
      "tensor(169.9111, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "169.91107177734375\n",
      "tensor(177.5112, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "177.5111846923828\n",
      "tensor(179.6901, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "179.69009399414062\n",
      "tensor(173.8533, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "173.85325622558594\n",
      "tensor(172.4095, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "172.4095001220703\n",
      "tensor(168.7550, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "168.75497436523438\n",
      "tensor(170.9387, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "170.93869018554688\n",
      "tensor(173.7663, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "173.7662811279297\n",
      "tensor(170.5164, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "170.5164031982422\n",
      "tensor(189.4886, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "189.4886016845703\n",
      "tensor(170.6028, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "170.60275268554688\n",
      "tensor(175.2025, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "175.2025146484375\n",
      "tensor(168.0907, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "168.09068298339844\n",
      "tensor(180.0143, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "180.01429748535156\n",
      "tensor(174.6563, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "174.65634155273438\n",
      "tensor(173.9237, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "173.92367553710938\n",
      "tensor(178.2928, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "178.2928009033203\n",
      "tensor(184.0244, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "184.02438354492188\n",
      "tensor(179.1106, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "179.11062622070312\n",
      "tensor(173.5984, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "173.5984344482422\n",
      "tensor(190.7639, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "190.76388549804688\n",
      "tensor(181.3310, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "181.33096313476562\n",
      "tensor(177.6818, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "177.68182373046875\n",
      "tensor(167.6906, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "167.6905975341797\n",
      "tensor(176.3864, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "176.38644409179688\n",
      "tensor(175.3971, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "175.39712524414062\n",
      "tensor(180.0049, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "180.00491333007812\n",
      "tensor(178.7904, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "178.79037475585938\n",
      "tensor(177.8608, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "177.8607635498047\n",
      "tensor(174.4465, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "174.44651794433594\n",
      "tensor(196.0172, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "196.01724243164062\n",
      "tensor(174.4647, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "174.46470642089844\n",
      "tensor(178.2405, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "178.24050903320312\n",
      "tensor(173.1109, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "173.11090087890625\n",
      "tensor(172.0637, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "172.063720703125\n",
      "tensor(184.2517, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "184.251708984375\n",
      "tensor(171.8114, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "171.8114013671875\n",
      "tensor(180.7683, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "180.768310546875\n",
      "tensor(175.1690, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "175.1690216064453\n",
      "tensor(174.1862, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "174.1861572265625\n",
      "tensor(178.2235, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "178.22348022460938\n",
      "tensor(174.8270, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "174.8269805908203\n",
      "tensor(174.5426, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "174.54258728027344\n",
      "tensor(183.0158, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "183.01580810546875\n",
      "tensor(190.0397, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "190.03973388671875\n",
      "tensor(172.1983, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "172.1982879638672\n",
      "tensor(168.0404, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "168.0404052734375\n",
      "tensor(180.7825, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "180.78253173828125\n",
      "tensor(184.4533, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "184.45333862304688\n",
      "tensor(175.6461, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "175.64614868164062\n",
      "tensor(169.1310, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "169.13095092773438\n",
      "tensor(170.8335, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "170.8334503173828\n",
      "tensor(174.6345, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "174.63453674316406\n",
      "tensor(171.3325, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "171.33251953125\n",
      "tensor(172.3438, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "172.3438262939453\n",
      "tensor(170.1780, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "170.177978515625\n",
      "tensor(175.5356, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "175.5355987548828\n",
      "tensor(172.0611, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "172.06106567382812\n",
      "tensor(165.3230, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "165.3229522705078\n",
      "tensor(165.7894, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "165.78939819335938\n",
      "tensor(171.4249, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "171.4249267578125\n",
      "tensor(165.4028, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "165.40283203125\n",
      "tensor(173.2825, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "173.28245544433594\n",
      "tensor(180.7855, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "180.78546142578125\n",
      "tensor(191.9257, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "191.9256591796875\n",
      "tensor(170.7955, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "170.79550170898438\n",
      "tensor(176.6866, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "176.68658447265625\n",
      "tensor(189.4052, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "189.40524291992188\n",
      "tensor(176.0354, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "176.0354461669922\n",
      "tensor(172.4088, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "172.40884399414062\n",
      "tensor(170.9403, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "170.94032287597656\n",
      "tensor(176.2359, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "176.23590087890625\n",
      "tensor(185.4671, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "185.4670867919922\n",
      "tensor(180.5989, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "180.5989227294922\n",
      "tensor(176.9774, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "176.97744750976562\n",
      "tensor(175.8806, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "175.88063049316406\n",
      "tensor(174.2978, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "174.29776000976562\n",
      "tensor(176.1799, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "176.1798858642578\n",
      "tensor(182.5138, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "182.51380920410156\n",
      "tensor(167.7517, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "167.75173950195312\n",
      "tensor(165.7678, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "165.76780700683594\n",
      "tensor(177.3964, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "177.3963623046875\n",
      "tensor(179.0523, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "179.0522918701172\n",
      "tensor(177.0002, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "177.000244140625\n",
      "tensor(161.3106, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "161.31060791015625\n",
      "tensor(179.0090, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "179.009033203125\n",
      "tensor(172.5612, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "172.56124877929688\n",
      "tensor(170.6372, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "170.63722229003906\n",
      "tensor(185.3813, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "185.38134765625\n",
      "tensor(171.6250, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "171.6250457763672\n",
      "tensor(174.6799, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "174.6798858642578\n",
      "tensor(167.6138, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "167.61383056640625\n",
      "tensor(170.9924, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "170.99237060546875\n",
      "tensor(182.8282, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "182.82815551757812\n",
      "tensor(168.7549, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "168.75491333007812\n",
      "tensor(173.5907, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "173.59066772460938\n",
      "tensor(180.3618, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "180.36184692382812\n",
      "tensor(173.4746, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "173.47462463378906\n",
      "tensor(172.8542, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "172.85421752929688\n",
      "tensor(169.5888, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "169.58880615234375\n",
      "tensor(180.4821, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "180.48211669921875\n",
      "tensor(169.2099, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "169.20994567871094\n",
      "tensor(172.7933, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "172.7932586669922\n",
      "tensor(177.5712, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "177.5712432861328\n",
      "tensor(173.7993, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "173.79934692382812\n",
      "tensor(164.6970, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "164.69700622558594\n",
      "tensor(173.0216, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "173.02157592773438\n",
      "tensor(180.0167, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "180.01666259765625\n",
      "tensor(164.4163, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "164.41627502441406\n",
      "tensor(171.5292, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "171.5291748046875\n",
      "tensor(175.8390, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "175.8390350341797\n",
      "tensor(187.3433, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "187.3433380126953\n",
      "tensor(175.6005, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "175.60049438476562\n",
      "tensor(185.4963, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "185.49627685546875\n",
      "tensor(163.4187, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "163.41873168945312\n",
      "tensor(177.4163, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "177.41632080078125\n",
      "tensor(171.3397, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "171.33969116210938\n",
      "tensor(173.4348, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "173.43478393554688\n",
      "tensor(170.1650, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "170.16497802734375\n",
      "tensor(174.0908, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "174.09075927734375\n",
      "tensor(177.9740, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "177.97402954101562\n",
      "tensor(179.5577, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "179.55767822265625\n",
      "tensor(183.6165, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "183.61648559570312\n",
      "tensor(178.6267, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "178.62669372558594\n",
      "tensor(169.4537, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "169.45367431640625\n",
      "tensor(171.1416, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "171.14158630371094\n",
      "tensor(174.6744, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "174.67437744140625\n",
      "tensor(171.2879, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "171.28790283203125\n",
      "tensor(170.9636, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "170.96356201171875\n",
      "tensor(168.7679, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "168.76792907714844\n",
      "tensor(179.9904, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "179.99041748046875\n",
      "tensor(170.3266, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "170.32662963867188\n",
      "tensor(179.4527, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "179.4526824951172\n",
      "tensor(169.4399, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "169.43994140625\n",
      "tensor(171.0116, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "171.0115509033203\n",
      "tensor(180.9725, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "180.97250366210938\n",
      "tensor(172.7426, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "172.7425537109375\n",
      "tensor(176.4220, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "176.42202758789062\n",
      "tensor(169.0973, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "169.09732055664062\n",
      "tensor(169.2717, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "169.27166748046875\n",
      "tensor(167.7085, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "167.70846557617188\n",
      "tensor(174.9655, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "174.9654541015625\n",
      "tensor(163.2836, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "163.28363037109375\n",
      "tensor(163.3362, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "163.33624267578125\n",
      "tensor(170.5735, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "170.57345581054688\n",
      "tensor(173.1125, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "173.11248779296875\n",
      "tensor(167.8909, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "167.89089965820312\n",
      "tensor(177.1959, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "177.19586181640625\n",
      "tensor(176.5088, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "176.5087890625\n",
      "tensor(175.9940, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "175.99404907226562\n",
      "tensor(172.7540, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "172.75396728515625\n",
      "tensor(169.0930, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "169.09303283691406\n",
      "tensor(166.3603, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "166.3603057861328\n",
      "tensor(175.5983, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "175.5982666015625\n",
      "tensor(165.5835, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "165.5835418701172\n",
      "tensor(174.4231, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "174.42312622070312\n",
      "tensor(169.2655, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "169.2655029296875\n",
      "tensor(165.1946, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "165.19461059570312\n",
      "tensor(174.4079, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "174.40789794921875\n",
      "tensor(173.0203, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "173.020263671875\n",
      "tensor(176.2397, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "176.23973083496094\n",
      "tensor(167.7129, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "167.71286010742188\n",
      "tensor(161.8286, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "161.82862854003906\n",
      "tensor(241.6932, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "241.6932373046875\n",
      "tensor(172.8435, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "172.84347534179688\n",
      "tensor(168.5805, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "168.58053588867188\n",
      "tensor(173.7702, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "173.77017211914062\n",
      "tensor(176.9181, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "176.91806030273438\n",
      "tensor(180.8547, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "180.8546905517578\n",
      "tensor(181.6701, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "181.67013549804688\n",
      "tensor(183.1238, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "183.12380981445312\n",
      "tensor(179.8281, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "179.82809448242188\n",
      "tensor(179.1486, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "179.14862060546875\n",
      "tensor(170.0372, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "170.03721618652344\n",
      "tensor(176.1245, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "176.12451171875\n",
      "tensor(181.4679, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "181.46786499023438\n",
      "tensor(177.9402, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "177.94015502929688\n",
      "tensor(181.0094, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "181.0093994140625\n",
      "tensor(178.8133, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "178.81332397460938\n",
      "tensor(188.2964, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "188.29638671875\n",
      "tensor(171.6407, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "171.64065551757812\n",
      "tensor(171.0337, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "171.03367614746094\n",
      "tensor(176.4980, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "176.498046875\n",
      "tensor(179.6480, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "179.64804077148438\n",
      "tensor(174.8359, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "174.83590698242188\n",
      "tensor(179.6066, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "179.60658264160156\n",
      "tensor(173.3524, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "173.35235595703125\n",
      "tensor(177.2379, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "177.23788452148438\n",
      "tensor(166.7488, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "166.74880981445312\n",
      "tensor(175.5262, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "175.52621459960938\n",
      "tensor(179.4886, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "179.4886016845703\n",
      "tensor(163.5406, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "163.54055786132812\n",
      "tensor(172.4966, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "172.49661254882812\n",
      "tensor(186.5825, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "186.58253479003906\n",
      "tensor(179.6860, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "179.68597412109375\n",
      "tensor(172.8863, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "172.8863067626953\n",
      "tensor(169.5756, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "169.5756378173828\n",
      "tensor(179.8978, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "179.8978271484375\n",
      "tensor(177.8261, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "177.82606506347656\n",
      "tensor(188.0308, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "188.03077697753906\n",
      "tensor(176.5818, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "176.58175659179688\n",
      "tensor(165.0547, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "165.0546875\n",
      "tensor(177.1596, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "177.15956115722656\n",
      "tensor(179.4508, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "179.45083618164062\n",
      "tensor(174.2029, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "174.20286560058594\n",
      "tensor(170.4268, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "170.42684936523438\n",
      "tensor(170.3187, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "170.31866455078125\n",
      "tensor(178.2622, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "178.26223754882812\n",
      "tensor(164.5714, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "164.57135009765625\n",
      "tensor(170.8521, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "170.85208129882812\n",
      "tensor(180.8072, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "180.80715942382812\n",
      "tensor(167.1777, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "167.177734375\n",
      "tensor(164.2461, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "164.24606323242188\n",
      "tensor(162.7628, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "162.76278686523438\n",
      "tensor(163.4902, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "163.490234375\n",
      "tensor(177.1949, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "177.1948699951172\n",
      "tensor(170.6822, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "170.68215942382812\n",
      "tensor(171.3371, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "171.33706665039062\n",
      "tensor(164.4163, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "164.41632080078125\n",
      "tensor(162.3150, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "162.3150177001953\n",
      "tensor(178.1447, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "178.14474487304688\n",
      "tensor(172.7955, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "172.79551696777344\n",
      "tensor(170.8641, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "170.8640594482422\n",
      "tensor(167.2517, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "167.2516632080078\n",
      "tensor(176.9313, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "176.93133544921875\n",
      "tensor(185.7743, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "185.7742919921875\n",
      "tensor(165.7053, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "165.70533752441406\n",
      "tensor(169.0280, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "169.0279541015625\n",
      "tensor(168.0590, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "168.0589599609375\n",
      "tensor(162.0680, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "162.06796264648438\n",
      "tensor(185.5958, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "185.5958251953125\n",
      "tensor(165.9190, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "165.91897583007812\n",
      "tensor(167.5303, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "167.5303497314453\n",
      "tensor(171.5458, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "171.54579162597656\n",
      "tensor(172.6641, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "172.66412353515625\n",
      "tensor(172.2776, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "172.27757263183594\n",
      "tensor(163.4113, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "163.41127014160156\n",
      "tensor(175.1474, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "175.1473846435547\n",
      "tensor(169.9891, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "169.98910522460938\n",
      "tensor(172.8302, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "172.8302001953125\n",
      "tensor(160.9795, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "160.9795379638672\n",
      "tensor(171.8371, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "171.83705139160156\n",
      "tensor(183.4572, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "183.45718383789062\n",
      "tensor(167.8035, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "167.80352783203125\n",
      "tensor(184.1126, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "184.11260986328125\n",
      "tensor(166.1104, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "166.11038208007812\n",
      "tensor(168.9717, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "168.9716796875\n",
      "tensor(169.6658, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "169.6658477783203\n",
      "tensor(175.3219, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "175.32188415527344\n",
      "tensor(173.6138, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "173.61376953125\n",
      "tensor(166.0296, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "166.02955627441406\n",
      "tensor(169.6968, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "169.69677734375\n",
      "tensor(164.6401, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "164.64013671875\n",
      "tensor(163.6248, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "163.62484741210938\n",
      "tensor(174.8246, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "174.82456970214844\n",
      "tensor(164.2185, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "164.21853637695312\n",
      "tensor(162.3362, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "162.33615112304688\n",
      "tensor(164.3532, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "164.35321044921875\n",
      "tensor(176.5706, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "176.570556640625\n",
      "tensor(165.9609, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "165.96090698242188\n",
      "tensor(162.6029, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "162.60289001464844\n",
      "tensor(170.4634, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "170.46336364746094\n",
      "tensor(175.4103, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "175.41033935546875\n",
      "tensor(174.2209, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "174.22085571289062\n",
      "tensor(175.2313, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "175.23133850097656\n",
      "tensor(172.7444, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "172.74435424804688\n",
      "tensor(171.4890, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "171.48904418945312\n",
      "tensor(168.0292, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "168.02923583984375\n",
      "tensor(169.3797, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "169.37969970703125\n",
      "tensor(170.3621, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "170.36212158203125\n",
      "tensor(163.3853, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "163.3853302001953\n",
      "tensor(174.9352, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "174.93521118164062\n",
      "tensor(172.6238, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "172.62384033203125\n",
      "tensor(167.8528, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "167.85284423828125\n",
      "tensor(166.9219, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "166.92185974121094\n",
      "tensor(172.0602, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "172.06015014648438\n",
      "tensor(165.9626, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "165.96255493164062\n",
      "tensor(162.5251, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "162.52511596679688\n",
      "tensor(186.7697, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "186.76974487304688\n",
      "tensor(165.7589, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "165.7589111328125\n",
      "tensor(167.2244, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "167.22438049316406\n",
      "tensor(170.3037, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "170.30374145507812\n",
      "tensor(176.4962, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "176.4962158203125\n",
      "tensor(172.3971, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "172.3971405029297\n",
      "tensor(172.7852, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "172.78517150878906\n",
      "tensor(172.5946, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "172.5946044921875\n",
      "tensor(161.9328, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "161.93284606933594\n",
      "tensor(166.4744, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "166.47438049316406\n",
      "tensor(159.6629, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "159.6628875732422\n",
      "tensor(184.2131, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "184.21310424804688\n",
      "tensor(177.6429, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "177.6429443359375\n",
      "tensor(166.8600, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "166.85995483398438\n",
      "tensor(159.8320, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "159.83200073242188\n",
      "tensor(165.5948, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "165.59475708007812\n",
      "tensor(166.9295, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "166.92950439453125\n",
      "tensor(192.0213, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "192.02134704589844\n",
      "tensor(172.6086, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "172.60858154296875\n",
      "tensor(163.8314, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "163.8314208984375\n",
      "tensor(174.3748, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "174.37484741210938\n",
      "tensor(168.4012, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "168.40115356445312\n",
      "tensor(168.0045, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "168.00454711914062\n",
      "tensor(184.5963, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "184.59634399414062\n",
      "tensor(170.8216, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "170.82156372070312\n",
      "tensor(168.8284, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "168.8284454345703\n",
      "tensor(183.5649, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "183.56494140625\n",
      "tensor(173.4094, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "173.4093780517578\n",
      "tensor(156.2812, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "156.28125\n",
      "tensor(174.1330, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "174.13296508789062\n",
      "tensor(170.3740, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "170.37400817871094\n",
      "tensor(161.1593, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "161.1592559814453\n",
      "tensor(178.2293, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "178.2293243408203\n",
      "tensor(169.5213, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "169.52127075195312\n",
      "tensor(169.1373, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "169.1372833251953\n",
      "tensor(171.1730, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "171.1730194091797\n",
      "tensor(166.4102, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "166.41018676757812\n",
      "tensor(159.9779, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "159.97787475585938\n",
      "tensor(177.2810, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "177.28097534179688\n",
      "tensor(165.4742, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "165.47418212890625\n",
      "tensor(170.6688, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "170.66876220703125\n",
      "tensor(172.5743, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "172.57431030273438\n",
      "tensor(174.2926, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "174.2926025390625\n",
      "tensor(190.0351, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "190.03509521484375\n",
      "tensor(164.4028, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "164.4027862548828\n",
      "tensor(174.4266, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "174.42657470703125\n",
      "tensor(163.5775, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "163.57749938964844\n",
      "tensor(167.2204, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "167.22036743164062\n",
      "tensor(166.3110, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "166.31097412109375\n",
      "tensor(176.2248, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "176.2247772216797\n",
      "tensor(167.8628, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "167.86279296875\n",
      "tensor(174.3387, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "174.3387451171875\n",
      "tensor(169.2657, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "169.26565551757812\n",
      "tensor(169.8350, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "169.8349609375\n",
      "tensor(176.8297, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "176.82965087890625\n",
      "tensor(165.4246, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "165.42459106445312\n",
      "tensor(172.9366, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "172.93663024902344\n",
      "tensor(155.9506, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "155.95059204101562\n",
      "tensor(173.7017, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "173.70167541503906\n",
      "tensor(164.8864, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "164.88644409179688\n",
      "tensor(191.0832, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "191.0832061767578\n",
      "tensor(182.2225, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "182.22254943847656\n",
      "tensor(171.4323, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "171.4322967529297\n",
      "tensor(179.9856, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "179.98561096191406\n",
      "tensor(173.6304, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "173.63040161132812\n",
      "tensor(161.6409, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "161.640869140625\n",
      "tensor(174.9948, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "174.99484252929688\n",
      "tensor(178.3467, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "178.3467254638672\n",
      "tensor(170.8664, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "170.86639404296875\n",
      "tensor(175.4654, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "175.46542358398438\n",
      "tensor(177.1256, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "177.12559509277344\n",
      "tensor(169.5650, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "169.56503295898438\n",
      "tensor(172.3004, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "172.30038452148438\n",
      "tensor(170.4617, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "170.46173095703125\n",
      "tensor(169.0341, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "169.03411865234375\n",
      "tensor(186.0190, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "186.01898193359375\n",
      "tensor(168.1090, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "168.1090087890625\n",
      "tensor(170.3607, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "170.36074829101562\n",
      "tensor(165.5420, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "165.5419921875\n",
      "tensor(165.1196, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "165.1195831298828\n",
      "tensor(174.6796, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "174.6795654296875\n",
      "tensor(180.6948, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "180.69476318359375\n",
      "tensor(180.7517, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "180.75167846679688\n",
      "tensor(175.9899, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "175.98985290527344\n",
      "tensor(159.5031, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "159.5030975341797\n",
      "tensor(164.7111, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "164.71109008789062\n",
      "tensor(173.2459, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "173.24591064453125\n",
      "tensor(174.9226, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "174.9225616455078\n",
      "tensor(166.6224, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "166.62237548828125\n",
      "tensor(167.5212, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "167.52117919921875\n",
      "tensor(166.5582, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "166.5582275390625\n",
      "tensor(168.3532, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "168.35316467285156\n",
      "tensor(178.8215, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "178.8214569091797\n",
      "tensor(167.9150, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "167.91497802734375\n",
      "tensor(176.1900, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "176.19000244140625\n",
      "tensor(184.6378, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "184.6377716064453\n",
      "tensor(171.8632, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "171.8632354736328\n",
      "tensor(169.9098, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "169.90982055664062\n",
      "tensor(173.6615, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "173.66146850585938\n",
      "tensor(169.1551, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "169.15505981445312\n",
      "tensor(184.8296, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "184.82962036132812\n",
      "tensor(168.8246, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "168.82461547851562\n",
      "tensor(170.5288, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "170.52882385253906\n",
      "tensor(179.4391, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "179.4391326904297\n",
      "tensor(174.9339, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "174.93392944335938\n",
      "tensor(188.5238, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "188.52378845214844\n",
      "tensor(171.2998, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "171.2998046875\n",
      "tensor(171.0120, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "171.01199340820312\n",
      "tensor(171.2755, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "171.27548217773438\n",
      "tensor(178.2442, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "178.24423217773438\n",
      "tensor(179.0747, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "179.07469177246094\n",
      "tensor(156.5734, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "156.57337951660156\n",
      "tensor(166.6736, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "166.67359924316406\n",
      "tensor(174.6291, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "174.62911987304688\n",
      "tensor(166.0961, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "166.0960693359375\n",
      "tensor(178.9772, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "178.97718811035156\n",
      "tensor(175.8644, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "175.86444091796875\n",
      "tensor(171.9711, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "171.9711456298828\n",
      "tensor(170.0341, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "170.03414916992188\n",
      "tensor(173.2577, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "173.25765991210938\n",
      "tensor(169.2005, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "169.20046997070312\n",
      "tensor(182.6230, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "182.62295532226562\n",
      "tensor(161.3191, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "161.31912231445312\n",
      "tensor(179.3283, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "179.32833862304688\n",
      "tensor(155.9575, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "155.95745849609375\n",
      "tensor(177.5237, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "177.52365112304688\n",
      "tensor(170.5003, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "170.5002899169922\n",
      "tensor(169.6258, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "169.62576293945312\n",
      "tensor(164.0335, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "164.03346252441406\n",
      "tensor(171.0266, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "171.026611328125\n",
      "tensor(167.4229, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "167.4229278564453\n",
      "tensor(165.2159, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "165.21585083007812\n",
      "tensor(176.8039, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "176.80392456054688\n",
      "tensor(189.8982, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "189.898193359375\n",
      "tensor(159.8958, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "159.89584350585938\n",
      "tensor(171.2346, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "171.23463439941406\n",
      "tensor(173.0677, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "173.06768798828125\n",
      "tensor(170.6488, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "170.6487579345703\n",
      "tensor(173.5784, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "173.57843017578125\n",
      "tensor(176.3051, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "176.30514526367188\n",
      "tensor(169.0436, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "169.04360961914062\n",
      "tensor(172.3150, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "172.31503295898438\n",
      "tensor(164.1263, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "164.1262969970703\n",
      "tensor(164.0058, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "164.00575256347656\n",
      "tensor(168.9832, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "168.98321533203125\n",
      "tensor(157.3964, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "157.39642333984375\n",
      "tensor(160.7324, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "160.73239135742188\n",
      "tensor(183.9602, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "183.96022033691406\n",
      "tensor(169.5828, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "169.58279418945312\n",
      "tensor(164.1616, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "164.16160583496094\n",
      "tensor(185.7405, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "185.74053955078125\n",
      "tensor(175.3106, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "175.31063842773438\n",
      "tensor(172.9646, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "172.96463012695312\n",
      "tensor(166.6331, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "166.63308715820312\n",
      "tensor(162.3170, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "162.31703186035156\n",
      "tensor(166.9357, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "166.9357452392578\n",
      "tensor(169.8510, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "169.85104370117188\n",
      "tensor(157.1678, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "157.16783142089844\n",
      "tensor(180.5885, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "180.58853149414062\n",
      "tensor(168.5516, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "168.55157470703125\n",
      "tensor(163.0430, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "163.0430145263672\n",
      "tensor(160.5408, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "160.54083251953125\n",
      "tensor(170.5953, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "170.59532165527344\n",
      "tensor(165.8469, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "165.84686279296875\n",
      "tensor(170.4389, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "170.43885803222656\n",
      "tensor(172.2946, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "172.2945556640625\n",
      "tensor(169.4773, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "169.4773406982422\n",
      "tensor(160.1610, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "160.16098022460938\n",
      "tensor(161.0438, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "161.04379272460938\n",
      "tensor(164.4915, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "164.49154663085938\n",
      "tensor(177.3520, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "177.35198974609375\n",
      "tensor(172.0248, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "172.02479553222656\n",
      "tensor(182.4592, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "182.45919799804688\n",
      "tensor(174.2519, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "174.25189208984375\n",
      "tensor(164.1576, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "164.15757751464844\n",
      "tensor(166.6592, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "166.6592254638672\n",
      "tensor(166.5454, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "166.5453643798828\n",
      "tensor(162.5440, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "162.54400634765625\n",
      "tensor(168.0739, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "168.07388305664062\n",
      "tensor(165.7966, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "165.79656982421875\n",
      "tensor(162.7896, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "162.78955078125\n",
      "tensor(167.5500, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "167.550048828125\n",
      "tensor(164.7506, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "164.75062561035156\n",
      "tensor(165.4195, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "165.41949462890625\n",
      "tensor(156.7706, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "156.7706298828125\n",
      "tensor(171.8196, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "171.81961059570312\n",
      "tensor(159.9752, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "159.97518920898438\n",
      "tensor(164.9567, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "164.95669555664062\n",
      "tensor(167.0737, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "167.07373046875\n",
      "tensor(177.1629, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "177.16293334960938\n",
      "tensor(170.4072, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "170.4072265625\n",
      "tensor(162.6835, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "162.68350219726562\n",
      "tensor(170.4318, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "170.4317626953125\n",
      "tensor(165.4204, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "165.42039489746094\n",
      "tensor(170.3264, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "170.32640075683594\n",
      "tensor(167.2445, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "167.2445068359375\n",
      "tensor(163.1382, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "163.13821411132812\n",
      "tensor(169.0817, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "169.0816650390625\n",
      "tensor(167.9760, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "167.97601318359375\n",
      "tensor(160.3600, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "160.35997009277344\n",
      "tensor(179.0547, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "179.05471801757812\n",
      "tensor(180.8463, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "180.8463134765625\n",
      "tensor(171.0295, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "171.0294952392578\n",
      "tensor(163.5680, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "163.5680389404297\n",
      "tensor(182.4246, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "182.4246063232422\n",
      "tensor(159.0759, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "159.0758514404297\n",
      "tensor(169.6178, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "169.6177520751953\n",
      "tensor(154.5555, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "154.5555419921875\n",
      "tensor(166.6423, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "166.64227294921875\n",
      "tensor(169.0702, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "169.0701904296875\n",
      "tensor(168.2584, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "168.25836181640625\n",
      "tensor(178.8305, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "178.8305206298828\n",
      "tensor(165.9583, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "165.95826721191406\n",
      "tensor(168.0700, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "168.07000732421875\n",
      "tensor(171.7279, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "171.72793579101562\n",
      "tensor(165.0784, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "165.0784149169922\n",
      "tensor(173.8712, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "173.87118530273438\n",
      "tensor(182.6763, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "182.67625427246094\n",
      "tensor(187.4050, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "187.405029296875\n",
      "tensor(169.3635, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "169.36349487304688\n",
      "tensor(174.0144, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "174.01437377929688\n",
      "tensor(165.9274, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "165.92735290527344\n",
      "tensor(166.6455, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "166.64547729492188\n",
      "tensor(167.4871, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "167.487060546875\n",
      "tensor(164.0862, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "164.0862274169922\n",
      "tensor(165.4116, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "165.41163635253906\n",
      "tensor(166.7131, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "166.7130889892578\n",
      "tensor(167.1479, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "167.1478729248047\n",
      "tensor(161.6751, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "161.67510986328125\n",
      "tensor(172.4277, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "172.42767333984375\n",
      "tensor(169.1392, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "169.13916015625\n",
      "tensor(167.4461, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "167.44607543945312\n",
      "tensor(181.1994, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "181.19940185546875\n",
      "tensor(169.1194, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "169.11944580078125\n",
      "tensor(168.7945, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "168.79454040527344\n",
      "tensor(169.8376, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "169.83755493164062\n",
      "tensor(167.6788, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "167.6788330078125\n",
      "tensor(172.3859, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "172.3859100341797\n",
      "tensor(163.3826, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "163.38259887695312\n",
      "tensor(165.4579, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "165.4579315185547\n",
      "tensor(161.3329, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "161.33291625976562\n",
      "tensor(169.9261, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "169.9261474609375\n",
      "tensor(160.6718, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "160.67181396484375\n",
      "tensor(173.2453, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "173.24526977539062\n",
      "tensor(167.4570, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "167.45704650878906\n",
      "tensor(183.3726, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "183.37255859375\n",
      "tensor(164.2973, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "164.29734802246094\n",
      "tensor(163.7866, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "163.78662109375\n",
      "tensor(167.3047, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "167.30465698242188\n",
      "tensor(176.1027, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "176.10272216796875\n",
      "tensor(175.3444, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "175.34442138671875\n",
      "tensor(164.7088, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "164.70875549316406\n",
      "tensor(170.4598, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "170.4597625732422\n",
      "tensor(170.9943, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "170.99429321289062\n",
      "tensor(167.0796, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "167.07962036132812\n",
      "tensor(165.4322, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "165.43218994140625\n",
      "tensor(161.6746, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "161.674560546875\n",
      "tensor(165.5291, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "165.529052734375\n",
      "tensor(165.5494, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "165.5494384765625\n",
      "tensor(174.6469, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "174.6468963623047\n",
      "tensor(160.6346, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "160.63455200195312\n",
      "tensor(174.0433, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "174.04330444335938\n",
      "tensor(156.1665, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "156.16650390625\n",
      "tensor(183.3003, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "183.30032348632812\n",
      "tensor(162.8091, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "162.80911254882812\n",
      "tensor(159.9379, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "159.93792724609375\n",
      "tensor(171.3982, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "171.39817810058594\n",
      "tensor(165.7163, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "165.71632385253906\n",
      "tensor(160.3104, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "160.3104248046875\n",
      "tensor(167.3012, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "167.30123901367188\n",
      "tensor(155.3369, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "155.33685302734375\n",
      "tensor(168.6114, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "168.61141967773438\n",
      "tensor(176.5923, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "176.59228515625\n",
      "tensor(170.9685, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "170.96853637695312\n",
      "tensor(165.0135, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "165.0135498046875\n",
      "tensor(162.2881, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "162.28814697265625\n",
      "tensor(166.1654, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "166.1654052734375\n",
      "tensor(177.3444, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "177.34439086914062\n",
      "tensor(181.1233, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "181.12326049804688\n",
      "tensor(175.5618, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "175.561767578125\n",
      "tensor(165.5417, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "165.541748046875\n",
      "tensor(164.6691, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "164.66905212402344\n",
      "tensor(155.8866, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "155.8865966796875\n",
      "tensor(168.1460, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "168.14598083496094\n",
      "tensor(182.4715, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "182.47146606445312\n",
      "tensor(158.2980, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "158.29798889160156\n",
      "tensor(174.5946, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "174.5946044921875\n",
      "tensor(162.6666, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "162.6666259765625\n",
      "tensor(172.1020, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "172.10198974609375\n",
      "tensor(169.1261, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "169.1260986328125\n",
      "tensor(176.7395, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "176.73948669433594\n",
      "tensor(174.7614, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "174.7614288330078\n",
      "tensor(164.0743, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "164.0742950439453\n",
      "tensor(164.4824, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "164.4823760986328\n",
      "tensor(161.5582, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "161.5581817626953\n",
      "tensor(170.2579, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "170.2579345703125\n",
      "tensor(175.8345, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "175.83453369140625\n",
      "tensor(163.2074, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "163.20738220214844\n",
      "tensor(163.2723, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "163.27227783203125\n",
      "tensor(169.2500, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "169.24998474121094\n",
      "tensor(161.6674, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "161.66741943359375\n",
      "tensor(166.0563, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "166.05633544921875\n",
      "tensor(168.9156, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "168.91555786132812\n",
      "tensor(169.5328, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "169.5327911376953\n",
      "tensor(180.7643, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "180.76431274414062\n",
      "tensor(160.9786, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "160.97857666015625\n",
      "tensor(171.6277, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "171.62765502929688\n",
      "tensor(158.5081, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "158.50808715820312\n",
      "tensor(161.8608, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "161.86082458496094\n",
      "tensor(172.1853, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "172.18533325195312\n",
      "tensor(163.2438, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "163.24383544921875\n",
      "tensor(160.0016, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "160.00164794921875\n",
      "tensor(164.0625, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "164.06251525878906\n",
      "tensor(174.3366, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "174.33657836914062\n",
      "tensor(160.4003, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "160.4003143310547\n",
      "tensor(163.4693, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "163.46926879882812\n",
      "tensor(159.5234, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "159.5233612060547\n",
      "tensor(157.5525, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "157.55247497558594\n",
      "tensor(181.0573, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "181.05726623535156\n",
      "tensor(160.5445, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "160.54446411132812\n",
      "tensor(159.3984, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "159.39840698242188\n",
      "tensor(167.6269, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "167.6269073486328\n",
      "tensor(175.3502, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "175.35020446777344\n",
      "tensor(171.8452, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "171.8451690673828\n",
      "tensor(168.9683, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "168.96827697753906\n",
      "tensor(178.2290, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "178.22897338867188\n",
      "tensor(166.3255, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "166.32553100585938\n",
      "tensor(161.4825, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "161.48245239257812\n",
      "tensor(174.9830, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "174.98297119140625\n",
      "tensor(163.6393, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "163.63934326171875\n",
      "tensor(176.7967, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "176.79666137695312\n",
      "tensor(170.8890, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "170.88900756835938\n",
      "tensor(168.9025, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "168.90252685546875\n",
      "tensor(168.2256, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "168.22561645507812\n",
      "tensor(170.8472, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "170.84716796875\n",
      "tensor(162.1963, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "162.19631958007812\n",
      "tensor(167.5021, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "167.50209045410156\n",
      "tensor(165.8228, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "165.82284545898438\n",
      "tensor(164.9131, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "164.9131317138672\n",
      "tensor(170.3060, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "170.3059844970703\n",
      "tensor(162.1213, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "162.1212615966797\n",
      "tensor(166.6160, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "166.6160125732422\n",
      "tensor(168.3904, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "168.3904266357422\n",
      "tensor(163.8156, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "163.81564331054688\n",
      "tensor(168.2453, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "168.24525451660156\n",
      "tensor(163.6009, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "163.60092163085938\n",
      "tensor(163.0485, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "163.04847717285156\n",
      "tensor(164.2126, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "164.212646484375\n",
      "tensor(158.1489, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "158.14894104003906\n",
      "tensor(162.0226, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "162.02264404296875\n",
      "tensor(174.5142, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "174.51422119140625\n",
      "tensor(156.2030, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "156.2030029296875\n",
      "tensor(178.6726, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "178.672607421875\n",
      "tensor(156.5885, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "156.5885009765625\n",
      "tensor(176.6851, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "176.68508911132812\n",
      "tensor(173.0565, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "173.05645751953125\n",
      "tensor(167.8919, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "167.89187622070312\n",
      "tensor(155.0706, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "155.0706329345703\n",
      "tensor(152.7733, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "152.7733154296875\n",
      "tensor(166.6978, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "166.69784545898438\n",
      "tensor(165.0688, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "165.06884765625\n",
      "tensor(157.5329, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "157.53289794921875\n",
      "tensor(166.2522, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "166.25221252441406\n",
      "tensor(170.2612, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "170.26116943359375\n",
      "tensor(150.9794, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "150.9793701171875\n",
      "tensor(163.3631, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "163.3631134033203\n",
      "tensor(163.1413, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "163.14129638671875\n",
      "tensor(167.7444, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "167.74444580078125\n",
      "tensor(157.0411, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "157.04110717773438\n",
      "tensor(168.7823, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "168.78231811523438\n",
      "tensor(156.7360, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "156.7359619140625\n",
      "tensor(163.9440, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "163.94400024414062\n",
      "tensor(157.7696, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "157.76963806152344\n",
      "tensor(166.9767, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "166.97674560546875\n",
      "tensor(163.3899, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "163.38986206054688\n",
      "tensor(167.9670, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "167.9669647216797\n",
      "tensor(165.0833, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "165.0833282470703\n",
      "tensor(162.3611, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "162.36114501953125\n",
      "tensor(170.6138, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "170.61380004882812\n",
      "tensor(168.1107, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "168.11065673828125\n",
      "tensor(164.0844, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "164.08444213867188\n",
      "tensor(176.4060, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "176.406005859375\n",
      "tensor(168.4146, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "168.4146270751953\n",
      "tensor(161.8632, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "161.8631591796875\n",
      "tensor(168.0645, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "168.06448364257812\n",
      "tensor(160.1989, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "160.19888305664062\n",
      "tensor(171.5398, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "171.53976440429688\n",
      "tensor(167.2525, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "167.25245666503906\n",
      "tensor(165.3643, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "165.36431884765625\n",
      "tensor(161.6542, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "161.65423583984375\n",
      "tensor(177.5536, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "177.5535888671875\n",
      "tensor(159.1849, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "159.18487548828125\n",
      "tensor(166.2454, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "166.2454376220703\n",
      "tensor(164.5399, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "164.5399169921875\n",
      "tensor(187.7451, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "187.74514770507812\n",
      "tensor(156.8832, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "156.88323974609375\n",
      "tensor(152.1594, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "152.15940856933594\n",
      "tensor(162.9917, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "162.99172973632812\n",
      "tensor(160.0950, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "160.09500122070312\n",
      "tensor(166.0571, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "166.05714416503906\n",
      "tensor(157.9536, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "157.95361328125\n",
      "tensor(159.4027, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "159.40272521972656\n",
      "tensor(176.4446, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "176.4446258544922\n",
      "tensor(173.1865, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "173.1864776611328\n",
      "tensor(168.8658, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "168.8658447265625\n",
      "tensor(166.4500, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "166.44998168945312\n",
      "tensor(165.2291, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "165.2290802001953\n",
      "tensor(160.9288, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "160.9288330078125\n",
      "tensor(157.9987, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "157.99868774414062\n",
      "tensor(189.8585, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "189.8585205078125\n",
      "tensor(171.6164, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "171.61636352539062\n",
      "tensor(157.0786, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "157.07858276367188\n",
      "tensor(157.4276, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "157.42764282226562\n",
      "tensor(157.6846, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "157.68460083007812\n",
      "tensor(171.4301, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "171.43011474609375\n",
      "tensor(168.9893, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "168.98931884765625\n",
      "tensor(164.0626, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "164.06259155273438\n",
      "tensor(158.7480, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "158.7480010986328\n",
      "tensor(154.7266, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "154.72659301757812\n",
      "tensor(184.3431, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "184.34312438964844\n",
      "tensor(165.5471, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "165.54713439941406\n",
      "tensor(162.9448, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "162.9447784423828\n",
      "tensor(169.3174, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "169.31744384765625\n",
      "tensor(167.5643, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "167.5643310546875\n",
      "tensor(162.9129, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "162.91294860839844\n",
      "tensor(158.0354, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "158.03536987304688\n",
      "tensor(163.0498, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "163.04983520507812\n",
      "tensor(161.4093, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "161.40933227539062\n",
      "tensor(174.9831, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "174.98309326171875\n",
      "tensor(167.4616, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "167.46157836914062\n",
      "tensor(150.8357, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "150.83572387695312\n",
      "tensor(172.1754, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "172.1754150390625\n",
      "tensor(164.0537, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "164.0536651611328\n",
      "tensor(178.4332, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "178.43319702148438\n",
      "tensor(166.5627, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "166.56272888183594\n",
      "tensor(179.2025, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "179.20254516601562\n",
      "tensor(172.3149, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "172.31492614746094\n",
      "tensor(171.7124, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "171.71240234375\n",
      "tensor(162.6718, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "162.67178344726562\n",
      "tensor(168.6509, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "168.65093994140625\n",
      "tensor(158.9624, device='cuda:6', grad_fn=<SumBackward0>)\n",
      "158.96241760253906\n"
     ]
    }
   ],
   "source": [
    "clsmodel = clsmodel.to(6)\n",
    "embeds = embeds.to(6)\n",
    "cri = models.ListMLE()\n",
    "# clsmodel.eval()\n",
    "# for i in data:\n",
    "#     i[\"seq_t\"] = i[\"seq_t\"].to(2)\n",
    "q = torch.optim.Adam(filter(lambda x: x.requires_grad, clsmodel.parameters()), lr=0.0001)\n",
    "for i in range(1500):\n",
    "    q.zero_grad()\n",
    "    loss = cri(clsmodel(embeds.unsqueeze(1)).squeeze(1))\n",
    "    # loss = clsmodel._list_training_step(data)\n",
    "    print(loss)\n",
    "    # loss = loss * 0.0\n",
    "    loss.backward()\n",
    "    q.step()\n",
    "    print(loss.item())\n",
    "    # print(model(data).item())\n",
    "    # print(\"\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clf.l1.weight Parameter containing:\n",
      "tensor([[ 5.6183e-03, -7.2583e-04,  9.2370e-04,  ...,  2.3575e-03,\n",
      "         -6.6478e-03, -2.2759e-03],\n",
      "        [-4.2368e-03,  3.8491e-03, -3.8733e-03,  ..., -3.8524e-03,\n",
      "         -4.0215e-03,  3.9197e-03],\n",
      "        [ 1.6638e-03,  8.2855e-04,  1.1220e-03,  ..., -5.4048e-04,\n",
      "         -3.3162e-05, -1.0610e-03],\n",
      "        ...,\n",
      "        [-4.1821e-03,  2.9903e-03, -2.4395e-03,  ..., -1.5212e-03,\n",
      "         -2.8255e-03,  3.6214e-03],\n",
      "        [ 1.8198e-03, -1.1366e-03,  1.9718e-03,  ...,  9.9019e-05,\n",
      "          7.1877e-04, -1.6034e-03],\n",
      "        [-1.1829e-03,  5.6399e-03, -4.5914e-03,  ...,  3.6545e-03,\n",
      "         -1.4379e-04,  5.3215e-03]], device='cuda:2', requires_grad=True)\n",
      "clf.l1.bias Parameter containing:\n",
      "tensor([ 2.9316e-02, -6.9022e-03, -6.3497e-04,  2.0163e-02,  1.9693e-03,\n",
      "         4.1604e-03,  7.1277e-03,  2.1045e-02,  1.6818e-02,  1.6161e-03,\n",
      "         1.4598e-02, -1.0070e-02, -5.4684e-04, -4.7448e-03, -1.8326e-03,\n",
      "         6.9637e-03,  6.9514e-03,  2.1132e-03, -3.2294e-03, -7.6070e-03,\n",
      "         1.1627e-02,  2.2202e-02,  1.3819e-03,  1.1194e-03,  1.7981e-02,\n",
      "         8.4880e-03,  1.7360e-02, -2.1212e-04,  5.2687e-03, -7.0888e-03,\n",
      "         1.3577e-02,  7.2277e-04,  1.3848e-02,  4.1628e-03,  1.5805e-03,\n",
      "         1.4541e-02,  2.3371e-02,  5.3903e-05,  4.1947e-03,  1.0670e-02,\n",
      "         1.5079e-02, -1.1911e-02,  1.1945e-02, -3.8656e-03,  2.1448e-02,\n",
      "         1.4740e-02,  1.4879e-02, -4.2359e-03,  1.7297e-02,  7.6483e-03,\n",
      "         2.9752e-03,  1.0214e-02,  8.8905e-04,  1.3978e-03, -4.4592e-04,\n",
      "         9.9586e-03,  1.7862e-02,  2.0642e-02,  4.9035e-03,  1.1962e-02,\n",
      "        -7.2790e-03,  2.7525e-04,  7.4641e-04,  4.4860e-03,  1.2593e-02,\n",
      "         1.7946e-02,  9.8589e-03,  1.5900e-02,  4.0260e-03,  4.0096e-03,\n",
      "        -6.1903e-03, -2.9462e-03,  2.3569e-02,  2.6050e-02,  3.7106e-03,\n",
      "         2.6087e-03,  1.2064e-02, -8.6739e-05,  8.5181e-03,  2.0361e-04,\n",
      "        -2.9976e-03,  2.4627e-03,  5.2186e-03,  4.9930e-03,  1.0881e-02,\n",
      "         1.1715e-02,  3.3346e-03, -7.3297e-03,  4.6348e-03,  6.0813e-04,\n",
      "        -2.5928e-04,  6.9294e-03,  4.4036e-03, -5.0533e-03, -4.0425e-04,\n",
      "         1.3600e-02, -1.3423e-03,  9.2342e-03,  1.0444e-02,  1.9833e-02,\n",
      "         1.7261e-02,  2.7908e-02,  3.6758e-03,  1.1956e-02,  1.5728e-02,\n",
      "        -3.4458e-03, -4.1225e-03,  5.1880e-04, -1.5313e-04, -2.7326e-03,\n",
      "         6.9649e-03,  7.5553e-04,  1.7948e-03, -1.1249e-02, -4.9315e-03,\n",
      "         4.4669e-03, -3.0221e-03,  7.3532e-03,  8.6020e-03, -3.0623e-03,\n",
      "         8.8783e-03,  2.5940e-03,  1.3334e-02,  1.9238e-02,  4.7789e-03,\n",
      "         2.0239e-03,  7.6495e-03,  6.2369e-04,  3.1390e-03, -5.6758e-03,\n",
      "         1.6585e-02,  1.0855e-02, -1.5788e-03,  2.8579e-02,  7.1673e-03,\n",
      "        -2.0624e-03,  1.1089e-03,  1.1957e-02,  9.6818e-03,  1.5314e-02,\n",
      "        -4.8753e-03, -2.0971e-03, -4.7343e-03, -1.4695e-03, -6.0603e-04,\n",
      "         1.3654e-03,  2.5255e-03,  5.5901e-03,  3.7474e-03,  5.8833e-03,\n",
      "         1.5084e-02,  7.1234e-03,  6.0208e-03,  4.9580e-03, -3.3189e-03,\n",
      "        -4.0573e-03, -5.3487e-03,  2.4141e-03,  7.9498e-03,  1.2017e-02,\n",
      "        -5.2094e-03,  5.4687e-03,  6.2032e-03,  1.6029e-02,  1.1218e-02,\n",
      "         4.4153e-03,  2.8527e-02, -5.5969e-03, -6.2284e-04, -9.7085e-04,\n",
      "         2.8682e-03,  2.2677e-03,  2.9059e-03, -4.5419e-03,  3.0941e-02,\n",
      "         1.3289e-03,  2.4669e-03, -6.6660e-03, -6.1192e-03,  6.8022e-03,\n",
      "         1.4670e-03, -6.1687e-03,  2.9753e-02,  8.4967e-04,  1.1984e-02,\n",
      "         1.1585e-02, -2.2384e-03,  1.3972e-02,  9.7625e-04, -7.5939e-03,\n",
      "        -3.5041e-06,  5.6072e-03,  2.4469e-02,  1.1861e-02, -3.4935e-03,\n",
      "         1.4935e-02,  2.5431e-04,  2.5519e-03, -8.9539e-03, -1.5088e-03,\n",
      "        -1.3453e-03,  8.7516e-03,  1.4115e-03,  2.3824e-02,  2.5549e-02,\n",
      "         9.2784e-03, -1.2691e-02,  4.0351e-03,  1.8892e-03,  5.0049e-03,\n",
      "        -1.5777e-03,  1.0276e-02, -1.0264e-02,  2.4648e-03,  1.6148e-02,\n",
      "         1.8465e-02, -8.5780e-03,  7.9008e-03, -2.6921e-03,  2.3246e-03,\n",
      "         7.4658e-03,  6.1668e-03, -5.9395e-03,  1.4024e-02,  2.8172e-04,\n",
      "         7.7910e-03,  1.7675e-03, -2.8120e-03,  9.9277e-03,  1.1494e-02,\n",
      "         1.2200e-02,  4.1551e-04,  8.5567e-03,  1.5739e-03,  2.3703e-03,\n",
      "         6.5206e-03,  3.3215e-03, -5.6454e-03,  2.0893e-02,  9.3659e-03,\n",
      "        -4.4474e-03,  1.3512e-02, -7.6348e-04, -4.9629e-03, -5.2683e-04,\n",
      "         2.6304e-03,  2.5258e-03,  6.1397e-03, -6.7724e-04,  7.9233e-03,\n",
      "         1.5253e-02,  5.5759e-03,  9.7872e-04, -9.6808e-03,  4.4343e-03,\n",
      "        -1.3686e-02, -2.0651e-03, -3.0731e-03,  1.4955e-02, -2.9253e-04,\n",
      "        -1.0091e-02,  8.6937e-03,  5.9277e-03,  2.8592e-03,  1.1561e-03,\n",
      "         6.4625e-03,  4.2199e-03,  1.1651e-02,  2.4569e-03,  1.3970e-03,\n",
      "         1.4554e-03,  6.3237e-03,  2.1123e-02, -3.6490e-04, -3.9099e-03,\n",
      "         7.7017e-03,  3.8866e-03,  4.4428e-04,  9.6337e-03, -7.5204e-03,\n",
      "         7.1176e-03, -7.3598e-03,  4.1036e-03,  2.5905e-02,  2.6718e-05,\n",
      "         3.6008e-03,  4.4432e-03, -2.2302e-03,  1.1753e-02,  1.1404e-02,\n",
      "         1.2019e-02,  2.8390e-03,  7.2568e-03,  1.5399e-02,  5.7405e-03,\n",
      "         3.5565e-03,  1.2405e-02,  5.8824e-03, -4.7023e-03,  1.4737e-04,\n",
      "         5.8616e-04,  1.2182e-02,  1.5356e-02,  8.7733e-03,  6.8594e-03,\n",
      "        -7.1624e-03,  1.0725e-02, -5.2411e-03,  1.9329e-02, -3.6959e-03,\n",
      "        -2.5093e-03,  2.5536e-02,  1.0697e-03,  4.3422e-04,  3.2651e-03,\n",
      "         1.8039e-02,  6.0013e-03,  2.0646e-03,  3.0085e-03, -1.5119e-03,\n",
      "        -4.0721e-03,  5.8524e-03,  4.5170e-03,  3.0610e-02,  1.1355e-03,\n",
      "         8.0239e-03,  6.4897e-03,  1.5216e-02,  1.8676e-02, -7.8732e-03,\n",
      "        -3.1069e-03,  2.3816e-02, -3.0422e-03,  4.7021e-03, -1.5728e-02,\n",
      "        -4.2533e-04,  6.0497e-03, -2.6682e-03,  9.0384e-03, -1.7775e-04,\n",
      "         8.9290e-03,  5.5556e-03, -3.1449e-03, -7.5259e-03,  2.4541e-02,\n",
      "         1.6526e-03,  3.8601e-03,  1.0936e-02,  1.1048e-02,  2.6398e-02,\n",
      "        -5.5842e-03,  3.4133e-04, -1.7368e-03,  7.7660e-04,  1.3734e-03,\n",
      "         9.4519e-04,  8.2423e-04,  1.5443e-02,  1.9696e-02, -4.6283e-03,\n",
      "         9.3884e-03,  2.5341e-03,  1.0199e-02,  2.1147e-03,  2.7360e-03,\n",
      "         8.9003e-03,  1.4718e-02,  8.3167e-04,  1.4644e-02,  1.3827e-02,\n",
      "        -4.4238e-03,  1.8611e-03,  6.7546e-03,  7.3624e-04,  4.0510e-03,\n",
      "         8.8614e-03, -9.3987e-04, -4.5683e-04,  1.0306e-02, -1.0082e-03,\n",
      "         1.1301e-03, -5.1635e-03,  7.0008e-04,  1.0838e-02, -4.9538e-03,\n",
      "         1.6529e-02, -9.5349e-03, -8.1158e-04,  8.4450e-04,  2.2744e-03,\n",
      "         7.9906e-03, -1.0237e-03, -3.6544e-03,  7.9897e-04, -5.0357e-03,\n",
      "         1.2617e-02,  2.9553e-02, -5.6488e-04,  1.2867e-02, -1.3715e-03,\n",
      "         1.7846e-03,  1.7102e-02, -6.7703e-03,  8.2637e-03, -2.6049e-03,\n",
      "         8.1133e-03,  1.3280e-02,  5.1652e-04, -3.8213e-03,  6.9380e-03,\n",
      "        -9.9944e-06, -2.8532e-03,  1.0096e-02,  2.7325e-03,  3.1989e-03,\n",
      "         8.8716e-03, -1.2342e-02, -7.7108e-03, -7.6089e-05,  2.7764e-03,\n",
      "         2.5117e-03, -1.0036e-03,  9.0982e-03,  1.0625e-02,  2.9129e-02,\n",
      "         1.3713e-03,  7.6257e-03,  6.2738e-03,  1.8151e-03, -4.1802e-03,\n",
      "        -1.1506e-04,  2.3757e-03,  1.4782e-02,  1.1659e-02,  5.2484e-03,\n",
      "         7.6126e-03,  1.3734e-03,  1.0359e-02, -2.6740e-03,  1.3178e-03,\n",
      "         2.7269e-03, -1.1555e-02, -5.1569e-03,  4.3623e-03, -3.3022e-03,\n",
      "         3.0880e-03, -2.2619e-03, -8.8545e-03,  4.9827e-03,  1.9580e-03,\n",
      "        -3.9624e-03,  4.5348e-03,  7.6566e-03, -3.1407e-03,  4.0202e-03,\n",
      "         9.4930e-04,  2.6968e-02,  3.4018e-03,  1.2464e-02,  4.0089e-03,\n",
      "         1.4676e-02,  2.1449e-03,  1.8898e-02,  6.7609e-03, -1.2319e-03,\n",
      "        -1.8980e-03, -1.7640e-03,  2.2843e-04,  2.2552e-02, -5.4070e-03,\n",
      "        -1.0727e-04, -1.0343e-02,  1.2843e-03,  2.1454e-03,  1.5111e-02,\n",
      "         1.4971e-04,  7.0931e-03,  2.9511e-02,  5.3099e-03,  8.6640e-03,\n",
      "         4.2189e-03, -1.1322e-03,  4.9722e-03,  7.5171e-03, -1.8843e-03,\n",
      "        -4.0812e-04, -7.6176e-03, -5.2873e-03,  1.0018e-02, -6.4204e-03,\n",
      "         1.1764e-03,  7.6672e-03,  5.3810e-03,  3.0914e-03,  9.9772e-03,\n",
      "         5.0530e-03,  1.5327e-02, -7.4796e-03,  4.9013e-03,  2.6197e-02,\n",
      "        -3.2452e-03, -4.3659e-03, -2.0394e-03,  1.1334e-02, -7.4645e-04,\n",
      "         1.0585e-03, -6.2541e-03,  1.7839e-03, -1.0725e-03, -3.0155e-03,\n",
      "        -1.0248e-03, -1.0620e-02,  2.7396e-02, -3.6524e-03,  1.0203e-02,\n",
      "         1.2113e-02,  1.3590e-03, -5.0465e-03,  4.8773e-03,  2.0148e-02,\n",
      "        -1.9414e-03,  1.1700e-02, -1.1250e-02,  2.1542e-02,  1.7705e-02,\n",
      "        -2.4761e-03,  6.1369e-03, -1.0477e-02,  2.8691e-02, -1.0644e-02,\n",
      "         1.0329e-03,  1.3230e-02,  1.0969e-02, -2.2881e-03,  1.3080e-03,\n",
      "         1.1045e-03,  8.8854e-03,  1.9716e-04,  8.8035e-03,  2.9197e-04,\n",
      "         1.3495e-02,  1.4609e-02,  2.8087e-03,  8.8138e-04, -2.2266e-03,\n",
      "         1.1557e-04, -2.3870e-03,  8.4098e-03,  6.7591e-03,  3.8046e-03,\n",
      "         4.0739e-03,  3.7035e-04, -7.8080e-04,  1.2396e-02,  1.6661e-02,\n",
      "         1.8045e-04,  2.9213e-03,  4.1457e-03,  2.5601e-03,  9.1011e-03,\n",
      "         3.0431e-03,  2.1980e-02,  5.8035e-04,  7.7631e-03,  6.1293e-03,\n",
      "         3.3073e-03,  1.1145e-02,  4.3380e-03,  1.6358e-02, -1.2421e-02,\n",
      "         1.1271e-02,  1.0328e-03,  2.4292e-02,  1.5753e-02, -4.0981e-03,\n",
      "         2.3135e-02], device='cuda:2', requires_grad=True)\n",
      "clf.l2.weight Parameter containing:\n",
      "tensor([[ 4.2965e-03,  6.0798e-04, -9.0565e-04,  ..., -1.6891e-03,\n",
      "          7.8209e-05, -1.1572e-03],\n",
      "        [ 2.3009e-03, -9.4394e-04, -3.3502e-03,  ...,  3.2168e-03,\n",
      "         -4.7184e-03, -8.1374e-04],\n",
      "        [-4.0656e-03,  1.1829e-03,  9.5954e-04,  ..., -5.5230e-03,\n",
      "          4.7459e-04, -1.4069e-02],\n",
      "        ...,\n",
      "        [ 6.9185e-04, -8.0920e-03,  6.9711e-03,  ..., -5.9359e-03,\n",
      "          8.5139e-03, -7.9627e-03],\n",
      "        [-3.2872e-03, -4.7071e-03,  2.6649e-04,  ...,  7.3735e-04,\n",
      "          9.9917e-04,  2.2702e-03],\n",
      "        [ 2.7850e-02,  4.6591e-03, -4.3217e-03,  ...,  2.7488e-03,\n",
      "         -3.9468e-03, -1.0860e-02]], device='cuda:2', requires_grad=True)\n",
      "clf.l2.bias Parameter containing:\n",
      "tensor([-5.6135e-03, -2.4775e-03,  3.7666e-03,  3.5573e-03,  5.4907e-03,\n",
      "        -1.3027e-02, -5.7855e-03,  4.6155e-03, -9.0300e-03, -1.4956e-03,\n",
      "         1.8492e-03,  3.7777e-03,  8.8117e-03,  7.1679e-03, -2.4149e-03,\n",
      "        -1.4188e-03,  1.4512e-03, -3.8477e-03, -4.2684e-03, -4.9121e-03,\n",
      "        -7.7667e-03, -4.1025e-04,  1.7253e-03, -3.6733e-04,  6.3470e-03,\n",
      "        -1.9642e-02, -1.1641e-02,  3.3866e-03, -5.3215e-03,  1.3078e-02,\n",
      "        -2.7836e-03,  8.6718e-03, -4.7459e-03, -2.0679e-03, -1.6767e-03,\n",
      "         7.5403e-04,  4.1529e-03,  2.0647e-02,  4.4639e-04, -4.0388e-03,\n",
      "         1.7097e-02,  3.6974e-03,  5.2687e-03,  1.0887e-03,  2.3914e-03,\n",
      "        -7.6586e-03,  1.9702e-03, -2.0376e-03, -8.0484e-04,  5.0489e-03,\n",
      "         1.0950e-02,  1.3123e-02,  4.3572e-03,  1.2318e-02,  1.7302e-03,\n",
      "         9.6022e-03, -3.7654e-03, -2.1963e-04, -1.4956e-03,  8.3731e-03,\n",
      "         1.1438e-02, -8.2606e-04, -4.7375e-03,  4.1318e-03,  4.9683e-03,\n",
      "         6.6949e-03, -8.8367e-03,  1.5283e-02,  1.4356e-02,  1.1738e-02,\n",
      "        -1.1132e-02,  5.1700e-03, -3.8331e-03, -1.0764e-02,  5.5070e-03,\n",
      "         6.6328e-03,  6.5925e-03,  3.1266e-03,  1.4305e-03,  1.8518e-03,\n",
      "        -2.6139e-04,  1.3282e-02,  1.5849e-02,  5.2935e-03,  2.0419e-02,\n",
      "         8.3022e-04, -3.6799e-03, -3.3788e-03, -5.7941e-03,  3.8340e-03,\n",
      "         1.0748e-03,  1.7984e-02,  4.4706e-03,  1.1208e-02,  5.1381e-03,\n",
      "         3.7638e-03,  2.1524e-03,  5.3900e-03,  4.7189e-03, -1.0364e-02,\n",
      "        -5.1352e-03,  1.1553e-03, -8.9020e-03, -4.3286e-03, -1.0750e-02,\n",
      "        -6.1165e-03, -6.3132e-04,  8.2280e-03,  8.9764e-04, -1.1828e-02,\n",
      "         3.4651e-03,  1.2769e-03,  7.8395e-03,  3.5046e-03, -4.7333e-05,\n",
      "         1.0277e-03, -2.0866e-03,  1.3915e-02,  3.6790e-03,  5.2276e-03,\n",
      "        -4.6844e-04, -4.5381e-03,  1.4719e-02,  6.1945e-03,  6.1808e-04,\n",
      "        -1.5436e-02, -1.2705e-03, -5.1604e-04,  1.2219e-02, -3.0737e-03,\n",
      "         1.8482e-03, -9.3404e-03,  3.9903e-04,  9.3169e-03, -9.4593e-03,\n",
      "         4.9698e-03, -4.2307e-03, -2.7258e-03, -4.8582e-03,  1.1713e-02,\n",
      "        -1.6599e-03,  4.8008e-03, -1.9132e-03, -1.7272e-03, -6.6121e-03,\n",
      "        -1.3410e-03, -6.9821e-03, -4.3211e-03,  1.2039e-03, -1.6229e-03,\n",
      "        -5.5397e-04, -1.1735e-02,  2.0487e-03,  7.8113e-04,  1.0272e-02,\n",
      "         2.5434e-03, -2.3989e-03,  2.3333e-03,  3.5300e-03,  2.3377e-03,\n",
      "         1.7199e-02,  5.9835e-03,  4.0740e-03, -2.6631e-03, -1.6027e-04,\n",
      "        -1.0263e-03, -1.8095e-03, -4.9312e-04, -8.5947e-03, -6.7667e-03,\n",
      "        -2.9420e-03,  7.7879e-03,  8.5732e-05,  1.6346e-02, -6.9649e-03,\n",
      "        -6.4080e-03,  1.8751e-02,  6.4051e-03, -4.5746e-03,  3.5270e-03,\n",
      "        -2.2649e-03, -5.1700e-03, -6.3740e-03, -1.2751e-02, -5.1785e-03,\n",
      "        -4.8238e-03,  1.3823e-02,  1.9819e-02,  1.5037e-04,  1.5723e-02,\n",
      "        -3.2161e-03,  5.4303e-04, -1.9661e-03,  1.1709e-02,  9.8101e-04,\n",
      "         1.3116e-02,  8.5598e-03, -3.9223e-03,  2.3416e-03,  2.5561e-03,\n",
      "        -3.6545e-03, -4.9902e-03, -6.1405e-03,  3.3153e-03,  1.2204e-04,\n",
      "        -2.2799e-02, -1.6014e-02,  1.2011e-03, -6.5678e-03,  4.2516e-03,\n",
      "         5.1835e-03, -1.2623e-03, -1.2527e-03,  1.0055e-02,  2.4802e-03,\n",
      "        -1.4226e-04, -2.6428e-03,  8.6848e-04, -6.7983e-03,  4.5448e-03,\n",
      "        -1.5350e-03,  5.0959e-03, -1.8893e-03,  5.6460e-04, -4.1387e-03,\n",
      "        -9.2047e-04,  3.7695e-03,  2.3089e-03,  6.6326e-03, -2.0978e-03,\n",
      "        -2.8362e-03,  7.2234e-04,  1.6468e-03,  5.3604e-03,  3.1334e-03,\n",
      "         3.6527e-03, -5.8334e-03,  1.0622e-03,  6.7267e-03,  7.2582e-03,\n",
      "         7.5924e-03,  1.7697e-03,  9.5563e-03, -1.0625e-02, -1.5179e-03,\n",
      "        -1.8451e-03,  4.7181e-03, -6.1290e-03, -6.2610e-04, -2.3846e-03,\n",
      "         1.5672e-02,  1.1465e-03, -7.9196e-03,  2.0755e-02, -6.4004e-03,\n",
      "         3.8673e-03,  2.8850e-03, -3.6548e-03, -3.2545e-04,  5.0090e-03,\n",
      "        -1.0788e-03, -5.2878e-03,  7.8120e-03, -3.4543e-03, -3.8834e-03,\n",
      "        -6.4013e-03, -1.0864e-03,  1.9908e-03, -4.6335e-03, -4.4871e-03,\n",
      "        -1.0841e-02,  5.5851e-04,  3.7319e-03,  1.1776e-02,  1.0010e-02,\n",
      "         1.5748e-03,  1.9064e-02,  3.4534e-03,  2.5870e-03, -7.1518e-03,\n",
      "         1.2667e-03, -3.7195e-03,  2.2341e-03,  3.6125e-03,  1.0512e-03,\n",
      "        -2.8095e-03,  4.8018e-03,  4.0257e-03], device='cuda:2',\n",
      "       requires_grad=True)\n",
      "clf.l3.weight Parameter containing:\n",
      "tensor([[-0.0627, -0.0278, -0.0696,  0.0298,  0.0528,  0.0566,  0.0507,  0.0372,\n",
      "          0.0250, -0.0320,  0.0139,  0.0604,  0.0700,  0.0583,  0.0376, -0.0932,\n",
      "          0.0007, -0.0014, -0.0069, -0.0064, -0.0260, -0.0476, -0.0098,  0.0053,\n",
      "          0.0219,  0.0589,  0.0551, -0.0574, -0.0817, -0.0656, -0.0056, -0.0582,\n",
      "          0.0425, -0.0179,  0.0628,  0.0233,  0.0176,  0.0570,  0.0037, -0.0598,\n",
      "          0.0456,  0.0475,  0.0161, -0.0108,  0.0125, -0.0886,  0.0089, -0.0945,\n",
      "         -0.0592, -0.0174, -0.0824, -0.0589, -0.0694, -0.0642, -0.0892,  0.0497,\n",
      "         -0.0219, -0.0109,  0.0117,  0.0529,  0.0406, -0.0131,  0.0026,  0.0134,\n",
      "          0.0470, -0.0753,  0.0478, -0.0788, -0.0890, -0.0542,  0.0399,  0.0132,\n",
      "         -0.0030,  0.0722,  0.0588, -0.0163,  0.0532, -0.0076,  0.0042,  0.0011,\n",
      "          0.0357,  0.0596,  0.0663, -0.0543,  0.0534,  0.0078, -0.0721,  0.0489,\n",
      "          0.0479, -0.0794, -0.0033, -0.0759,  0.0321, -0.0554, -0.0845, -0.0887,\n",
      "         -0.0158, -0.0149,  0.0092, -0.0733, -0.0931,  0.0138, -0.0710, -0.0012,\n",
      "         -0.0357, -0.0791,  0.0138,  0.0304, -0.0026, -0.0200,  0.0274,  0.0488,\n",
      "          0.0506,  0.0379, -0.0280,  0.0670, -0.0045,  0.0418,  0.0113, -0.0678,\n",
      "          0.0073, -0.0593,  0.0359,  0.0551, -0.0102, -0.0717,  0.0151,  0.0519,\n",
      "          0.0516, -0.0673, -0.0068,  0.0613,  0.0002, -0.0844, -0.0843,  0.0559,\n",
      "         -0.0729, -0.0240, -0.0037,  0.0527,  0.0288,  0.0188, -0.0063,  0.0471,\n",
      "          0.0475, -0.0083,  0.0213,  0.0526, -0.0089,  0.0550,  0.0015,  0.0543,\n",
      "          0.0239, -0.0012, -0.0911,  0.0050, -0.0816, -0.0153,  0.0611, -0.0077,\n",
      "         -0.0712, -0.0908,  0.0340,  0.0592,  0.0359,  0.0262,  0.0732,  0.0136,\n",
      "          0.0618,  0.0602,  0.0149,  0.0562,  0.0117, -0.0449, -0.0779, -0.0622,\n",
      "         -0.0885,  0.0279,  0.0037, -0.0118, -0.0054, -0.0421,  0.0438,  0.0614,\n",
      "         -0.0541, -0.0057,  0.0547, -0.0840,  0.0262, -0.0888,  0.0782, -0.0079,\n",
      "         -0.0126,  0.0463, -0.0121, -0.0852,  0.0452, -0.0110,  0.0024,  0.0307,\n",
      "         -0.0542, -0.0035, -0.0206, -0.0890,  0.0068, -0.0894, -0.0935, -0.0295,\n",
      "         -0.0914, -0.0150,  0.0515, -0.0207, -0.0016,  0.0593,  0.0169,  0.0102,\n",
      "          0.0703,  0.0206, -0.0330, -0.0517,  0.0610,  0.0254,  0.0141, -0.0213,\n",
      "         -0.0092,  0.0270,  0.0526,  0.0032,  0.0343, -0.0471,  0.0555, -0.0002,\n",
      "         -0.0031,  0.0594,  0.0546,  0.0623, -0.0065,  0.0036,  0.0613,  0.0518,\n",
      "          0.0599,  0.0153,  0.0564, -0.0739, -0.0036,  0.0334,  0.0584, -0.0891,\n",
      "         -0.0159,  0.0116, -0.0775,  0.0636, -0.0740, -0.0705, -0.0149,  0.0347,\n",
      "          0.0165, -0.0011,  0.0352,  0.0199, -0.0072, -0.0056,  0.0395,  0.0091,\n",
      "         -0.0817,  0.0667, -0.0975, -0.0035,  0.0051, -0.0129, -0.0364,  0.0085,\n",
      "         -0.0412,  0.0596,  0.0652,  0.0120,  0.0598,  0.0217, -0.0210, -0.0527,\n",
      "         -0.0455,  0.0662, -0.0084, -0.0717,  0.0084, -0.0382,  0.0344,  0.0454]],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "clf.l3.bias Parameter containing:\n",
      "tensor([0.0506], device='cuda:2', requires_grad=True)\n",
      "clf.ln1.weight Parameter containing:\n",
      "tensor([0.4885, 0.0835, 0.0859, 0.2820, 0.1061, 0.0835, 0.2024, 0.2524, 0.1146,\n",
      "        0.0812, 0.2565, 0.0899, 0.0825, 0.0805, 0.0811, 0.0840, 0.0981, 0.1420,\n",
      "        0.0797, 0.1321, 0.1270, 0.3389, 0.1401, 0.0959, 0.1774, 0.2897, 0.1166,\n",
      "        0.1235, 0.2321, 0.0846, 0.2981, 0.0818, 0.1197, 0.0964, 0.1281, 0.2771,\n",
      "        0.2012, 0.0800, 0.1461, 0.1307, 0.2378, 0.0920, 0.1190, 0.0816, 0.2791,\n",
      "        0.1497, 0.3030, 0.1746, 0.1575, 0.1856, 0.0817, 0.1599, 0.1068, 0.0989,\n",
      "        0.0794, 0.1607, 0.2145, 0.2388, 0.2545, 0.1696, 0.0802, 0.0871, 0.1859,\n",
      "        0.1270, 0.1925, 0.1115, 0.2466, 0.1691, 0.0902, 0.0829, 0.2260, 0.1087,\n",
      "        0.1775, 0.2441, 0.1597, 0.0915, 0.1878, 0.0921, 0.0905, 0.0882, 0.0814,\n",
      "        0.1388, 0.1787, 0.0947, 0.1447, 0.1543, 0.2707, 0.1649, 0.1111, 0.0920,\n",
      "        0.0788, 0.0842, 0.0874, 0.0861, 0.1212, 0.2106, 0.0988, 0.2612, 0.2612,\n",
      "        0.2086, 0.1909, 0.3320, 0.2325, 0.1554, 0.1861, 0.0799, 0.1725, 0.0875,\n",
      "        0.0840, 0.0878, 0.1345, 0.0940, 0.0841, 0.1240, 0.1603, 0.1386, 0.0839,\n",
      "        0.1733, 0.2036, 0.0792, 0.1299, 0.0831, 0.1425, 0.3366, 0.0863, 0.1048,\n",
      "        0.1164, 0.0771, 0.1345, 0.0871, 0.2311, 0.1958, 0.0866, 0.3882, 0.3141,\n",
      "        0.0875, 0.0883, 0.1254, 0.1898, 0.1271, 0.1099, 0.0875, 0.0809, 0.1037,\n",
      "        0.0991, 0.1801, 0.0784, 0.1029, 0.0788, 0.0881, 0.1750, 0.1324, 0.1192,\n",
      "        0.0874, 0.0881, 0.1137, 0.0960, 0.0914, 0.1067, 0.1271, 0.0864, 0.0876,\n",
      "        0.1013, 0.3188, 0.2228, 0.0790, 0.2633, 0.1009, 0.1029, 0.0861, 0.0783,\n",
      "        0.0793, 0.0820, 0.1146, 0.2524, 0.0888, 0.0784, 0.0881, 0.0837, 0.2262,\n",
      "        0.0793, 0.1045, 0.3463, 0.0964, 0.1598, 0.3154, 0.0855, 0.2653, 0.0813,\n",
      "        0.1014, 0.0781, 0.1718, 0.3025, 0.2582, 0.0840, 0.1313, 0.2034, 0.0878,\n",
      "        0.0966, 0.0788, 0.2897, 0.1963, 0.0915, 0.2661, 0.2896, 0.2141, 0.1275,\n",
      "        0.2404, 0.1575, 0.0979, 0.1638, 0.0971, 0.1030, 0.0930, 0.2070, 0.2338,\n",
      "        0.1253, 0.1047, 0.0942, 0.0804, 0.1341, 0.1672, 0.0978, 0.2950, 0.1147,\n",
      "        0.1047, 0.0877, 0.0934, 0.2081, 0.1991, 0.3000, 0.1254, 0.2078, 0.0876,\n",
      "        0.1085, 0.1331, 0.0871, 0.2876, 0.3114, 0.1462, 0.0875, 0.1195, 0.0796,\n",
      "        0.0973, 0.0950, 0.1446, 0.0809, 0.1116, 0.1443, 0.1731, 0.2296, 0.0900,\n",
      "        0.0795, 0.1201, 0.1576, 0.1874, 0.1139, 0.1327, 0.2275, 0.0779, 0.0913,\n",
      "        0.2138, 0.1169, 0.0921, 0.0782, 0.3003, 0.0811, 0.2680, 0.0944, 0.0970,\n",
      "        0.0780, 0.1527, 0.2985, 0.0786, 0.1055, 0.2094, 0.0843, 0.0810, 0.2442,\n",
      "        0.0841, 0.1255, 0.1263, 0.0857, 0.2833, 0.1908, 0.0934, 0.2520, 0.1283,\n",
      "        0.3391, 0.0921, 0.0974, 0.1347, 0.0830, 0.1407, 0.1134, 0.1197, 0.1272,\n",
      "        0.1362, 0.0848, 0.0860, 0.2066, 0.2552, 0.1605, 0.1260, 0.0809, 0.0944,\n",
      "        0.1047, 0.2904, 0.2560, 0.1792, 0.2761, 0.2392, 0.0858, 0.0797, 0.0770,\n",
      "        0.2035, 0.1221, 0.0790, 0.1513, 0.0946, 0.0803, 0.1438, 0.1395, 0.3091,\n",
      "        0.0989, 0.1595, 0.1305, 0.2161, 0.2100, 0.0978, 0.0899, 0.1651, 0.0899,\n",
      "        0.2415, 0.1065, 0.0925, 0.0837, 0.0931, 0.1292, 0.0846, 0.1962, 0.0827,\n",
      "        0.1165, 0.0865, 0.2262, 0.0988, 0.1424, 0.1966, 0.1159, 0.3116, 0.0875,\n",
      "        0.0930, 0.0955, 0.0839, 0.0867, 0.1056, 0.1104, 0.2004, 0.2334, 0.1136,\n",
      "        0.1145, 0.0790, 0.1810, 0.1659, 0.0792, 0.0902, 0.1512, 0.2910, 0.1186,\n",
      "        0.2201, 0.2140, 0.0825, 0.0850, 0.0859, 0.1559, 0.2586, 0.0840, 0.0953,\n",
      "        0.1070, 0.1121, 0.0783, 0.0860, 0.0793, 0.2392, 0.1377, 0.2244, 0.0879,\n",
      "        0.0872, 0.0919, 0.0927, 0.0955, 0.0786, 0.0829, 0.0908, 0.0897, 0.1843,\n",
      "        0.3394, 0.0876, 0.2028, 0.0904, 0.1068, 0.1631, 0.1771, 0.2902, 0.1314,\n",
      "        0.1037, 0.2122, 0.0779, 0.0844, 0.1314, 0.1213, 0.2795, 0.3319, 0.0862,\n",
      "        0.0791, 0.1068, 0.1024, 0.1236, 0.0898, 0.0802, 0.0797, 0.0849, 0.1327,\n",
      "        0.1551, 0.3144, 0.1591, 0.1251, 0.0896, 0.0851, 0.0785, 0.0881, 0.0784,\n",
      "        0.2773, 0.1060, 0.1022, 0.1032, 0.0790, 0.1090, 0.0849, 0.0789, 0.0786,\n",
      "        0.1041, 0.0853, 0.1369, 0.1136, 0.0931, 0.0871, 0.2722, 0.1050, 0.0811,\n",
      "        0.0918, 0.0844, 0.1665, 0.0859, 0.2054, 0.0786, 0.2612, 0.0897, 0.1444,\n",
      "        0.0972, 0.1138, 0.0827, 0.2220, 0.0838, 0.0803, 0.0807, 0.0776, 0.3147,\n",
      "        0.2241, 0.1376, 0.0814, 0.0904, 0.0779, 0.0803, 0.1854, 0.0939, 0.2806,\n",
      "        0.2829, 0.1623, 0.1253, 0.0960, 0.0831, 0.1577, 0.1044, 0.1254, 0.0960,\n",
      "        0.0914, 0.0922, 0.1847, 0.0921, 0.0832, 0.0858, 0.1152, 0.2426, 0.1834,\n",
      "        0.2030, 0.1081, 0.0968, 0.1086, 0.1794, 0.0991, 0.1084, 0.0801, 0.3531,\n",
      "        0.0905, 0.0815, 0.1108, 0.0830, 0.0796, 0.0779, 0.0921, 0.0958, 0.3026,\n",
      "        0.0930, 0.2608, 0.1508, 0.1359, 0.1100, 0.1678, 0.2025, 0.0781, 0.2237,\n",
      "        0.1296, 0.2896, 0.2599, 0.0989, 0.0796, 0.1009, 0.3806, 0.1277, 0.1996,\n",
      "        0.1456, 0.2750, 0.0805, 0.0845, 0.0879, 0.0916, 0.0795, 0.1023, 0.1277,\n",
      "        0.2293, 0.3937, 0.0781, 0.0793, 0.1006, 0.1167, 0.0800, 0.2538, 0.0868,\n",
      "        0.0954, 0.0869, 0.0785, 0.0793, 0.1468, 0.2246, 0.0780, 0.0910, 0.1482,\n",
      "        0.3032, 0.1668, 0.0886, 0.2910, 0.1035, 0.3042, 0.0785, 0.1085, 0.1987,\n",
      "        0.0890, 0.2320, 0.1380, 0.2244, 0.0838, 0.2342, 0.1342, 0.0814, 0.3489],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "clf.ln1.bias Parameter containing:\n",
      "tensor([-1.7169e-03, -6.4024e-03, -4.0817e-03, -2.8322e-03,  3.0609e-03,\n",
      "         3.2516e-03, -1.0613e-03,  3.8960e-03,  2.5319e-03,  2.4460e-03,\n",
      "         6.5901e-03, -5.4361e-03,  2.6698e-03, -6.1033e-03, -1.8769e-03,\n",
      "         6.0750e-03,  3.7635e-03, -3.1617e-03, -3.6937e-03, -7.2553e-03,\n",
      "         4.7570e-03, -4.8233e-05, -6.2589e-03, -9.6564e-04,  1.5505e-03,\n",
      "        -2.5191e-03,  5.9887e-03, -2.7519e-03,  7.1440e-03, -3.0155e-03,\n",
      "         6.6367e-03, -6.6881e-05,  4.1761e-03, -1.8205e-03,  4.6875e-03,\n",
      "        -1.1505e-03,  4.3006e-03,  1.8032e-03,  2.5827e-03,  1.3467e-03,\n",
      "         6.5443e-03, -3.5968e-03,  5.2514e-03, -4.7872e-03,  4.7710e-03,\n",
      "         8.7511e-03, -3.8376e-03, -1.6151e-03,  2.5726e-03,  9.3679e-03,\n",
      "         4.2489e-03, -2.5855e-03, -1.4595e-03,  2.9561e-03, -1.0671e-03,\n",
      "         6.2592e-03,  1.6030e-03,  7.1540e-03,  1.1825e-03,  2.3114e-03,\n",
      "        -6.8138e-03, -1.2981e-03, -5.2673e-03,  5.1305e-04,  3.7510e-03,\n",
      "         5.6093e-03,  1.9092e-04, -6.9248e-04,  3.6319e-03,  3.5979e-03,\n",
      "        -2.5885e-03, -7.3299e-03,  3.2451e-03,  5.5232e-03,  7.3445e-03,\n",
      "         3.6901e-03,  2.4866e-03,  3.8887e-03,  3.3705e-03, -1.6095e-03,\n",
      "        -2.1066e-03,  6.6740e-03,  3.2104e-03, -7.2744e-04,  3.6151e-03,\n",
      "         3.0407e-03, -4.9732e-03, -5.1959e-03,  3.5279e-03,  2.6547e-03,\n",
      "        -4.0316e-03,  2.9055e-03,  1.8915e-03, -7.1677e-03, -8.4716e-05,\n",
      "         9.9647e-04, -2.2603e-03,  7.2356e-03, -2.5841e-03,  3.7609e-03,\n",
      "         1.2996e-03, -6.0478e-06,  7.6986e-03,  3.9677e-03,  8.7882e-03,\n",
      "        -5.2402e-03, -5.1996e-03,  9.0843e-04, -1.0661e-05, -1.2774e-03,\n",
      "         6.6963e-03, -1.1735e-03,  4.5238e-03, -5.4784e-03, -3.6891e-03,\n",
      "        -9.8194e-04, -4.9928e-04,  1.7495e-03,  7.2891e-03, -2.9155e-03,\n",
      "         2.5630e-03,  9.1983e-04,  3.2941e-03, -1.3372e-03,  1.6226e-03,\n",
      "         3.4274e-03,  5.3412e-04, -2.1217e-03, -1.0208e-03, -5.1439e-03,\n",
      "         2.1468e-03,  2.4617e-03, -4.6370e-03,  1.8262e-03, -1.2361e-03,\n",
      "        -5.6781e-04,  2.2630e-03, -4.1486e-03,  9.3931e-03,  3.4902e-03,\n",
      "        -4.2583e-03, -3.9366e-03, -6.9751e-03,  4.2000e-03,  4.2952e-03,\n",
      "         3.1982e-03,  2.1038e-03,  4.2516e-03,  4.2748e-03,  2.2211e-03,\n",
      "         2.5939e-03, -5.1954e-03,  2.6547e-03, -8.8790e-05, -9.6481e-04,\n",
      "        -6.7785e-03,  5.6276e-04, -4.6442e-03,  4.2841e-03,  3.3749e-04,\n",
      "        -4.4963e-03,  5.3245e-05, -2.6936e-04,  2.6724e-03,  4.5386e-03,\n",
      "         4.3848e-03,  8.9149e-03, -6.7733e-03,  1.3215e-03,  3.2201e-03,\n",
      "         3.4018e-03,  3.5517e-03,  2.5417e-03, -4.6048e-03,  3.2198e-03,\n",
      "        -8.8734e-04,  1.6324e-03, -6.0494e-03, -3.6494e-03,  2.8981e-03,\n",
      "         6.7651e-05, -3.2245e-03,  5.2721e-03, -1.7140e-03,  3.1385e-03,\n",
      "         4.8572e-03, -4.7048e-03,  4.1077e-03, -9.0880e-04, -4.4186e-03,\n",
      "        -1.5650e-03,  5.2427e-03,  4.9873e-03,  7.5581e-03, -4.4017e-03,\n",
      "         2.2968e-03, -4.5359e-03,  1.0032e-03, -4.9931e-03, -2.4281e-03,\n",
      "         2.7529e-03,  3.0492e-03,  3.0366e-03,  8.0719e-03,  3.5544e-03,\n",
      "         7.7903e-03, -3.7275e-03,  3.7900e-03,  2.5442e-03,  5.3166e-03,\n",
      "        -1.9836e-03,  4.8077e-03, -5.5137e-03,  3.6882e-03,  3.8475e-03,\n",
      "         1.6942e-03, -3.0567e-03, -2.7887e-03, -1.7471e-03,  4.2166e-03,\n",
      "        -4.0746e-03,  7.6173e-04,  5.3100e-05,  4.2503e-03, -8.4897e-04,\n",
      "         6.5718e-03,  2.5249e-03, -5.9585e-03, -1.0726e-03, -1.1319e-03,\n",
      "         9.4659e-04, -3.7647e-03,  6.9439e-03, -4.0191e-03,  6.1331e-03,\n",
      "         4.7025e-03,  2.0306e-03,  4.5050e-03,  4.4499e-03,  3.9740e-03,\n",
      "        -3.4693e-03,  5.5257e-03, -5.3991e-04, -5.7186e-03,  7.0201e-05,\n",
      "         4.2586e-03,  4.3470e-03, -1.2227e-03, -4.8707e-03,  6.4680e-03,\n",
      "         6.6786e-03,  2.4905e-03,  3.8261e-04, -5.3732e-03, -4.0731e-03,\n",
      "        -1.8837e-04,  3.2447e-05, -1.2291e-03,  4.1231e-03, -2.1154e-03,\n",
      "        -6.5319e-03,  3.5192e-03,  3.3003e-03,  1.6539e-03, -1.0008e-03,\n",
      "         2.0766e-03,  3.9354e-03,  1.9069e-03,  2.7128e-03,  2.8479e-03,\n",
      "        -1.2695e-03,  4.1526e-03,  1.0440e-03,  6.8113e-04, -3.1886e-03,\n",
      "        -5.3649e-04,  1.1478e-03,  3.9880e-05,  8.8157e-03, -4.4572e-03,\n",
      "        -6.9641e-04, -3.9386e-03,  5.4461e-03,  5.8342e-03,  1.0130e-03,\n",
      "         7.6428e-04,  4.4386e-03,  2.5995e-03,  1.2913e-03,  5.0453e-03,\n",
      "         4.9594e-03, -4.4249e-03,  3.9027e-03,  4.8459e-03,  5.4668e-04,\n",
      "         3.1372e-03,  7.1809e-03,  3.7587e-03, -5.8207e-04, -1.0494e-03,\n",
      "         6.5072e-03,  3.1304e-03,  5.1495e-03, -2.6987e-03,  4.6983e-03,\n",
      "        -5.7414e-03,  3.5624e-03, -1.8211e-03,  2.1574e-03,  5.0386e-03,\n",
      "         4.2335e-03,  6.3784e-03,  4.8858e-03, -8.8545e-04,  2.4251e-03,\n",
      "         5.6907e-03,  4.5334e-03, -3.8192e-03, -9.6119e-04, -3.0815e-03,\n",
      "        -2.6393e-03,  2.9800e-03,  2.5510e-03,  7.3937e-03,  2.3042e-03,\n",
      "         3.8165e-03, -1.4908e-03, -1.6872e-04,  2.9918e-03, -2.7639e-03,\n",
      "        -1.6390e-03,  7.7472e-03,  1.4382e-04,  4.4371e-04, -3.2413e-03,\n",
      "        -1.3548e-03,  3.5655e-03, -3.4944e-03, -6.6127e-04, -1.3404e-03,\n",
      "         4.1042e-03,  5.9579e-03, -4.2710e-03, -3.1435e-03,  3.0984e-03,\n",
      "         3.1176e-03,  3.3186e-03,  1.9791e-03, -4.8484e-04,  3.0187e-03,\n",
      "        -5.8445e-03, -3.8346e-03, -2.4358e-03, -1.5640e-03, -4.3997e-03,\n",
      "         1.8110e-03,  1.2584e-03, -3.4799e-03,  2.3630e-03, -3.4408e-03,\n",
      "         1.3044e-02,  3.4573e-03, -1.0708e-03,  5.2649e-03, -4.3005e-04,\n",
      "         2.7071e-03,  9.0830e-04,  1.0327e-03,  9.0725e-06,  1.0959e-03,\n",
      "         2.4268e-03, -1.5082e-03,  3.5193e-03, -7.7678e-04,  7.0963e-03,\n",
      "        -9.5247e-04, -2.7094e-03, -5.6585e-03,  2.4441e-03,  1.9781e-04,\n",
      "        -1.5814e-03, -7.4467e-04, -3.4565e-03,  1.2991e-02,  2.8941e-03,\n",
      "         4.8483e-04, -6.5297e-03,  2.9045e-03,  1.1490e-05, -1.5250e-03,\n",
      "         5.3740e-03, -4.5160e-03, -3.1390e-03,  2.5321e-03, -4.8296e-03,\n",
      "         3.1942e-03,  3.2589e-03, -4.5805e-03,  1.0853e-03, -6.0256e-04,\n",
      "         9.3623e-04, -5.7330e-04,  3.1469e-03,  1.1394e-03, -1.0681e-02,\n",
      "         5.1593e-03,  5.1299e-03,  4.1923e-04, -5.0436e-03, -1.2714e-03,\n",
      "        -4.5662e-03,  3.7948e-03,  5.1192e-03,  4.3405e-03,  1.5547e-03,\n",
      "         8.0495e-04, -5.4770e-03, -4.3682e-03,  1.2135e-04,  3.1228e-03,\n",
      "         4.3030e-03, -3.1620e-03,  2.2579e-03, -5.1392e-03,  7.3365e-03,\n",
      "         3.1072e-03,  1.6420e-03,  3.2801e-03, -3.6090e-03, -3.8053e-03,\n",
      "        -1.0366e-03,  3.6422e-03,  7.0699e-03,  6.3525e-03,  4.7306e-03,\n",
      "         6.0049e-03, -6.4592e-04,  4.0021e-03, -3.1342e-03, -2.0982e-03,\n",
      "         4.4884e-03, -1.2862e-03, -5.0746e-03,  7.1182e-03, -4.2060e-03,\n",
      "         3.5041e-03,  2.7183e-03,  4.4076e-03,  1.3522e-03,  2.4042e-03,\n",
      "        -3.8380e-03,  2.8803e-03, -3.7142e-04, -4.4956e-03, -5.9256e-04,\n",
      "        -1.0589e-03,  6.0239e-03,  5.6488e-04,  2.3930e-03,  4.0433e-03,\n",
      "         4.2737e-03,  1.3197e-03,  2.2189e-03,  6.3790e-03, -5.9200e-03,\n",
      "        -4.8676e-03, -6.4263e-03,  3.3313e-03,  6.9326e-04, -1.1633e-03,\n",
      "        -5.4137e-04, -8.2302e-03,  2.3488e-03,  1.7001e-04,  5.1193e-03,\n",
      "        -2.3022e-03, -7.6225e-05,  4.5208e-03,  9.5531e-04,  2.5367e-03,\n",
      "        -1.0990e-03, -4.8384e-03,  5.1225e-04,  3.1121e-03, -7.0463e-03,\n",
      "        -2.8990e-03, -3.7989e-03, -5.1725e-03,  3.5360e-03, -2.7052e-03,\n",
      "         4.9766e-03,  4.2025e-03,  4.0796e-03,  5.3245e-03,  2.5167e-03,\n",
      "         3.8535e-03,  7.1950e-03, -5.4333e-03,  2.0426e-03,  3.9677e-03,\n",
      "        -2.2897e-03, -4.9444e-03, -2.2634e-03,  6.0194e-03,  2.8302e-03,\n",
      "         6.3532e-04, -1.2417e-03,  4.9555e-04, -4.2937e-03, -5.2242e-03,\n",
      "        -1.8925e-03, -4.3446e-03,  3.9666e-04, -3.2465e-03,  1.5074e-03,\n",
      "         1.9837e-03, -2.7517e-03, -2.3451e-03, -4.3494e-03,  6.8762e-03,\n",
      "        -4.5205e-03,  6.0533e-03, -6.8286e-03,  8.1998e-03, -1.4872e-03,\n",
      "        -5.4506e-03,  3.6701e-03, -6.1596e-03,  1.5351e-03, -4.6115e-03,\n",
      "         2.8454e-03,  2.8644e-03,  9.9247e-04, -6.3254e-03,  1.4656e-03,\n",
      "        -1.6860e-03,  3.7626e-03, -4.1496e-04, -8.4843e-05, -3.2065e-03,\n",
      "         7.8444e-03, -3.4443e-04,  2.8216e-03,  3.0704e-04,  2.1233e-03,\n",
      "        -3.8907e-03, -3.5005e-03, -2.9644e-03,  2.5672e-03,  1.0615e-03,\n",
      "         3.7628e-03, -5.2772e-04, -1.9884e-03,  8.6778e-05,  4.4170e-03,\n",
      "        -1.9148e-03,  4.6962e-03, -3.5299e-03,  3.6498e-03, -2.0560e-03,\n",
      "         2.1988e-03, -1.7963e-03, -3.8985e-03,  6.3822e-03,  5.5111e-03,\n",
      "         8.5996e-04,  7.6556e-04,  3.1649e-03,  3.7718e-03, -5.1426e-03,\n",
      "        -2.0823e-03,  1.9926e-03,  3.6202e-03, -3.0058e-03, -2.9444e-03,\n",
      "         4.6843e-03], device='cuda:2', requires_grad=True)\n",
      "clf.ln2.weight Parameter containing:\n",
      "tensor([0.2796, 0.0954, 0.4265, 0.1609, 0.3313, 0.4390, 0.2942, 0.2715, 0.1213,\n",
      "        0.1891, 0.1178, 0.3941, 0.5056, 0.3772, 0.1263, 0.3743, 0.0734, 0.0717,\n",
      "        0.0783, 0.0749, 0.0964, 0.2928, 0.1136, 0.0768, 0.1447, 0.3933, 0.3830,\n",
      "        0.3155, 0.3445, 0.3710, 0.0796, 0.3368, 0.2142, 0.1085, 0.3591, 0.1859,\n",
      "        0.1571, 0.5300, 0.0776, 0.3970, 0.3845, 0.4430, 0.1633, 0.0978, 0.1248,\n",
      "        0.3566, 0.0932, 0.3729, 0.2815, 0.1733, 0.4386, 0.3913, 0.2762, 0.3380,\n",
      "        0.4702, 0.3958, 0.0947, 0.1041, 0.1019, 0.3219, 0.3020, 0.1112, 0.0717,\n",
      "        0.1189, 0.3092, 0.4183, 0.3527, 0.5100, 0.3606, 0.3081, 0.2157, 0.1388,\n",
      "        0.0749, 0.4343, 0.4745, 0.1865, 0.3904, 0.1216, 0.0828, 0.0791, 0.2571,\n",
      "        0.3819, 0.5330, 0.2543, 0.4532, 0.0803, 0.3566, 0.2743, 0.3738, 0.3410,\n",
      "        0.0810, 0.5131, 0.1525, 0.3166, 0.4280, 0.3783, 0.1495, 0.1600, 0.0946,\n",
      "        0.4698, 0.4513, 0.0926, 0.3524, 0.0723, 0.1333, 0.3168, 0.0842, 0.1972,\n",
      "        0.0896, 0.0841, 0.1233, 0.2914, 0.5222, 0.2194, 0.1807, 0.4916, 0.0872,\n",
      "        0.2586, 0.1082, 0.3350, 0.0832, 0.3584, 0.3740, 0.4248, 0.0868, 0.3411,\n",
      "        0.0967, 0.3199, 0.4523, 0.3608, 0.1061, 0.5352, 0.0742, 0.4125, 0.4094,\n",
      "        0.4598, 0.3994, 0.1154, 0.0752, 0.3332, 0.1283, 0.1459, 0.0968, 0.2157,\n",
      "        0.3495, 0.1055, 0.1095, 0.3881, 0.1229, 0.4325, 0.0712, 0.4474, 0.1243,\n",
      "        0.0710, 0.4843, 0.0800, 0.4143, 0.1442, 0.3430, 0.0994, 0.4646, 0.4237,\n",
      "        0.2148, 0.3885, 0.1482, 0.1796, 0.4566, 0.0874, 0.4727, 0.4663, 0.0759,\n",
      "        0.4996, 0.0917, 0.3147, 0.4274, 0.4060, 0.3569, 0.2084, 0.0804, 0.1217,\n",
      "        0.0790, 0.1466, 0.2699, 0.4170, 0.3039, 0.0777, 0.3582, 0.4439, 0.1322,\n",
      "        0.3979, 0.4504, 0.1163, 0.0853, 0.2506, 0.1390, 0.4727, 0.3209, 0.0801,\n",
      "        0.0748, 0.1290, 0.2817, 0.0735, 0.1027, 0.4545, 0.0828, 0.4346, 0.3820,\n",
      "        0.1778, 0.4665, 0.1596, 0.2425, 0.0981, 0.0735, 0.3606, 0.1045, 0.0822,\n",
      "        0.3573, 0.1226, 0.1432, 0.2540, 0.3489, 0.1628, 0.0968, 0.1333, 0.0766,\n",
      "        0.1218, 0.4390, 0.0801, 0.1938, 0.1913, 0.3241, 0.0703, 0.0825, 0.3507,\n",
      "        0.3407, 0.2676, 0.0745, 0.0838, 0.2710, 0.2050, 0.4977, 0.1206, 0.4114,\n",
      "        0.5316, 0.0782, 0.1519, 0.3468, 0.4257, 0.1165, 0.0803, 0.4601, 0.4003,\n",
      "        0.4361, 0.5037, 0.0938, 0.2549, 0.1053, 0.0733, 0.2155, 0.1454, 0.0845,\n",
      "        0.0813, 0.2084, 0.0767, 0.3273, 0.4133, 0.3741, 0.0809, 0.0724, 0.0776,\n",
      "        0.1290, 0.0898, 0.2151, 0.4919, 0.3290, 0.1039, 0.4182, 0.1239, 0.1496,\n",
      "        0.2020, 0.1776, 0.4464, 0.0955, 0.4811, 0.0907, 0.1728, 0.1848, 0.3779],\n",
      "       device='cuda:2', requires_grad=True)\n",
      "clf.ln2.bias Parameter containing:\n",
      "tensor([ 8.6169e-03,  2.9158e-04,  1.3521e-02,  6.4053e-03,  1.0579e-02,\n",
      "         5.8642e-03,  4.4049e-03,  6.8116e-03, -2.4615e-03,  2.7833e-03,\n",
      "         3.0098e-03,  1.4066e-02,  7.0938e-03,  7.3184e-03,  5.2483e-03,\n",
      "         2.3079e-02, -1.6376e-03, -1.3197e-04,  3.2767e-03, -4.6463e-04,\n",
      "         3.5050e-03,  7.5110e-03, -7.2622e-05,  2.4044e-03,  1.2425e-02,\n",
      "         2.9051e-03,  6.0351e-03,  8.7719e-03,  1.8175e-02,  1.4225e-02,\n",
      "        -1.1901e-03,  1.6341e-02,  3.8712e-03,  1.8694e-04,  4.7292e-03,\n",
      "         2.9701e-03,  2.2112e-03,  8.7568e-03, -1.1613e-04,  1.2618e-02,\n",
      "         1.0165e-02,  5.5450e-03, -8.9889e-04, -9.3869e-04,  1.1939e-03,\n",
      "         1.5697e-02, -1.7809e-03,  2.6342e-02,  8.7329e-03,  1.5549e-03,\n",
      "         1.6926e-02,  1.4787e-02,  1.8020e-02,  2.1513e-02,  1.9330e-02,\n",
      "         6.0448e-03,  3.8052e-04,  2.2868e-05,  3.0641e-03,  1.2943e-02,\n",
      "         8.8392e-03,  7.1072e-04,  7.1078e-04,  9.8074e-04,  8.2485e-03,\n",
      "         1.7356e-02,  7.7785e-03,  1.0131e-02,  2.8876e-02,  9.2524e-03,\n",
      "         3.3684e-04,  5.9845e-03,  2.2527e-03,  9.7945e-03,  7.9807e-03,\n",
      "         4.6242e-04,  1.2643e-02, -7.1027e-04,  1.5094e-03, -2.5191e-03,\n",
      "         6.5175e-03,  1.8476e-02,  9.0412e-03,  1.4186e-02,  7.4216e-03,\n",
      "        -2.7297e-03,  1.0920e-02,  1.0229e-02,  8.2256e-04,  1.7135e-02,\n",
      "         6.2551e-05,  6.9766e-03,  7.7284e-03,  1.8904e-02,  2.2586e-02,\n",
      "         2.7122e-02, -2.0892e-04, -2.3299e-03, -1.4796e-04,  1.0291e-02,\n",
      "         1.7326e-02,  1.2612e-03,  1.9452e-02, -7.7772e-04, -5.8827e-04,\n",
      "         1.4405e-02, -8.3631e-04,  1.2823e-02, -2.4092e-03, -6.1532e-03,\n",
      "         5.0125e-03,  8.3509e-03,  3.9538e-03,  7.5956e-03,  3.5327e-03,\n",
      "         9.2519e-03,  2.0568e-04,  1.1161e-02,  1.6302e-03,  1.0405e-02,\n",
      "         9.7594e-05,  1.0746e-02,  2.9203e-03,  7.6575e-03,  3.4200e-04,\n",
      "         1.1090e-02,  7.7512e-04,  3.5358e-03,  1.1309e-02,  1.4584e-02,\n",
      "        -8.5288e-04,  6.5821e-03, -5.9907e-04,  2.5361e-02,  1.7141e-02,\n",
      "         9.5432e-03,  1.4009e-02, -1.0661e-03,  3.0729e-03,  1.2107e-02,\n",
      "         4.0797e-03,  2.9660e-03, -2.0776e-04,  9.7255e-03,  1.0893e-02,\n",
      "        -3.6015e-03, -1.6041e-03,  1.7171e-03,  1.0903e-04,  1.1590e-02,\n",
      "        -1.1382e-03,  4.8394e-03,  1.3899e-03, -1.5115e-03,  1.2071e-02,\n",
      "        -2.4485e-03,  2.1414e-02,  3.6034e-03,  9.2700e-03,  1.0866e-03,\n",
      "         9.8533e-03,  1.4794e-02,  9.0513e-03,  1.1358e-02,  5.4163e-03,\n",
      "         8.0557e-04,  1.2088e-02,  3.3856e-04,  2.3726e-03,  4.6063e-03,\n",
      "         2.3272e-03,  8.8741e-03, -3.0413e-03,  1.2576e-02,  1.0176e-02,\n",
      "         8.5202e-03,  3.0240e-02,  7.2848e-03, -1.4583e-03,  5.6529e-04,\n",
      "         1.3586e-03,  6.2066e-03,  3.4451e-03,  6.4599e-03,  1.3158e-02,\n",
      "         3.8068e-03,  1.4265e-02,  2.0656e-02,  1.8939e-03,  1.9455e-02,\n",
      "         1.5566e-02, -5.0603e-04, -3.1872e-04,  1.1708e-02,  3.2021e-04,\n",
      "         1.4296e-02,  1.2144e-02,  2.5228e-04, -1.0568e-03,  3.8168e-03,\n",
      "         8.5489e-03, -1.6990e-03, -1.0559e-03,  1.3639e-02, -8.5688e-04,\n",
      "         9.2560e-03,  1.7919e-02,  6.0917e-03,  1.7188e-02, -2.4522e-03,\n",
      "         1.1667e-02, -5.1120e-03, -3.2488e-04,  9.0676e-03,  2.4016e-03,\n",
      "        -4.6788e-04,  1.2370e-02,  3.5706e-03,  2.3372e-03,  1.1298e-02,\n",
      "         1.3010e-02,  4.1725e-03, -1.0658e-03,  6.4803e-04,  2.0543e-03,\n",
      "         6.9118e-04,  5.4502e-03, -9.5041e-04, -5.7196e-03,  7.5998e-03,\n",
      "         1.0888e-02, -1.9110e-03,  2.8987e-03,  5.6721e-03,  8.4877e-03,\n",
      "         1.1040e-02,  1.7315e-04,  2.7616e-04,  1.1907e-02,  1.5554e-02,\n",
      "         3.8336e-03,  5.1500e-04,  1.3497e-02,  9.1580e-03,  3.4520e-03,\n",
      "         4.0590e-03,  1.6146e-02,  1.8940e-02, -1.0306e-03,  1.0368e-03,\n",
      "         1.6371e-02,  7.7471e-03,  1.2469e-02,  1.2390e-02,  3.4519e-03,\n",
      "         2.1271e-03,  1.8929e-03, -3.8818e-05,  8.1168e-03,  4.8030e-03,\n",
      "         1.6059e-03,  1.2390e-03,  9.9383e-03,  9.3789e-05,  2.1970e-02,\n",
      "         1.2487e-02,  1.8115e-02,  1.4796e-03, -1.0992e-03, -8.6139e-04,\n",
      "        -3.5361e-03,  1.1325e-03,  1.2623e-02,  9.9336e-03,  1.2327e-02,\n",
      "         3.6923e-03,  1.2138e-02,  4.3567e-03, -5.2354e-05,  5.5097e-03,\n",
      "         5.2499e-03,  7.1194e-03, -3.0409e-03,  1.6723e-02, -4.5372e-04,\n",
      "        -1.2470e-03,  1.0979e-02,  1.0922e-02], device='cuda:2',\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for i, j in model.named_parameters():\n",
    "    if j.requires_grad:\n",
    "        print(i, j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test MLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "def listMLE(y_pred, y_true, eps=1e-8, padded_value_indicator=0):\n",
    "    \"\"\"\n",
    "    ListMLE loss introduced in \"Listwise Approach to Learning to Rank - Theory and Algorithm\".\n",
    "    :param y_pred: predictions from the model, shape [batch_size, slate_length]\n",
    "    :param y_true: ground truth labels, shape [batch_size, slate_length]\n",
    "    :param eps: epsilon value, used for numerical stability\n",
    "    :param padded_value_indicator: an indicator of the y_true index containing a padded item, e.g. -1\n",
    "    :return: loss value, a torch.Tensor\n",
    "    \"\"\"\n",
    "    # shuffle for randomised tie resolution\n",
    "    random_indices = torch.randperm(y_pred.shape[-1])\n",
    "    y_pred_shuffled = y_pred[:, random_indices]\n",
    "    y_true_shuffled = y_true[:, random_indices]\n",
    "\n",
    "    y_true_sorted, indices = y_true_shuffled.sort(descending=True, dim=-1)\n",
    "\n",
    "    mask = y_true_sorted == padded_value_indicator\n",
    "\n",
    "    preds_sorted_by_true = torch.gather(y_pred_shuffled, dim=1, index=indices)\n",
    "    preds_sorted_by_true[mask] = float(\"-inf\")\n",
    "\n",
    "    max_pred_values, _ = preds_sorted_by_true.max(dim=1, keepdim=True)\n",
    "\n",
    "    preds_sorted_by_true_minus_max = preds_sorted_by_true - max_pred_values\n",
    "\n",
    "    cumsums = torch.cumsum(preds_sorted_by_true_minus_max.exp().flip(dims=[1]), dim=1).flip(dims=[1])\n",
    "\n",
    "    observation_loss = torch.log(cumsums + eps) - preds_sorted_by_true_minus_max\n",
    "\n",
    "    observation_loss[mask] = 0.0\n",
    "\n",
    "    return torch.mean(torch.sum(observation_loss, dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.6818,  1.1132,  0.5710,  1.1020, -1.1299]) tensor([ 1.6818,  1.1132,  0.5710,  1.1020, -1.1299])\n"
     ]
    }
   ],
   "source": [
    "gelu = nn.Identity()\n",
    "ln = nn.LayerNorm(5)\n",
    "b = gelu(a)\n",
    "print(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.0510,  0.4618, -0.1001,  0.4501, -1.8627],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ln(a*10+2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(NN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.GELU()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        # out = self.softmax(out)\n",
    "        return out\n",
    "model = NN(50, 50, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0780], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model.train()\n",
    "model(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Linearcls(256, p0=0.2, dropout=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.8889)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([0.5, 0.4, 0.3, 0.2, 0.1]).unsqueeze(0)\n",
    "b = torch.tensor([0.1, 0.2, 0.3, 0.4, 0.5]).unsqueeze(0)\n",
    "listMLE(b, torch.tensor(range(5)).unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(85, 50) \n",
    "b = torch.tensor(range(85)).float().unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13.,\n",
       "         14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25., 26., 27.,\n",
       "         28., 29., 30., 31., 32., 33., 34., 35., 36., 37., 38., 39., 40., 41.,\n",
       "         42., 43., 44., 45., 46., 47., 48., 49., 50., 51., 52., 53., 54., 55.,\n",
       "         56., 57., 58., 59., 60., 61., 62., 63., 64., 65., 66., 67., 68., 69.,\n",
       "         70., 71., 72., 73., 74., 75., 76., 77., 78., 79., 80., 81., 82., 83.,\n",
       "         84.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cri = models.ListMLE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(291.3251), tensor(295.7650))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.tensor([ 3.5803e-04,  2.1979e-03,  3.8311e-04,  5.2792e-04,  4.8840e-04,\n",
    "         1.0956e-03,  4.0375e-04,  2.1282e-03, -1.0719e-03,  2.1690e-03,\n",
    "         3.5637e-04,  7.8660e-04, -1.7349e-04,  1.1136e-03,  1.4135e-03,\n",
    "        -5.7234e-05, -1.9069e-04,  1.5373e-03, -1.5336e-04,  5.0368e-04,\n",
    "         1.0354e-03,  9.4463e-04,  1.5163e-03,  1.9483e-03,  6.8653e-04,\n",
    "         1.1449e-03,  1.4879e-04,  3.3806e-04,  1.5077e-03,  9.2047e-04,\n",
    "         2.3447e-03,  2.2386e-03,  1.4788e-03,  1.7258e-03, -2.6664e-04,\n",
    "        -1.5059e-04,  6.0289e-04, -6.1682e-04,  7.1805e-04,  1.0268e-03,\n",
    "         2.7502e-03, -7.3034e-04, -8.2444e-05, -7.1462e-04,  1.1572e-03,\n",
    "         7.2149e-04,  6.2846e-04,  1.6673e-03,  1.2135e-03,  1.4576e-03,\n",
    "         1.4565e-03,  1.9022e-03, -4.4323e-04,  8.4509e-04,  8.5283e-04,\n",
    "         3.7751e-04,  1.6441e-03,  7.9547e-04, -1.8599e-04,  2.2232e-04,\n",
    "         9.0810e-04,  1.7102e-03,  5.1223e-04,  7.4762e-05, -5.0921e-04,\n",
    "         2.4580e-03,  1.3834e-03,  1.8816e-04,  1.7089e-03,  1.1783e-03,\n",
    "         1.0902e-03,  9.6748e-06,  7.7385e-04,  2.1562e-03,  8.9369e-04,\n",
    "         1.0644e-03,  4.2991e-05,  1.5249e-03,  2.2387e-03, -1.2712e-03,\n",
    "         3.6258e-04, -3.7134e-04,  2.8287e-04,  2.0146e-03,  2.1470e-03])\n",
    "listMLE(t.unsqueeze(0), torch.tensor(range(len(t))).unsqueeze(0)), cri(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(298.6251, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cri(model(a).squeeze(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1719],\n",
       "        [ 0.0232],\n",
       "        [ 0.1478],\n",
       "        [-0.3223],\n",
       "        [ 0.0409],\n",
       "        [-0.2715],\n",
       "        [-0.0988],\n",
       "        [-0.1593],\n",
       "        [ 0.0015],\n",
       "        [-0.4033],\n",
       "        [-0.4174],\n",
       "        [-0.4033],\n",
       "        [-0.2422],\n",
       "        [-0.1940],\n",
       "        [ 0.3468],\n",
       "        [-0.2545],\n",
       "        [-0.1316],\n",
       "        [-0.1732],\n",
       "        [-0.2200],\n",
       "        [-0.3019],\n",
       "        [-0.0202],\n",
       "        [-0.2633],\n",
       "        [-0.2919],\n",
       "        [-0.0913],\n",
       "        [-0.1816],\n",
       "        [ 0.0142],\n",
       "        [ 0.0456],\n",
       "        [-0.0702],\n",
       "        [-0.4243],\n",
       "        [-0.2370],\n",
       "        [-0.1419],\n",
       "        [-0.3999],\n",
       "        [-0.2288],\n",
       "        [-0.2057],\n",
       "        [-0.1580],\n",
       "        [-0.1026],\n",
       "        [-0.0859],\n",
       "        [-0.1071],\n",
       "        [-0.1817],\n",
       "        [-0.0507],\n",
       "        [-0.0473],\n",
       "        [-0.0468],\n",
       "        [-0.3241],\n",
       "        [ 0.0374],\n",
       "        [ 0.0046],\n",
       "        [-0.1215],\n",
       "        [-0.2482],\n",
       "        [-0.2893],\n",
       "        [-0.1320],\n",
       "        [ 0.1539],\n",
       "        [-0.1502],\n",
       "        [ 0.0855],\n",
       "        [ 0.0929],\n",
       "        [-0.1974],\n",
       "        [-0.4818],\n",
       "        [ 0.1231],\n",
       "        [-0.2769],\n",
       "        [-0.2654],\n",
       "        [-0.2120],\n",
       "        [-0.0330],\n",
       "        [-0.2568],\n",
       "        [ 0.1294],\n",
       "        [ 0.0472],\n",
       "        [-0.3249],\n",
       "        [-0.1694],\n",
       "        [ 0.0586],\n",
       "        [-0.2214],\n",
       "        [ 0.0786],\n",
       "        [-0.4206],\n",
       "        [-0.2201],\n",
       "        [-0.1833],\n",
       "        [-0.4648],\n",
       "        [-0.2233],\n",
       "        [-0.4330],\n",
       "        [-0.0648],\n",
       "        [-0.1225],\n",
       "        [ 0.0961],\n",
       "        [ 0.1179],\n",
       "        [ 0.0008],\n",
       "        [ 0.4616],\n",
       "        [ 0.3030],\n",
       "        [ 0.0882],\n",
       "        [-0.0654],\n",
       "        [-0.0729],\n",
       "        [-0.0837]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeds = embeds.to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc1.weight Parameter containing:\n",
      "tensor([[-0.0279,  0.0043,  0.1825,  ..., -0.1534, -0.1215,  0.2763],\n",
      "        [ 0.0121, -0.1111,  0.1724,  ..., -0.3070,  0.0582, -0.0786],\n",
      "        [-0.0142, -0.1625,  0.2000,  ..., -0.0525,  0.0381, -0.1630],\n",
      "        ...,\n",
      "        [-0.3378,  0.1492,  0.2998,  ...,  0.2824, -0.3519, -0.1671],\n",
      "        [-0.2589, -0.0412,  0.0214,  ..., -0.1667,  0.1242,  0.2417],\n",
      "        [ 0.3284, -0.1897, -0.0264,  ..., -0.1723,  0.2315,  0.2736]],\n",
      "       requires_grad=True)\n",
      "fc1.bias Parameter containing:\n",
      "tensor([ 0.1124,  0.0783,  0.1414,  0.0805,  0.1332,  0.1182,  0.2013,  0.2869,\n",
      "         0.1947,  0.0760, -0.1375,  0.2667,  0.0584,  0.1275,  0.1456,  0.2045,\n",
      "         0.1409,  0.1069,  0.3160,  0.1832,  0.2036,  0.0835,  0.2350,  0.1788,\n",
      "        -0.0908,  0.0475,  0.2332,  0.0854,  0.1001,  0.0647, -0.0127,  0.0817,\n",
      "         0.2769,  0.1208,  0.2200,  0.2132,  0.1891,  0.0272,  0.1092,  0.1077,\n",
      "         0.2005,  0.0364,  0.1362,  0.1097,  0.1636,  0.1569,  0.2000,  0.1451,\n",
      "         0.0858,  0.2234], requires_grad=True)\n",
      "fc2.weight Parameter containing:\n",
      "tensor([[ 0.2545,  0.2311,  0.2603, -0.3232,  0.2515, -0.3314, -0.3267, -0.2937,\n",
      "         -0.2908,  0.2782, -0.2810, -0.2548,  0.2348, -0.3202, -0.2792, -0.2576,\n",
      "          0.2600, -0.3757,  0.2349, -0.2800, -0.2465, -0.2680,  0.2302,  0.2947,\n",
      "         -0.2286,  0.3445, -0.2728,  0.3110, -0.2567,  0.2673,  0.2449,  0.3360,\n",
      "         -0.2211,  0.2972, -0.2319, -0.2303,  0.2409, -0.3065, -0.2692,  0.2429,\n",
      "          0.2623, -0.2791, -0.2888,  0.2004, -0.3673,  0.3290,  0.2782, -0.2588,\n",
      "          0.3149, -0.2296]], requires_grad=True)\n",
      "fc2.bias Parameter containing:\n",
      "tensor([-0.0389], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for i, j in model.named_parameters():\n",
    "    print(i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291.46185302734375\n",
      "284.89581298828125\n",
      "278.4154968261719\n",
      "271.0216064453125\n",
      "262.43304443359375\n",
      "252.792724609375\n",
      "242.41966247558594\n",
      "231.54661560058594\n",
      "220.30198669433594\n",
      "208.88369750976562\n",
      "197.58184814453125\n",
      "186.66175842285156\n",
      "176.27749633789062\n",
      "166.52468872070312\n",
      "157.51181030273438\n",
      "149.46783447265625\n",
      "142.9174041748047\n",
      "138.11264038085938\n",
      "134.81072998046875\n",
      "132.6311492919922\n",
      "131.20948791503906\n",
      "130.210205078125\n",
      "129.5453338623047\n",
      "129.45982360839844\n",
      "129.21636962890625\n",
      "129.2898712158203\n",
      "129.11300659179688\n",
      "129.08448791503906\n",
      "128.95175170898438\n",
      "128.96481323242188\n",
      "128.9128875732422\n",
      "128.9095458984375\n",
      "128.8632354736328\n",
      "128.71414184570312\n",
      "128.7430419921875\n",
      "128.76937866210938\n",
      "128.89527893066406\n",
      "128.8540802001953\n",
      "128.66522216796875\n",
      "128.8581085205078\n",
      "128.639404296875\n",
      "128.7723388671875\n",
      "128.77435302734375\n",
      "128.9160919189453\n",
      "128.75860595703125\n",
      "128.9180145263672\n",
      "128.73268127441406\n",
      "128.80215454101562\n",
      "128.7133026123047\n",
      "128.67440795898438\n",
      "128.78245544433594\n",
      "128.760498046875\n",
      "128.78074645996094\n",
      "128.86822509765625\n",
      "128.73895263671875\n",
      "128.859375\n",
      "128.92279052734375\n",
      "128.66078186035156\n",
      "128.7006378173828\n",
      "128.64401245117188\n",
      "128.85919189453125\n",
      "128.6962127685547\n",
      "128.80677795410156\n",
      "128.72918701171875\n",
      "128.62661743164062\n",
      "128.77085876464844\n",
      "128.74526977539062\n",
      "128.74700927734375\n",
      "128.70864868164062\n",
      "128.70159912109375\n",
      "129.0113525390625\n",
      "128.81886291503906\n",
      "128.9272003173828\n",
      "128.7576904296875\n",
      "128.71527099609375\n",
      "128.78073120117188\n",
      "128.6793975830078\n",
      "128.6883544921875\n",
      "128.7140655517578\n",
      "128.74676513671875\n",
      "128.64813232421875\n",
      "128.77279663085938\n",
      "128.8035430908203\n",
      "128.84129333496094\n",
      "128.6123046875\n",
      "128.8085174560547\n",
      "128.74533081054688\n",
      "128.7650604248047\n",
      "128.79971313476562\n",
      "128.85067749023438\n",
      "128.8571014404297\n",
      "128.74110412597656\n",
      "128.7857666015625\n",
      "128.66986083984375\n",
      "128.7969207763672\n",
      "128.72938537597656\n",
      "128.68984985351562\n",
      "128.804443359375\n",
      "128.81138610839844\n",
      "128.7781524658203\n"
     ]
    }
   ],
   "source": [
    "q = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "for i in range(1000):\n",
    "    q.zero_grad()\n",
    "    # loss = cri(model(embeds).squeeze(1))\n",
    "    loss = listMLE(model(a).T, b)\n",
    "    loss.backward()\n",
    "    q.step()\n",
    "    if i % 10 == 0:\n",
    "        print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'state': {0: {'step': tensor(1000.),\n",
       "   'exp_avg': tensor([[ 0.3624, -0.0180,  0.0869,  ...,  0.1210, -0.1889, -0.0382],\n",
       "           [ 0.3376, -0.0175,  0.0706,  ...,  0.1113, -0.1621, -0.0224],\n",
       "           [ 0.3828, -0.0033,  0.1014,  ...,  0.1104, -0.1883, -0.0070],\n",
       "           ...,\n",
       "           [-0.0309,  0.0461,  0.0257,  ..., -0.0556,  0.0204, -0.0142],\n",
       "           [ 0.4842, -0.0369,  0.1025,  ...,  0.1440, -0.2434, -0.0419],\n",
       "           [-0.2140,  0.0103, -0.0538,  ..., -0.0549,  0.1110,  0.0041]]),\n",
       "   'exp_avg_sq': tensor([[1.0088, 0.0942, 0.1916,  ..., 0.3879, 0.3529, 0.7078],\n",
       "           [0.7957, 0.0746, 0.1558,  ..., 0.2263, 0.2691, 0.4234],\n",
       "           [1.1089, 0.1546, 0.1994,  ..., 0.2568, 0.3463, 0.0579],\n",
       "           ...,\n",
       "           [0.1074, 0.0681, 0.0455,  ..., 0.2289, 0.0395, 0.0111],\n",
       "           [1.5793, 0.1695, 0.3196,  ..., 0.3848, 0.5516, 1.0559],\n",
       "           [0.2913, 0.0523, 0.0579,  ..., 0.0755, 0.1181, 0.4904]])},\n",
       "  1: {'step': tensor(1000.),\n",
       "   'exp_avg': tensor([ 0.0069,  0.0052,  0.0127, -0.1112, -0.0652, -0.0453, -0.0911, -0.1255,\n",
       "            0.0358, -0.0899,  0.0347, -0.0620, -0.0977,  0.0174,  0.0597,  0.0250,\n",
       "           -0.0276,  0.0238,  0.0248, -0.0551, -0.0652,  0.0729, -0.0017,  0.0102,\n",
       "            0.0685, -0.0421,  0.0896,  0.0148, -0.0068, -0.0157, -0.0853,  0.0101,\n",
       "            0.0832,  0.0143,  0.0782, -0.0331, -0.0130, -0.0893, -0.0206,  0.0164,\n",
       "           -0.0094,  0.0115, -0.0072,  0.0067, -0.0828,  0.0284,  0.0719,  0.0579,\n",
       "           -0.0213,  0.0159]),\n",
       "   'exp_avg_sq': tensor([0.0061, 0.0024, 0.1150, 0.1245, 0.1282, 0.1059, 0.1087, 0.1186, 0.0580,\n",
       "           0.1812, 0.0932, 0.0654, 0.1228, 0.1099, 0.0671, 0.0631, 0.1228, 0.1487,\n",
       "           0.0180, 0.0710, 0.0681, 0.0917, 0.0940, 0.1659, 0.0635, 0.1421, 0.0756,\n",
       "           0.0816, 0.1179, 0.1629, 0.1411, 0.0700, 0.0722, 0.0092, 0.0793, 0.0200,\n",
       "           0.1081, 0.0671, 0.0659, 0.0084, 0.0628, 0.0830, 0.1064, 0.0041, 0.1091,\n",
       "           0.0100, 0.1588, 0.0663, 0.0287, 0.0551])},\n",
       "  2: {'step': tensor(1000.),\n",
       "   'exp_avg': tensor([[ 0.1256,  0.2336,  0.5462,  0.2878, -0.5607, -0.0281,  0.2868,  0.4345,\n",
       "            -0.1415, -0.3748, -0.1721,  0.1174, -0.5509,  0.0542, -0.3491, -0.1950,\n",
       "            -0.1054, -0.0547,  0.1461,  0.1179,  0.2531, -0.1737, -0.1319,  0.3002,\n",
       "            -0.1792, -0.6011, -0.1583,  0.1950,  0.1198, -0.2699, -0.6696,  0.3225,\n",
       "            -0.5121, -0.2529, -0.5007,  0.1117,  0.3253,  0.1989,  0.0963, -0.1695,\n",
       "            -0.2552,  0.0141,  0.0456, -0.1138,  0.1909, -0.6597,  0.9257, -0.0575,\n",
       "            -0.3938, -0.0968]]),\n",
       "   'exp_avg_sq': tensor([[ 9.4297, 15.6054,  8.4876,  2.3040, 17.2553,  3.1336,  2.1094,  3.5121,\n",
       "             2.3842,  9.2341,  5.0681,  2.1786, 19.3084,  4.7234,  3.1900,  4.7682,\n",
       "             3.7419,  3.0520,  7.5869,  1.0606,  3.4148,  1.8034,  7.6449, 12.3677,\n",
       "             1.2048, 10.1314,  2.7887,  5.1834,  3.6890, 11.8587,  7.3933,  7.3670,\n",
       "             5.9031,  3.6280,  6.9617,  1.5081, 10.4545,  1.5974,  2.1161,  8.3644,\n",
       "             8.1725,  3.2835,  2.8401,  9.5150,  2.1405,  5.2129, 18.6755,  5.0030,\n",
       "             8.8290,  5.2571]])},\n",
       "  3: {'step': tensor(1000.),\n",
       "   'exp_avg': tensor([-3.2321e-08]),\n",
       "   'exp_avg_sq': tensor([4.0164e-14])}},\n",
       " 'param_groups': [{'lr': 0.001,\n",
       "   'betas': (0.9, 0.999),\n",
       "   'eps': 1e-08,\n",
       "   'weight_decay': 0,\n",
       "   'amsgrad': False,\n",
       "   'maximize': False,\n",
       "   'foreach': None,\n",
       "   'capturable': False,\n",
       "   'differentiable': False,\n",
       "   'fused': None,\n",
       "   'params': [0, 1, 2, 3]}]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -1.8344],\n",
       "        [-10.8776],\n",
       "        [-10.6649],\n",
       "        [-10.3965],\n",
       "        [-10.1751],\n",
       "        [ -9.8600],\n",
       "        [ -9.6131],\n",
       "        [ -9.3776],\n",
       "        [ -9.1433],\n",
       "        [ -8.8702],\n",
       "        [ -8.6376],\n",
       "        [ -8.3426],\n",
       "        [ -8.1251],\n",
       "        [ -7.8258],\n",
       "        [ -7.6583],\n",
       "        [ -7.3539],\n",
       "        [ -7.0861],\n",
       "        [ -6.8799],\n",
       "        [ -6.5894],\n",
       "        [ -6.3686],\n",
       "        [ -6.0891],\n",
       "        [ -5.8393],\n",
       "        [ -5.5828],\n",
       "        [ -5.3361],\n",
       "        [ -5.0743],\n",
       "        [ -4.8626],\n",
       "        [ -4.5704],\n",
       "        [ -4.3510],\n",
       "        [ -3.9892],\n",
       "        [ -3.8003],\n",
       "        [ -3.5776],\n",
       "        [ -3.3267],\n",
       "        [ -3.0435],\n",
       "        [ -2.7844],\n",
       "        [ -2.5751],\n",
       "        [ -2.2815],\n",
       "        [ -2.0667],\n",
       "        [ -1.7644],\n",
       "        [ -1.5289],\n",
       "        [ -1.2880],\n",
       "        [ -1.0456],\n",
       "        [ -0.7574],\n",
       "        [ -0.4885],\n",
       "        [ -0.2374],\n",
       "        [  0.0395],\n",
       "        [  0.2724],\n",
       "        [  0.4757],\n",
       "        [  0.7451],\n",
       "        [  0.9777],\n",
       "        [  1.2863],\n",
       "        [  1.5187],\n",
       "        [  1.7922],\n",
       "        [  2.0076],\n",
       "        [  2.2806],\n",
       "        [  2.5184],\n",
       "        [  2.8293],\n",
       "        [  2.9897],\n",
       "        [  3.2998],\n",
       "        [  3.5542],\n",
       "        [  3.7831],\n",
       "        [  4.0065],\n",
       "        [  4.3110],\n",
       "        [  4.5410],\n",
       "        [  4.8380],\n",
       "        [  5.1084],\n",
       "        [  5.2647],\n",
       "        [  5.5611],\n",
       "        [  5.7984],\n",
       "        [  6.0770],\n",
       "        [  6.3487],\n",
       "        [  6.5776],\n",
       "        [  6.7896],\n",
       "        [  7.1187],\n",
       "        [  7.3275],\n",
       "        [  7.5954],\n",
       "        [  7.8266],\n",
       "        [  8.1518],\n",
       "        [  8.3724],\n",
       "        [  8.6022],\n",
       "        [  8.7622],\n",
       "        [  8.6580],\n",
       "        [  8.6188],\n",
       "        [  8.6914],\n",
       "        [  8.7918],\n",
       "        [  8.7404]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = models.ListMLE() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.3083)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a(b.squeeze(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 885"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>average</th>\n",
       "      <th>datav2_1130_e22</th>\n",
       "      <th>datav2_1125_v2_e9</th>\n",
       "      <th>v4_1125_e7</th>\n",
       "      <th>geomean1</th>\n",
       "      <th>geomean2</th>\n",
       "      <th>DeepPLM_mCNN</th>\n",
       "      <th>domain885_e7</th>\n",
       "      <th>testdomain_e9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MKPLCTPWVDGTILCSLLFLLAFSGVSSAWSNDTKLPQRRSGHLRD...</td>\n",
       "      <td>GSMKPLCTPWVDGTILCSLLFLLAFSGVSSAWSNDTKLPQRRSGHL...</td>\n",
       "      <td>VIL1</td>\n",
       "      <td>0.764076</td>\n",
       "      <td>0.866837</td>\n",
       "      <td>0.963859</td>\n",
       "      <td>0.994411</td>\n",
       "      <td>0.940096</td>\n",
       "      <td>0.892614</td>\n",
       "      <td>0.100018</td>\n",
       "      <td>0.210354</td>\n",
       "      <td>0.614913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MLRYPWLQLLATFLLFEVSLCCFFSKKGLTTSYNRRFHYRWIQLNR...</td>\n",
       "      <td>GSMLRYPWLQLLATFLLFEVSLCCFFSKKGLTTSYNRRFHYRWIQL...</td>\n",
       "      <td>VIL2</td>\n",
       "      <td>0.428990</td>\n",
       "      <td>0.565509</td>\n",
       "      <td>0.256785</td>\n",
       "      <td>0.528166</td>\n",
       "      <td>0.424874</td>\n",
       "      <td>0.425899</td>\n",
       "      <td>0.166094</td>\n",
       "      <td>0.316010</td>\n",
       "      <td>0.588083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MGRQDTSREGNEDYEDIMRWVRRFVWLTRVYTVLAVQMAVTLAFCL...</td>\n",
       "      <td>GSMGRQDTSREGNEDYEDIMRWVRRFVWLTRVYTVLAVQMAVTLAF...</td>\n",
       "      <td>VIL3</td>\n",
       "      <td>0.599692</td>\n",
       "      <td>0.911146</td>\n",
       "      <td>0.906326</td>\n",
       "      <td>0.996002</td>\n",
       "      <td>0.936938</td>\n",
       "      <td>0.838041</td>\n",
       "      <td>0.298704</td>\n",
       "      <td>0.834467</td>\n",
       "      <td>0.856670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MEVLRFQVRFTESIIWIQRFKILIQLYSYWLLQVTVTSTLSTLMWL...</td>\n",
       "      <td>GSMEVLRFQVRFTESIIWIQRFKILIQLYSYWLLQVTVTSTLSTLM...</td>\n",
       "      <td>VIL4</td>\n",
       "      <td>0.822577</td>\n",
       "      <td>0.970665</td>\n",
       "      <td>0.952568</td>\n",
       "      <td>0.935138</td>\n",
       "      <td>0.952680</td>\n",
       "      <td>0.918342</td>\n",
       "      <td>0.364926</td>\n",
       "      <td>0.775129</td>\n",
       "      <td>0.871358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MDHRSYADAELAESWMHENLVQWIDRFRSVVAIYSNALFEVAGTLS...</td>\n",
       "      <td>GSMDHRSYADAELAESWMHENLVQWIDRFRSVVAIYSNALFEVAGT...</td>\n",
       "      <td>VIL5</td>\n",
       "      <td>0.633763</td>\n",
       "      <td>0.995752</td>\n",
       "      <td>0.529931</td>\n",
       "      <td>0.994043</td>\n",
       "      <td>0.806477</td>\n",
       "      <td>0.759321</td>\n",
       "      <td>0.368040</td>\n",
       "      <td>0.732566</td>\n",
       "      <td>0.850245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    \\\n",
       "num                                                      \n",
       "0    MKPLCTPWVDGTILCSLLFLLAFSGVSSAWSNDTKLPQRRSGHLRD...   \n",
       "1    MLRYPWLQLLATFLLFEVSLCCFFSKKGLTTSYNRRFHYRWIQLNR...   \n",
       "2    MGRQDTSREGNEDYEDIMRWVRRFVWLTRVYTVLAVQMAVTLAFCL...   \n",
       "3    MEVLRFQVRFTESIIWIQRFKILIQLYSYWLLQVTVTSTLSTLMWL...   \n",
       "4    MDHRSYADAELAESWMHENLVQWIDRFRSVVAIYSNALFEVAGTLS...   \n",
       "\n",
       "                                                     average  \\\n",
       "num                                                                      \n",
       "0    GSMKPLCTPWVDGTILCSLLFLLAFSGVSSAWSNDTKLPQRRSGHL...  VIL1  0.764076   \n",
       "1    GSMLRYPWLQLLATFLLFEVSLCCFFSKKGLTTSYNRRFHYRWIQL...  VIL2  0.428990   \n",
       "2    GSMGRQDTSREGNEDYEDIMRWVRRFVWLTRVYTVLAVQMAVTLAF...  VIL3  0.599692   \n",
       "3    GSMEVLRFQVRFTESIIWIQRFKILIQLYSYWLLQVTVTSTLSTLM...  VIL4  0.822577   \n",
       "4    GSMDHRSYADAELAESWMHENLVQWIDRFRSVVAIYSNALFEVAGT...  VIL5  0.633763   \n",
       "\n",
       "     datav2_1130_e22  datav2_1125_v2_e9  v4_1125_e7  geomean1  geomean2  \\\n",
       "num                                                                       \n",
       "0           0.866837           0.963859    0.994411  0.940096  0.892614   \n",
       "1           0.565509           0.256785    0.528166  0.424874  0.425899   \n",
       "2           0.911146           0.906326    0.996002  0.936938  0.838041   \n",
       "3           0.970665           0.952568    0.935138  0.952680  0.918342   \n",
       "4           0.995752           0.529931    0.994043  0.806477  0.759321   \n",
       "\n",
       "     DeepPLM_mCNN  domain885_e7  testdomain_e9  \n",
       "num                                             \n",
       "0        0.100018      0.210354       0.614913  \n",
       "1        0.166094      0.316010       0.588083  \n",
       "2        0.298704      0.834467       0.856670  \n",
       "3        0.364926      0.775129       0.871358  \n",
       "4        0.368040      0.732566       0.850245  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(\"./temp/1204.xlsx\", sheet_name=\"Sheet1\", index_col=0)\n",
    "# df = df[~pd.isnull(df[\"\"])]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "885"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>name2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MKPLCTPWVDGTILCSLLFLLAFSGVSSAWSNDTKLPQRRSGHLRD...</td>\n",
       "      <td>GSMKPLCTPWVDGTILCSLLFLLAFSGVSSAWSNDTKLPQRRSGHL...</td>\n",
       "      <td>VIL1</td>\n",
       "      <td>VILH-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MLRYPWLQLLATFLLFEVSLCCFFSKKGLTTSYNRRFHYRWIQLNR...</td>\n",
       "      <td>GSMLRYPWLQLLATFLLFEVSLCCFFSKKGLTTSYNRRFHYRWIQL...</td>\n",
       "      <td>VIL2</td>\n",
       "      <td>VILH-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MGRQDTSREGNEDYEDIMRWVRRFVWLTRVYTVLAVQMAVTLAFCL...</td>\n",
       "      <td>GSMGRQDTSREGNEDYEDIMRWVRRFVWLTRVYTVLAVQMAVTLAF...</td>\n",
       "      <td>VIL3</td>\n",
       "      <td>VILH-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MEVLRFQVRFTESIIWIQRFKILIQLYSYWLLQVTVTSTLSTLMWL...</td>\n",
       "      <td>GSMEVLRFQVRFTESIIWIQRFKILIQLYSYWLLQVTVTSTLSTLM...</td>\n",
       "      <td>VIL4</td>\n",
       "      <td>VILH-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MDHRSYADAELAESWMHENLVQWIDRFRSVVAIYSNALFEVAGTLS...</td>\n",
       "      <td>GSMDHRSYADAELAESWMHENLVQWIDRFRSVVAIYSNALFEVAGT...</td>\n",
       "      <td>VIL5</td>\n",
       "      <td>VILH-5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    \\\n",
       "num                                                      \n",
       "0    MKPLCTPWVDGTILCSLLFLLAFSGVSSAWSNDTKLPQRRSGHLRD...   \n",
       "1    MLRYPWLQLLATFLLFEVSLCCFFSKKGLTTSYNRRFHYRWIQLNR...   \n",
       "2    MGRQDTSREGNEDYEDIMRWVRRFVWLTRVYTVLAVQMAVTLAFCL...   \n",
       "3    MEVLRFQVRFTESIIWIQRFKILIQLYSYWLLQVTVTSTLSTLMWL...   \n",
       "4    MDHRSYADAELAESWMHENLVQWIDRFRSVVAIYSNALFEVAGTLS...   \n",
       "\n",
       "                                                     name2  \n",
       "num                                                                   \n",
       "0    GSMKPLCTPWVDGTILCSLLFLLAFSGVSSAWSNDTKLPQRRSGHL...  VIL1  VILH-1  \n",
       "1    GSMLRYPWLQLLATFLLFEVSLCCFFSKKGLTTSYNRRFHYRWIQL...  VIL2  VILH-2  \n",
       "2    GSMGRQDTSREGNEDYEDIMRWVRRFVWLTRVYTVLAVQMAVTLAF...  VIL3  VILH-3  \n",
       "3    GSMEVLRFQVRFTESIIWIQRFKILIQLYSYWLLQVTVTSTLSTLM...  VIL4  VILH-4  \n",
       "4    GSMDHRSYADAELAESWMHENLVQWIDRFRSVVAIYSNALFEVAGT...  VIL5  VILH-5  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[[\"\", \"\", \"\"]]\n",
    "df[\"name2\"] = df[\"\"].apply(lambda x: x[:3]+\"H-\"+x[3:])\n",
    "df.to_csv(\"./temp/all885.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VILH-301</td>\n",
       "      <td>GSMPPQRARGAPPRRRGSDPPDPGSLAGRLSPGGRSGGGSRRTLSR...</td>\n",
       "      <td>MPPQRARGAPPRRRGSDPPDPGSLAGRLSPGGRSGGGSRRTLSRSS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VILH-197</td>\n",
       "      <td>GSMRASKSDRFLMSSWVKLLFVAVIMYICSAVVPMAATYEGLGFPC...</td>\n",
       "      <td>MRASKSDRFLMSSWVKLLFVAVIMYICSAVVPMAATYEGLGFPCYF...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VILH-19</td>\n",
       "      <td>GSMAPSKVDSVNSRIWGISVFLAFLTFANICGHTTMMNVPGVGYPC...</td>\n",
       "      <td>MAPSKVDSVNSRIWGISVFLAFLTFANICGHTTMMNVPGVGYPCSY...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VILH-363</td>\n",
       "      <td>GSMDAVSALCVALASAAAMFVALQMWAVYENYDNIREFNSANAALE...</td>\n",
       "      <td>MDAVSALCVALASAAAMFVALQMWAVYENYDNIREFNSANAALEFA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VILH-426</td>\n",
       "      <td>GSMDKTTLSVNACNLEYVREKAIVGVQAAKTSTLIFFVIILAISAL...</td>\n",
       "      <td>MDKTTLSVNACNLEYVREKAIVGVQAAKTSTLIFFVIILAISALLL...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      \\\n",
       "0  VILH-301  GSMPPQRARGAPPRRRGSDPPDPGSLAGRLSPGGRSGGGSRRTLSR...   \n",
       "1  VILH-197  GSMRASKSDRFLMSSWVKLLFVAVIMYICSAVVPMAATYEGLGFPC...   \n",
       "2   VILH-19  GSMAPSKVDSVNSRIWGISVFLAFLTFANICGHTTMMNVPGVGYPC...   \n",
       "3  VILH-363  GSMDAVSALCVALASAAAMFVALQMWAVYENYDNIREFNSANAALE...   \n",
       "4  VILH-426  GSMDKTTLSVNACNLEYVREKAIVGVQAAKTSTLIFFVIILAISAL...   \n",
       "\n",
       "                                             .1  \n",
       "0  MPPQRARGAPPRRRGSDPPDPGSLAGRLSPGGRSGGGSRRTLSRSS...  \n",
       "1  MRASKSDRFLMSSWVKLLFVAVIMYICSAVVPMAATYEGLGFPCYF...  \n",
       "2  MAPSKVDSVNSRIWGISVFLAFLTFANICGHTTMMNVPGVGYPCSY...  \n",
       "3  MDAVSALCVALASAAAMFVALQMWAVYENYDNIREFNSANAALEFA...  \n",
       "4  MDKTTLSVNACNLEYVREKAIVGVQAAKTSTLIFFVIILAISALLL...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfexp = pd.read_excel(\"./temp/1210_.xlsx\", sheet_name=\"Sheet1\")\n",
    "# dfexp[\"new\"] = dfexp[\".1\"].map(df[\"new\"])\n",
    "dfexp2 = pd.read_excel(\"./temp/1210_.xlsx\", sheet_name=\"Sheet2\")\n",
    "dfexp2 = dfexp2.sort_values(\"final_p\", ascending=False)\n",
    "dfexp2[\"rank\"] = range(len(dfexp2))\n",
    "# dfexp2[\"rank\"] = -dfexp2[\"rank\"]\n",
    "# dfexp[\"rank\"] = dfexp[\"\"].map(dfexp2.set_index(\"Name\")[\"rank\"])\n",
    "# dfexp = dfexp.sort_values(\"rank\")\n",
    "dfexp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'VILH-828': 0,\n",
       " 'VILH-53': 1,\n",
       " 'VILH-791': 2,\n",
       " 'VILH-295': 3,\n",
       " 'VILH-284': 4,\n",
       " 'VILH-149': 5,\n",
       " 'VILH-238': 6,\n",
       " 'VILH-537': 7,\n",
       " 'VILH-796': 8,\n",
       " 'VILH-151': 9,\n",
       " 'VILH-534': 10,\n",
       " 'VILH-736': 11,\n",
       " 'VILH-776': 12,\n",
       " 'VILH-731': 13,\n",
       " 'VILH-845': 14,\n",
       " 'VILH-511': 15,\n",
       " 'VILH-228': 16,\n",
       " 'VILH-518': 17,\n",
       " 'VILH-188': 18,\n",
       " 'VILH-802': 19,\n",
       " 'VILH-450': 20,\n",
       " 'VILH-63': 21,\n",
       " 'VILH-179': 22,\n",
       " 'VILH-787': 23,\n",
       " 'VILH-129': 24,\n",
       " 'VILH-311': 25,\n",
       " 'VILH-559': 26,\n",
       " 'VILH-741': 27,\n",
       " 'VILH-325': 28,\n",
       " 'VILH-131': 29,\n",
       " 'VILH-723': 30,\n",
       " 'VILH-713': 31,\n",
       " 'VILH-591': 32,\n",
       " 'VILH-712': 33,\n",
       " 'VILH-62': 34,\n",
       " 'VILH-827': 35,\n",
       " 'VILH-752': 36,\n",
       " 'VILH-594': 37,\n",
       " 'VILH-525': 38,\n",
       " 'VILH-282': 39,\n",
       " 'VILH-732': 40,\n",
       " 'VILH-124': 41,\n",
       " 'VILH-749': 42,\n",
       " 'VILH-786': 43,\n",
       " 'VILH-254': 44,\n",
       " 'VILH-503': 45,\n",
       " 'VILH-449': 46,\n",
       " 'VILH-453': 47,\n",
       " 'VILH-581': 48,\n",
       " 'VILH-280': 49,\n",
       " 'VILH-259': 50,\n",
       " 'VILH-150': 51,\n",
       " 'VILH-314': 52,\n",
       " 'VILH-144': 53,\n",
       " 'VILH-832': 54,\n",
       " 'VILH-194': 55,\n",
       " 'VILH-785': 56,\n",
       " 'VILH-456': 57,\n",
       " 'VILH-232': 58,\n",
       " 'VILH-267': 59,\n",
       " 'VILH-502': 60,\n",
       " 'VILH-759': 61,\n",
       " 'VILH-59': 62,\n",
       " 'VILH-801': 63,\n",
       " 'VILH-279': 64,\n",
       " 'VILH-211': 65,\n",
       " 'VILH-446': 66,\n",
       " 'VILH-366': 67,\n",
       " 'VILH-635': 68,\n",
       " 'VILH-757': 69,\n",
       " 'VILH-199': 70,\n",
       " 'VILH-293': 71,\n",
       " 'VILH-771': 72,\n",
       " 'VILH-640': 73,\n",
       " 'VILH-265': 74,\n",
       " 'VILH-2': 75,\n",
       " 'VILH-204': 76,\n",
       " 'VILH-313': 77,\n",
       " 'VILH-241': 78,\n",
       " 'VILH-166': 79,\n",
       " 'VILH-681': 80,\n",
       " 'VILH-243': 81,\n",
       " 'VILH-815': 82,\n",
       " 'VILH-157': 83,\n",
       " 'VILH-844': 84,\n",
       " 'VILH-197': 85,\n",
       " 'VILH-154': 86,\n",
       " 'VILH-346': 87,\n",
       " 'VILH-200': 88,\n",
       " 'VILH-19': 89,\n",
       " 'VILH-743': 90,\n",
       " 'VILH-735': 91,\n",
       " 'VILH-429': 92,\n",
       " 'VILH-251': 93,\n",
       " 'VILH-515': 94,\n",
       " 'VILH-363': 95,\n",
       " 'VILH-426': 96,\n",
       " 'VILH-480': 97,\n",
       " 'VILH-61': 98,\n",
       " 'VILH-231': 99,\n",
       " 'VILH-838': 100,\n",
       " 'VILH-301': 101,\n",
       " 'VILH-730': 102,\n",
       " 'VILH-48': 103,\n",
       " 'VILH-5': 104,\n",
       " 'VILH-306': 105}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfexp2.head()\n",
    "dfexp2 = dfexp2.set_index(\"Name\")\n",
    "d = dict(dfexp2[\"rank\"])\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>experiment_1</th>\n",
       "      <th>experiment_2</th>\n",
       "      <th>yeast_1</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MLRYPWLQLLATFLLFEVSLCCFFSKKGLTTSYNRRFHYRWIQLNR...</td>\n",
       "      <td>GSMLRYPWLQLLATFLLFEVSLCCFFSKKGLTTSYNRRFHYRWIQL...</td>\n",
       "      <td>VIL2</td>\n",
       "      <td>75</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>VILH-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MDHRSYADAELAESWMHENLVQWIDRFRSVVAIYSNALFEVAGTLS...</td>\n",
       "      <td>GSMDHRSYADAELAESWMHENLVQWIDRFRSVVAIYSNALFEVAGT...</td>\n",
       "      <td>VIL5</td>\n",
       "      <td>104</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>VILH-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>MAPSKVDSVNSRIWGISVFLAFLTFANICGHTTMMNVPGVGYPCSY...</td>\n",
       "      <td>GSMAPSKVDSVNSRIWGISVFLAFLTFANICGHTTMMNVPGVGYPC...</td>\n",
       "      <td>VIL19</td>\n",
       "      <td>89</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>VILH-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>MAQARPQGHISWLWKWATSATNTNTHKLATKAPLNLSSEYRLNFAR...</td>\n",
       "      <td>GSMAQARPQGHISWLWKWATSATNTNTHKLATKAPLNLSSEYRLNF...</td>\n",
       "      <td>VIL48</td>\n",
       "      <td>103</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>VILH-48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>MPAIPVQYVNCVGVVGLVAFGLLSYQWIERKRRQGPLPQWFKEYLK...</td>\n",
       "      <td>GSMPAIPVQYVNCVGVVGLVAFGLLSYQWIERKRRQGPLPQWFKEY...</td>\n",
       "      <td>VIL53</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>VILH-53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>837</th>\n",
       "      <td>MNNATFNCTNINPITHIRGSIIITICVSLIVILIVFGCIAKIFINK...</td>\n",
       "      <td>GSMNNATFNCTNINPITHIRGSIIITICVSLIVILIVFGCIAKIFI...</td>\n",
       "      <td>VIL828</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>VILH-828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841</th>\n",
       "      <td>MLSLILFFPSFAFSATPVTPYYGPGHITSDWCGFGDSRSDCNNSYF...</td>\n",
       "      <td>GSMLSLILFFPSFAFSATPVTPYYGPGHITSDWCGFGDSRSDCNNS...</td>\n",
       "      <td>VIL832</td>\n",
       "      <td>54</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>VILH-832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>847</th>\n",
       "      <td>MGGWSSKPRQGMGTNLSVPNPLGFFPDHQLDPAFGANSNNPDWDFN...</td>\n",
       "      <td>GSMGGWSSKPRQGMGTNLSVPNPLGFFPDHQLDPAFGANSNNPDWD...</td>\n",
       "      <td>VIL838</td>\n",
       "      <td>100</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>VILH-838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853</th>\n",
       "      <td>MFLKLVDDHALVVNVILWCVVLIVLLLVCITIIKLIKLCFTCHMFC...</td>\n",
       "      <td>GSMFLKLVDDHALVVNVILWCVVLIVLLLVCITIIKLIKLCFTCHM...</td>\n",
       "      <td>VIL844</td>\n",
       "      <td>84</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>VILH-844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>854</th>\n",
       "      <td>MTEANITQEELVTHLKNWNFSWNIILTIFIVILQFGHYKYSRIFYG...</td>\n",
       "      <td>GSMTEANITQEELVTHLKNWNFSWNIILTIFIVILQFGHYKYSRIF...</td>\n",
       "      <td>VIL845</td>\n",
       "      <td>14</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>VILH-845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>106 rows  7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    \\\n",
       "num                                                      \n",
       "1    MLRYPWLQLLATFLLFEVSLCCFFSKKGLTTSYNRRFHYRWIQLNR...   \n",
       "4    MDHRSYADAELAESWMHENLVQWIDRFRSVVAIYSNALFEVAGTLS...   \n",
       "18   MAPSKVDSVNSRIWGISVFLAFLTFANICGHTTMMNVPGVGYPCSY...   \n",
       "48   MAQARPQGHISWLWKWATSATNTNTHKLATKAPLNLSSEYRLNFAR...   \n",
       "53   MPAIPVQYVNCVGVVGLVAFGLLSYQWIERKRRQGPLPQWFKEYLK...   \n",
       "..                                                 ...   \n",
       "837  MNNATFNCTNINPITHIRGSIIITICVSLIVILIVFGCIAKIFINK...   \n",
       "841  MLSLILFFPSFAFSATPVTPYYGPGHITSDWCGFGDSRSDCNNSYF...   \n",
       "847  MGGWSSKPRQGMGTNLSVPNPLGFFPDHQLDPAFGANSNNPDWDFN...   \n",
       "853  MFLKLVDDHALVVNVILWCVVLIVLLLVCITIIKLIKLCFTCHMFC...   \n",
       "854  MTEANITQEELVTHLKNWNFSWNIILTIFIVILQFGHYKYSRIFYG...   \n",
       "\n",
       "                                                      experiment_1  \\\n",
       "num                                                                            \n",
       "1    GSMLRYPWLQLLATFLLFEVSLCCFFSKKGLTTSYNRRFHYRWIQL...    VIL2            75   \n",
       "4    GSMDHRSYADAELAESWMHENLVQWIDRFRSVVAIYSNALFEVAGT...    VIL5           104   \n",
       "18   GSMAPSKVDSVNSRIWGISVFLAFLTFANICGHTTMMNVPGVGYPC...   VIL19            89   \n",
       "48   GSMAQARPQGHISWLWKWATSATNTNTHKLATKAPLNLSSEYRLNF...   VIL48           103   \n",
       "53   GSMPAIPVQYVNCVGVVGLVAFGLLSYQWIERKRRQGPLPQWFKEY...   VIL53             1   \n",
       "..                                                 ...     ...           ...   \n",
       "837  GSMNNATFNCTNINPITHIRGSIIITICVSLIVILIVFGCIAKIFI...  VIL828             0   \n",
       "841  GSMLSLILFFPSFAFSATPVTPYYGPGHITSDWCGFGDSRSDCNNS...  VIL832            54   \n",
       "847  GSMGGWSSKPRQGMGTNLSVPNPLGFFPDHQLDPAFGANSNNPDWD...  VIL838           100   \n",
       "853  GSMFLKLVDDHALVVNVILWCVVLIVLLLVCITIIKLIKLCFTCHM...  VIL844            84   \n",
       "854  GSMTEANITQEELVTHLKNWNFSWNIILTIFIVILQFGHYKYSRIF...  VIL845            14   \n",
       "\n",
       "     experiment_2  yeast_1      name  \n",
       "num                                   \n",
       "1              -1       -1    VILH-2  \n",
       "4              -1       -1    VILH-5  \n",
       "18             -1       -1   VILH-19  \n",
       "48             -1       -1   VILH-48  \n",
       "53             -1       -1   VILH-53  \n",
       "..            ...      ...       ...  \n",
       "837            -1       -1  VILH-828  \n",
       "841            -1       -1  VILH-832  \n",
       "847            -1       -1  VILH-838  \n",
       "853            -1       -1  VILH-844  \n",
       "854            -1       -1  VILH-845  \n",
       "\n",
       "[106 rows x 7 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# t = pd.read_csv(\"./temp/expres.csv\", index_col=0)\n",
    "# t[\"name\"] = t[\"\"].apply(lambda x: \"-\" if not isinstance(x, str) else x[:3]+\"H-\"+x[3:])\n",
    "# t[\"experiment_1\"] = t[\"name\"].apply(lambda x: d.get(x, -1))\n",
    "# t[t[\"experiment_1\"]>=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.to_csv(\"./temp/expres.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/data/tyfei/datasets/ion_channel/Interprot/test885.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "# data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('MGCDVHDPSWQCQWGVPTIIVAWITCAALGIWCLAGSSADVSSGPGIAAVVGCSVFMIFLCAYLIRYREFFKDSVIDLLTCRWVRYCSCSCKCSCKCISGPCSRCCSACYKETMIYDMVQYGHRRRPGHGDDPDRVICEIVESPPVSAPTVFVPPPSEESHQPVIPPQPPTPTSEPKPKKGRAKDKPKGRPKNKPPCEPTVSSQPPSQPTAMPGGPPDASPPAMPQMPPGVAEAVQAAVQAAMAAALQQQQQHQTGT',\n",
       " 'MISQGNGGGCRPGEPCWRCALESTRCITLMGVLVALLAACMLSVPPAASTMLLGVASLMAMLRLPMPLVDRFIPACMGLQLVGAAVFAAGWALASRDAISAGVLLWAVCALISHMYNVVCVASGPDAHYRPACLVMGVAAACGAAGALVNVRTEARLGIALGLAVTCATNNVARSLRGTCTYVASRARFLAAPADLGRGYSVENADADPTAEPERRVYEATVPHTHAYAGSIALFALVFSAASSLQWMVSQMVGRGNQLVSPTTAAAAGAAGFLDAAAVSLFVRPSTRHLSVAVKGAHTLLILAAIVLTAAGEPMGVPISLAASTGLGAARGGPRPLRHTRAYRLAAAHVTRALLVQAYVTVAMCATSIKSVS')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"/data/tyfei/datasets/ion_channel/Interprot/activeLearningTest/0/test.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f) \n",
    "data[-1][\"ori_seq\"], data[0][\"ori_seq\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('MGGWSSKPRQGMGTNLSVPNPLGFFPDHQLDPAFGANSNNPDWDFNPNKDHWPEANQVGAGAFGPGFTPPHGGLLGWSPQAQGILTTVPAAPPPASTNRQSGRQPTPISPPLRDSHPQAIRWNSTTFHQALLDPRVRGLYFPAGGSSSGTVNPVPTTASPISSIFSRTGDPATNMENTTSGFLGPLLVLQAGFFSLTRILTIPQSLDSWWTSLNFLGGAPTCPGQNSQSPTSNHSPTSCPPICPGYRWMCLRRFIIFLFILLLCLIFLLVLLDYQGMLPVCPLLPGTSTTSTGPCKTCTIPAQGTSMFPSCCCTKPSDGNCTCIPIPSSWAFARFLWEWASVRFSWLSLLVPFVQWFVGLSPTVWLSVIWMMWYWGPSLYNILSPFLPLLPIFFYLWVYI',\n",
       " 'MNNATFNCTNINPITHIRGSIIITICVSLIVILIVFGCIAKIFINKNNCTNNVIRVHKRIKCPDCEPFCNKRDDISTPRAGVDIPSFILPGLNLSEGTPN')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"/data/tyfei/datasets/ion_channel/Interprot/activeLearningTest/0/test_2.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f) \n",
    "data[-1][\"ori_seq\"], data[0][\"ori_seq\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>experiment_1</th>\n",
       "      <th>experiment_2</th>\n",
       "      <th>yeast_1</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>837</th>\n",
       "      <td>MNNATFNCTNINPITHIRGSIIITICVSLIVILIVFGCIAKIFINK...</td>\n",
       "      <td>GSMNNATFNCTNINPITHIRGSIIITICVSLIVILIVFGCIAKIFI...</td>\n",
       "      <td>VIL828</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>VILH-828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>MPAIPVQYVNCVGVVGLVAFGLLSYQWIERKRRQGPLPQWFKEYLK...</td>\n",
       "      <td>GSMPAIPVQYVNCVGVVGLVAFGLLSYQWIERKRRQGPLPQWFKEY...</td>\n",
       "      <td>VIL53</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>VILH-53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>MGNTSITIEFTSKFWPYFTLIHMILTLISLLIIITIMIAILNKLSE...</td>\n",
       "      <td>GSMGNTSITIEFTSKFWPYFTLIHMILTLISLLIIITIMIAILNKL...</td>\n",
       "      <td>VIL791</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>VILH-791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>MFALVLAVVILPLWTTANKSYVTPTPATRSIGHMSALLREYSDRNM...</td>\n",
       "      <td>GSMFALVLAVVILPLWTTANKSYVTPTPATRSIGHMSALLREYSDR...</td>\n",
       "      <td>VIL295</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>VILH-295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>MVRARVLRGLLAAWVLAAWGGVAAVETTWKHASAGDDVRFFDLPAG...</td>\n",
       "      <td>GSMVRARVLRGLLAAWVLAAWGGVAAVETTWKHASAGDDVRFFDLP...</td>\n",
       "      <td>VIL284</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>VILH-284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>MPPQRARGAPPRRRGSDPPDPGSLAGRLSPGGRSGGGSRRTLSRSS...</td>\n",
       "      <td>GSMPPQRARGAPPRRRGSDPPDPGSLAGRLSPGGRSGGGSRRTLSR...</td>\n",
       "      <td>VIL301</td>\n",
       "      <td>101</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>VILH-301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>SFSEPLTVVGVMLTLASGMMRHTSQEALCALAAASFLLLMLVLGTR...</td>\n",
       "      <td>GSMSFSEPLTVVGVMLTLASGMMRHTSQEALCALAAASFLLLMLVL...</td>\n",
       "      <td>VIL730</td>\n",
       "      <td>102</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>VILH-730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>MAQARPQGHISWLWKWATSATNTNTHKLATKAPLNLSSEYRLNFAR...</td>\n",
       "      <td>GSMAQARPQGHISWLWKWATSATNTNTHKLATKAPLNLSSEYRLNF...</td>\n",
       "      <td>VIL48</td>\n",
       "      <td>103</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>VILH-48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MDHRSYADAELAESWMHENLVQWIDRFRSVVAIYSNALFEVAGTLS...</td>\n",
       "      <td>GSMDHRSYADAELAESWMHENLVQWIDRFRSVVAIYSNALFEVAGT...</td>\n",
       "      <td>VIL5</td>\n",
       "      <td>104</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>VILH-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>MISQGNGGGCRPGEPCWRCALESTRCITLMGVLVALLAACMLSVPP...</td>\n",
       "      <td>GSMISQGNGGGCRPGEPCWRCALESTRCITLMGVLVALLAACMLSV...</td>\n",
       "      <td>VIL306</td>\n",
       "      <td>105</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>VILH-306</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>106 rows  7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    \\\n",
       "num                                                      \n",
       "837  MNNATFNCTNINPITHIRGSIIITICVSLIVILIVFGCIAKIFINK...   \n",
       "53   MPAIPVQYVNCVGVVGLVAFGLLSYQWIERKRRQGPLPQWFKEYLK...   \n",
       "799  MGNTSITIEFTSKFWPYFTLIHMILTLISLLIIITIMIAILNKLSE...   \n",
       "299  MFALVLAVVILPLWTTANKSYVTPTPATRSIGHMSALLREYSDRNM...   \n",
       "288  MVRARVLRGLLAAWVLAAWGGVAAVETTWKHASAGDDVRFFDLPAG...   \n",
       "..                                                 ...   \n",
       "305  MPPQRARGAPPRRRGSDPPDPGSLAGRLSPGGRSGGGSRRTLSRSS...   \n",
       "737  SFSEPLTVVGVMLTLASGMMRHTSQEALCALAAASFLLLMLVLGTR...   \n",
       "48   MAQARPQGHISWLWKWATSATNTNTHKLATKAPLNLSSEYRLNFAR...   \n",
       "4    MDHRSYADAELAESWMHENLVQWIDRFRSVVAIYSNALFEVAGTLS...   \n",
       "310  MISQGNGGGCRPGEPCWRCALESTRCITLMGVLVALLAACMLSVPP...   \n",
       "\n",
       "                                                      experiment_1  \\\n",
       "num                                                                            \n",
       "837  GSMNNATFNCTNINPITHIRGSIIITICVSLIVILIVFGCIAKIFI...  VIL828             0   \n",
       "53   GSMPAIPVQYVNCVGVVGLVAFGLLSYQWIERKRRQGPLPQWFKEY...   VIL53             1   \n",
       "799  GSMGNTSITIEFTSKFWPYFTLIHMILTLISLLIIITIMIAILNKL...  VIL791             2   \n",
       "299  GSMFALVLAVVILPLWTTANKSYVTPTPATRSIGHMSALLREYSDR...  VIL295             3   \n",
       "288  GSMVRARVLRGLLAAWVLAAWGGVAAVETTWKHASAGDDVRFFDLP...  VIL284             4   \n",
       "..                                                 ...     ...           ...   \n",
       "305  GSMPPQRARGAPPRRRGSDPPDPGSLAGRLSPGGRSGGGSRRTLSR...  VIL301           101   \n",
       "737  GSMSFSEPLTVVGVMLTLASGMMRHTSQEALCALAAASFLLLMLVL...  VIL730           102   \n",
       "48   GSMAQARPQGHISWLWKWATSATNTNTHKLATKAPLNLSSEYRLNF...   VIL48           103   \n",
       "4    GSMDHRSYADAELAESWMHENLVQWIDRFRSVVAIYSNALFEVAGT...    VIL5           104   \n",
       "310  GSMISQGNGGGCRPGEPCWRCALESTRCITLMGVLVALLAACMLSV...  VIL306           105   \n",
       "\n",
       "     experiment_2  yeast_1      name  \n",
       "num                                   \n",
       "837            -1       -1  VILH-828  \n",
       "53             -1       -1   VILH-53  \n",
       "799            -1       -1  VILH-791  \n",
       "299            -1       -1  VILH-295  \n",
       "288            -1       -1  VILH-284  \n",
       "..            ...      ...       ...  \n",
       "305            -1       -1  VILH-301  \n",
       "737            -1       -1  VILH-730  \n",
       "48             -1       -1   VILH-48  \n",
       "4              -1       -1    VILH-5  \n",
       "310            -1       -1  VILH-306  \n",
       "\n",
       "[106 rows x 7 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = pd.read_csv(\"./temp/expres.csv\", index_col=0)\n",
    "# t = t.sort_values(\"experiment_2\", ascending=False)\n",
    "t = t[t[\"experiment_1\"] >= 0]\n",
    "t = t.sort_values(\"experiment_1\")\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(106, 106)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = [] \n",
    "for i in t[\"\"]:\n",
    "    for j in data:\n",
    "        if i == j[\"ori_seq\"]:\n",
    "            res.append(j)\n",
    "len(res), len(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/data/tyfei/datasets/ion_channel/Interprot/activeLearningTest/exp2.pkl\", \"wb\") as f:\n",
    "    pickle.dump(res, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = list(range(106))\n",
    "random.seed(1509)\n",
    "random.shuffle(a)\n",
    "splits = [0, 21, 42, 63, 85, 106]\n",
    "for i in range(5):\n",
    "    test_indices = a[splits[i]:splits[i+1]] \n",
    "    train = [] \n",
    "    test = [] \n",
    "    for j in range(106):\n",
    "        if j in test_indices:\n",
    "            test.append(res[j])\n",
    "        else:\n",
    "            train.append(res[j])\n",
    "    with open(f\"/data/tyfei/datasets/ion_channel/Interprot/activeLearningTest/{i}/train_2.pkl\", \"wb\") as f:\n",
    "        pickle.dump(train, f)\n",
    "    with open(f\"/data/tyfei/datasets/ion_channel/Interprot/activeLearningTest/{i}/test_2.pkl\", \"wb\") as f:\n",
    "        pickle.dump(test, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tyfei/anaconda3/envs/esm3/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import json\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import trainUtils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/data2/tyfei/trainresults/ionChannels/ESMCActiveLearning/FromTestDomain/1\"\n",
    "with open(os.path.join(path, \"config.json\"), \"r\") as f:\n",
    "    configs = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fix model for active learning\n"
     ]
    }
   ],
   "source": [
    "pretrain_model = trainUtils.loadPretrainModel(configs)\n",
    "model = trainUtils.buildModel(configs, pretrain_model, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = trainUtils.loadDataset(configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = ds.train_dataloader()\n",
    "for i, j in enumerate(dl):\n",
    "    break\n",
    "print(j[0].shape, j[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clf.l1.weight\n",
      "clf.l1.bias\n",
      "clf.l2.weight\n",
      "clf.l2.bias\n",
      "clf.l3.weight\n",
      "clf.l3.bias\n",
      "clf.ln1.weight\n",
      "clf.ln1.bias\n",
      "clf.ln2.weight\n",
      "clf.ln2.bias\n"
     ]
    }
   ],
   "source": [
    "for i, j in model.named_parameters():\n",
    "    if j.requires_grad:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = trainUtils.loadDataset(configs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>name2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>VIL1</th>\n",
       "      <td>MKPLCTPWVDGTILCSLLFLLAFSGVSSAWSNDTKLPQRRSGHLRD...</td>\n",
       "      <td>GSMKPLCTPWVDGTILCSLLFLLAFSGVSSAWSNDTKLPQRRSGHL...</td>\n",
       "      <td>VILH-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VIL2</th>\n",
       "      <td>MLRYPWLQLLATFLLFEVSLCCFFSKKGLTTSYNRRFHYRWIQLNR...</td>\n",
       "      <td>GSMLRYPWLQLLATFLLFEVSLCCFFSKKGLTTSYNRRFHYRWIQL...</td>\n",
       "      <td>VILH-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VIL3</th>\n",
       "      <td>MGRQDTSREGNEDYEDIMRWVRRFVWLTRVYTVLAVQMAVTLAFCL...</td>\n",
       "      <td>GSMGRQDTSREGNEDYEDIMRWVRRFVWLTRVYTVLAVQMAVTLAF...</td>\n",
       "      <td>VILH-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VIL4</th>\n",
       "      <td>MEVLRFQVRFTESIIWIQRFKILIQLYSYWLLQVTVTSTLSTLMWL...</td>\n",
       "      <td>GSMEVLRFQVRFTESIIWIQRFKILIQLYSYWLLQVTVTSTLSTLM...</td>\n",
       "      <td>VILH-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VIL5</th>\n",
       "      <td>MDHRSYADAELAESWMHENLVQWIDRFRSVVAIYSNALFEVAGTLS...</td>\n",
       "      <td>GSMDHRSYADAELAESWMHENLVQWIDRFRSVVAIYSNALFEVAGT...</td>\n",
       "      <td>VILH-5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      \\\n",
       "                                                      \n",
       "VIL1   MKPLCTPWVDGTILCSLLFLLAFSGVSSAWSNDTKLPQRRSGHLRD...   \n",
       "VIL2   MLRYPWLQLLATFLLFEVSLCCFFSKKGLTTSYNRRFHYRWIQLNR...   \n",
       "VIL3   MGRQDTSREGNEDYEDIMRWVRRFVWLTRVYTVLAVQMAVTLAFCL...   \n",
       "VIL4   MEVLRFQVRFTESIIWIQRFKILIQLYSYWLLQVTVTSTLSTLMWL...   \n",
       "VIL5   MDHRSYADAELAESWMHENLVQWIDRFRSVVAIYSNALFEVAGTLS...   \n",
       "\n",
       "                                                      name2  \n",
       "                                                             \n",
       "VIL1   GSMKPLCTPWVDGTILCSLLFLLAFSGVSSAWSNDTKLPQRRSGHL...  VILH-1  \n",
       "VIL2   GSMLRYPWLQLLATFLLFEVSLCCFFSKKGLTTSYNRRFHYRWIQL...  VILH-2  \n",
       "VIL3   GSMGRQDTSREGNEDYEDIMRWVRRFVWLTRVYTVLAVQMAVTLAF...  VILH-3  \n",
       "VIL4   GSMEVLRFQVRFTESIIWIQRFKILIQLYSYWLLQVTVTSTLSTLM...  VILH-4  \n",
       "VIL5   GSMDHRSYADAELAESWMHENLVQWIDRFRSVVAIYSNALFEVAGT...  VILH-5  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./temp/all885.csv\", index_col=0)\n",
    "df = df.set_index(\"\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Areatstatistic</th>\n",
       "      <th>Areapvalue</th>\n",
       "      <th>Maxtstatistic</th>\n",
       "      <th>Maxpvalue</th>\n",
       "      <th>geomean</th>\n",
       "      <th>seq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>VIL100</th>\n",
       "      <td>13.051121</td>\n",
       "      <td>0.999901</td>\n",
       "      <td>10.967152</td>\n",
       "      <td>0.999804</td>\n",
       "      <td>0.999852</td>\n",
       "      <td>MNNSSCDLLQAFKIDDASRDVSVGFYSIAICVGLVANILILLVLIR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VIL455</th>\n",
       "      <td>3.114733</td>\n",
       "      <td>0.982146</td>\n",
       "      <td>11.386229</td>\n",
       "      <td>0.999830</td>\n",
       "      <td>0.990949</td>\n",
       "      <td>MALTCRLRFPVPGFRGRMHRRRGMAGHGLTGGMRRAHHRRRRASHR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VIL750</th>\n",
       "      <td>7.659041</td>\n",
       "      <td>0.999219</td>\n",
       "      <td>2.369652</td>\n",
       "      <td>0.961575</td>\n",
       "      <td>0.980216</td>\n",
       "      <td>MMADSKLVSLNNNLSGKIKDQGKVIKNYYGTMDIKKINDGLLDSKI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VIL10</th>\n",
       "      <td>1.946238</td>\n",
       "      <td>0.938255</td>\n",
       "      <td>3.043280</td>\n",
       "      <td>0.980860</td>\n",
       "      <td>0.959321</td>\n",
       "      <td>MTGEVCHVNDTMKAYGMTPDLTISLYSLGMILGIGGNMLILCVICL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VIL835</th>\n",
       "      <td>2.592156</td>\n",
       "      <td>0.969727</td>\n",
       "      <td>2.055082</td>\n",
       "      <td>0.945470</td>\n",
       "      <td>0.957522</td>\n",
       "      <td>MPLSYQHFRRLLLLDDEAGPLEEELPRLADEGLNRRVAEDLNLGNL...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Areatstatistic  Areapvalue  Maxtstatistic  Maxpvalue   geomean  \\\n",
       "Name                                                                     \n",
       "VIL100       13.051121    0.999901      10.967152   0.999804  0.999852   \n",
       "VIL455        3.114733    0.982146      11.386229   0.999830  0.990949   \n",
       "VIL750        7.659041    0.999219       2.369652   0.961575  0.980216   \n",
       "VIL10         1.946238    0.938255       3.043280   0.980860  0.959321   \n",
       "VIL835        2.592156    0.969727       2.055082   0.945470  0.957522   \n",
       "\n",
       "                                                      seq  \n",
       "Name                                                       \n",
       "VIL100  MNNSSCDLLQAFKIDDASRDVSVGFYSIAICVGLVANILILLVLIR...  \n",
       "VIL455  MALTCRLRFPVPGFRGRMHRRRGMAGHGLTGGMRRAHHRRRRASHR...  \n",
       "VIL750  MMADSKLVSLNNNLSGKIKDQGKVIKNYYGTMDIKKINDGLLDSKI...  \n",
       "VIL10   MTGEVCHVNDTMKAYGMTPDLTISLYSLGMILGIGGNMLILCVICL...  \n",
       "VIL835  MPLSYQHFRRLLLLDDEAGPLEEELPRLADEGLNRRVAEDLNLGNL...  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfexp = pd.read_excel(\"./temp/exp2.xlsx\", sheet_name=\"Sheet1\")\n",
    "dfexp = dfexp.set_index(\"Name\")\n",
    "dfexp[\"seq\"] = df[\"\"]\n",
    "dfexp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Areatstatistic</th>\n",
       "      <th>Areapvalue</th>\n",
       "      <th>Maxtstatistic</th>\n",
       "      <th>Maxpvalue</th>\n",
       "      <th>geomean</th>\n",
       "      <th>seq</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>VIL100</th>\n",
       "      <td>13.051121</td>\n",
       "      <td>0.999901</td>\n",
       "      <td>10.967152</td>\n",
       "      <td>0.999804</td>\n",
       "      <td>0.999852</td>\n",
       "      <td>MNNSSCDLLQAFKIDDASRDVSVGFYSIAICVGLVANILILLVLIR...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VIL455</th>\n",
       "      <td>3.114733</td>\n",
       "      <td>0.982146</td>\n",
       "      <td>11.386229</td>\n",
       "      <td>0.999830</td>\n",
       "      <td>0.990949</td>\n",
       "      <td>MALTCRLRFPVPGFRGRMHRRRGMAGHGLTGGMRRAHHRRRRASHR...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VIL750</th>\n",
       "      <td>7.659041</td>\n",
       "      <td>0.999219</td>\n",
       "      <td>2.369652</td>\n",
       "      <td>0.961575</td>\n",
       "      <td>0.980216</td>\n",
       "      <td>MMADSKLVSLNNNLSGKIKDQGKVIKNYYGTMDIKKINDGLLDSKI...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VIL10</th>\n",
       "      <td>1.946238</td>\n",
       "      <td>0.938255</td>\n",
       "      <td>3.043280</td>\n",
       "      <td>0.980860</td>\n",
       "      <td>0.959321</td>\n",
       "      <td>MTGEVCHVNDTMKAYGMTPDLTISLYSLGMILGIGGNMLILCVICL...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VIL835</th>\n",
       "      <td>2.592156</td>\n",
       "      <td>0.969727</td>\n",
       "      <td>2.055082</td>\n",
       "      <td>0.945470</td>\n",
       "      <td>0.957522</td>\n",
       "      <td>MPLSYQHFRRLLLLDDEAGPLEEELPRLADEGLNRRVAEDLNLGNL...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Areatstatistic  Areapvalue  Maxtstatistic  Maxpvalue   geomean  \\\n",
       "Name                                                                     \n",
       "VIL100       13.051121    0.999901      10.967152   0.999804  0.999852   \n",
       "VIL455        3.114733    0.982146      11.386229   0.999830  0.990949   \n",
       "VIL750        7.659041    0.999219       2.369652   0.961575  0.980216   \n",
       "VIL10         1.946238    0.938255       3.043280   0.980860  0.959321   \n",
       "VIL835        2.592156    0.969727       2.055082   0.945470  0.957522   \n",
       "\n",
       "                                                      seq  rank  \n",
       "Name                                                             \n",
       "VIL100  MNNSSCDLLQAFKIDDASRDVSVGFYSIAICVGLVANILILLVLIR...     0  \n",
       "VIL455  MALTCRLRFPVPGFRGRMHRRRGMAGHGLTGGMRRAHHRRRRASHR...     1  \n",
       "VIL750  MMADSKLVSLNNNLSGKIKDQGKVIKNYYGTMDIKKINDGLLDSKI...     2  \n",
       "VIL10   MTGEVCHVNDTMKAYGMTPDLTISLYSLGMILGIGGNMLILCVICL...     3  \n",
       "VIL835  MPLSYQHFRRLLLLDDEAGPLEEELPRLADEGLNRRVAEDLNLGNL...     4  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfexp = dfexp.sort_values(\"geomean\", ascending=False) \n",
    "dfexp[\"rank\"] = range(len(dfexp))\n",
    "dfexp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/data/tyfei/datasets/ion_channel/Interprot/test885.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62, 62)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = [] \n",
    "for i in dfexp[\"seq\"]:\n",
    "    for j in data:\n",
    "        if i == j[\"ori_seq\"]:\n",
    "            res.append(j)\n",
    "len(res), len(dfexp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"/data/tyfei/datasets/ion_channel/Interprot/activeLearningTest/exp2.pkl\", \"wb\") as f:\n",
    "    pickle.dump(res, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-fold validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=2-validate_acc=0.9944.ckpt\n",
      "load model\n",
      "load dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "/home/tyfei/anaconda3/envs/esm3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|| 885/885 [00:42<00:00, 20.62it/s]\n",
      "epoch=8-validate_acc=0.9823.ckpt\n",
      "load model\n",
      "load dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "/home/tyfei/anaconda3/envs/esm3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|| 885/885 [00:43<00:00, 20.25it/s]\n",
      "load model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/tyfei/ionChannel/test.py\", line 92, in <module>\n",
      "    run()\n",
      "  File \"/home/tyfei/ionChannel/test.py\", line 55, in run\n",
      "    model = trainUtils.buildModel(\n",
      "  File \"/home/tyfei/ionChannel/trainUtils.py\", line 470, in buildModel\n",
      "    t = torch.load(checkpoint, map_location=\"cpu\")\n",
      "  File \"/home/tyfei/anaconda3/envs/esm3/lib/python3.10/site-packages/torch/serialization.py\", line 1040, in load\n",
      "    return _legacy_load(opened_file, map_location, pickle_module, **pickle_load_args)\n",
      "  File \"/home/tyfei/anaconda3/envs/esm3/lib/python3.10/site-packages/torch/serialization.py\", line 1262, in _legacy_load\n",
      "    magic_number = pickle_module.load(f, **pickle_load_args)\n",
      "_pickle.UnpicklingError: invalid load key, '{'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=4-validate_acc=0.9909.ckpt\n",
      "load model\n",
      "load dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "/home/tyfei/anaconda3/envs/esm3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|| 885/885 [00:42<00:00, 21.06it/s]\n",
      "epoch=11-validate_acc=0.9924.ckpt\n",
      "load model\n",
      "load dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "/home/tyfei/anaconda3/envs/esm3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|| 885/885 [00:44<00:00, 20.10it/s]\n",
      "epoch=9-validate_acc=0.9894.ckpt\n",
      "load model\n",
      "load dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "/home/tyfei/anaconda3/envs/esm3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|| 885/885 [00:43<00:00, 20.39it/s]\n",
      "epoch=13-validate_acc=0.9889.ckpt\n",
      "load model\n",
      "load dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "/home/tyfei/anaconda3/envs/esm3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|| 885/885 [00:42<00:00, 20.81it/s]\n",
      "epoch=5-validate_acc=0.9884.ckpt\n",
      "load model\n",
      "load dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "/home/tyfei/anaconda3/envs/esm3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|| 885/885 [00:42<00:00, 20.69it/s]\n",
      "epoch=14-validate_acc=0.9934.ckpt\n",
      "load model\n",
      "load dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "/home/tyfei/anaconda3/envs/esm3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|| 885/885 [00:42<00:00, 20.98it/s]\n",
      "epoch=15-validate_acc=0.9924.ckpt\n",
      "load model\n",
      "load dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "/home/tyfei/anaconda3/envs/esm3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|| 885/885 [00:43<00:00, 20.48it/s]\n",
      "load model\n",
      "load dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "/home/tyfei/anaconda3/envs/esm3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|| 885/885 [00:42<00:00, 20.80it/s]\n",
      "epoch=3-validate_acc=0.9863.ckpt\n",
      "load model\n",
      "load dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "/home/tyfei/anaconda3/envs/esm3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|| 885/885 [00:42<00:00, 20.93it/s]\n",
      "epoch=12-validate_acc=0.9924.ckpt\n",
      "load model\n",
      "load dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "/home/tyfei/anaconda3/envs/esm3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|| 885/885 [00:43<00:00, 20.19it/s]\n",
      "epoch=1-validate_acc=0.9909.ckpt\n",
      "load model\n",
      "load dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "/home/tyfei/anaconda3/envs/esm3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|| 885/885 [00:43<00:00, 20.57it/s]\n",
      "epoch=7-validate_acc=0.9919.ckpt\n",
      "load model\n",
      "load dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "/home/tyfei/anaconda3/envs/esm3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|| 885/885 [00:43<00:00, 20.57it/s]\n",
      "epoch=0-validate_acc=0.9828.ckpt\n",
      "load model\n",
      "load dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "/home/tyfei/anaconda3/envs/esm3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|| 885/885 [00:42<00:00, 20.99it/s]\n",
      "epoch=6-validate_acc=0.9899.ckpt\n",
      "load model\n",
      "load dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "/home/tyfei/anaconda3/envs/esm3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|| 885/885 [00:42<00:00, 20.59it/s]\n",
      "epoch=10-validate_acc=0.9873.ckpt\n",
      "load model\n",
      "load dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "/home/tyfei/anaconda3/envs/esm3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|| 885/885 [00:42<00:00, 20.59it/s]\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "from scipy import stats\n",
    "target_dir = \"/data2/tyfei/trainresults/ionChannels/ESMC/newtest/\"\n",
    "output_dir = \"/data2/tyfei/trainresults/ionChannels/ESMC/newtest/bayes10/\"\n",
    "dataset = \"/data/tyfei/datasets/ion_channel/Interprot/test885.pkl\"\n",
    "for i in os.listdir(target_dir):\n",
    "    if i.startswith(\"epoch\"):\n",
    "        print(i) \n",
    "        \n",
    "    ret = os.system(\"python test.py -p %s -c %s -i %s -d %d -b %d -o %s\"%(target_dir, i, dataset, 5, 10, output_dir)) \n",
    "    \n",
    "target_dir = \"/data2/tyfei/trainresults/ionChannels/ESMC/newtest2/\"\n",
    "output_dir = \"/data2/tyfei/trainresults/ionChannels/ESMC/newtest2/bayes10/\"\n",
    "dataset = \"/data/tyfei/datasets/ion_channel/Interprot/test885.pkl\"\n",
    "for i in os.listdir(target_dir):\n",
    "    if i.startswith(\"epoch\"):\n",
    "        print(i) \n",
    "        \n",
    "    ret = os.system(\"python test.py -p %s -c %s -i %s -d %d -b %d -o %s\"%(target_dir, i, dataset, 5, 10, output_dir)) \n",
    "    \n",
    "# target_dir = \"/data2/tyfei/trainresults/ionChannels/ESMC/newtest3/\"\n",
    "# output_dir = \"/data2/tyfei/trainresults/ionChannels/ESMC/newtest3/bayes10/\"\n",
    "# dataset = \"/data/tyfei/datasets/ion_channel/Interprot/test885.pkl\"\n",
    "# for i in os.listdir(target_dir):\n",
    "#     if i.startswith(\"epoch\"):\n",
    "#         print(i) \n",
    "        \n",
    "#     ret = os.system(\"python test.py -p %s -c %s -i %s -d %d -b %d -o %s\"%(target_dir, i, dataset, 5, 10, output_dir)) \n",
    "    # if ret == 0:\n",
    "    #     a = np.loadtxt(\"/data2/tyfei/trainresults/ionChannels/ESMCActiveLearning/FromTestDomain/4_2/test_last.txt\")\n",
    "    #     stats.spearmanr(a, range(len(a)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load model\n",
      "load dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "/home/tyfei/anaconda3/envs/esm3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|| 21/21 [00:01<00:00, 16.90it/s]\n",
      "load model\n",
      "load dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "/home/tyfei/anaconda3/envs/esm3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|| 21/21 [00:01<00:00, 17.04it/s]\n",
      "load model\n",
      "load dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "/home/tyfei/anaconda3/envs/esm3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|| 21/21 [00:01<00:00, 16.68it/s]\n",
      "load model\n",
      "load dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "/home/tyfei/anaconda3/envs/esm3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|| 21/21 [00:01<00:00, 17.41it/s]\n",
      "load model\n",
      "load dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "/home/tyfei/anaconda3/envs/esm3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|| 22/22 [00:01<00:00, 17.98it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "for i in range(5):\n",
    "    # target_dir = \"/data2/tyfei/trainresults/ionChannels/ESMCActiveLearning/nodomain/%d_2/\"%i\n",
    "    target_dir = \"/data2/tyfei/trainresults/ionChannels/ESMC/nodomain/\"\n",
    "    dataset = \"/data/tyfei/datasets/ion_channel/Interprot/activeLearningTest/%d/test.pkl\"%i\n",
    "    outputdir = \"/data2/tyfei/trainresults/ionChannels/ESMC/nodomain/%d\"%i\n",
    "    os.system(\"python test.py -p %s -c %s -i %s -d %d -o %s\"%(target_dir, target_dir+\"epoch=8-validate_acc=0.9899.ckpt\", dataset, 5, outputdir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load model\n",
      "fix model for active learning\n",
      "load dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "/home/tyfei/anaconda3/envs/esm3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|| 21/21 [00:01<00:00, 18.45it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/tyfei/ionChannel/test.py\", line 92, in <module>\n",
      "    run()\n",
      "  File \"/home/tyfei/ionChannel/test.py\", line 36, in run\n",
      "    assert os.path.isdir(args.path)\n",
      "AssertionError\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/tyfei/ionChannel/test.py\", line 92, in <module>\n",
      "    run()\n",
      "  File \"/home/tyfei/ionChannel/test.py\", line 36, in run\n",
      "    assert os.path.isdir(args.path)\n",
      "AssertionError\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/tyfei/ionChannel/test.py\", line 92, in <module>\n",
      "    run()\n",
      "  File \"/home/tyfei/ionChannel/test.py\", line 36, in run\n",
      "    assert os.path.isdir(args.path)\n",
      "AssertionError\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/tyfei/ionChannel/test.py\", line 92, in <module>\n",
      "    run()\n",
      "  File \"/home/tyfei/ionChannel/test.py\", line 36, in run\n",
      "    assert os.path.isdir(args.path)\n",
      "AssertionError\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "for i in range(5):\n",
    "    target_dir = \"/data2/tyfei/trainresults/ionChannels/ESMCActiveLearning/nodomain/%d_4/\"%i\n",
    "    dataset = \"/data/tyfei/datasets/ion_channel/Interprot/activeLearningTest/%d/test.pkl\"%i\n",
    "    os.system(\"python test.py -p %s -c %s -i %s -d %d\"%(target_dir, target_dir+\"last.ckpt\", dataset, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SignificanceResult(statistic=0.247482962061986, pvalue=0.279429612882753)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import testUtils \n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "a = np.loadtxt(\"/data2/tyfei/trainresults/ionChannels/ESMCActiveLearning/FromTestDomain/4_2/test_last.txt\")\n",
    "stats.spearmanr(a, range(len(a)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.14285714285714285,\n",
       " -0.212987012987013,\n",
       " 0.14935064935064934,\n",
       " 0.22337662337662337,\n",
       " -0.005081874647092039]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d0 = []\n",
    "for i in range(5):\n",
    "    a = np.loadtxt(f\"/data2/tyfei/trainresults/ionChannels/ESMC/nodomain/{i}/test_epoch=8-validate_acc=0.9899.txt\")\n",
    "    d0.append(stats.spearmanr(a, range(len(a)))[0])\n",
    "d0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.32597402597402597,\n",
       " 0.15194805194805194,\n",
       " 0.6896103896103896,\n",
       " 0.5064935064935064,\n",
       " 0.11914172783738003]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1 = [] \n",
    "for i in range(5):\n",
    "    if os.path.exists(f\"/data2/tyfei/trainresults/ionChannels/ESMCActiveLearning/nodomain/{i}/test_last-v1.txt\"):\n",
    "        a = np.loadtxt(f\"/data2/tyfei/trainresults/ionChannels/ESMCActiveLearning/nodomain/{i}/test_last-v1.txt\")\n",
    "    else:\n",
    "        a = np.loadtxt(f\"/data2/tyfei/trainresults/ionChannels/ESMCActiveLearning/nodomain/{i}/test_last.txt\")\n",
    "    d1.append(stats.spearmanr(a, range(len(a)))[0])\n",
    "d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6168831168831169,\n",
       " -0.15584415584415584,\n",
       " 0.3922077922077922,\n",
       " 0.5649350649350648,\n",
       " 0.1981931112365895]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2 = [] \n",
    "for i in range(5):\n",
    "    if os.path.exists(f\"/data2/tyfei/trainresults/ionChannels/ESMCActiveLearning/nodomain/{i}_3/test_last-v1.txt\"):\n",
    "        a = np.loadtxt(f\"/data2/tyfei/trainresults/ionChannels/ESMCActiveLearning/nodomain/{i}_3/test_last-v1.txt\")\n",
    "    else:\n",
    "        # print(\"train\")\n",
    "        a = np.loadtxt(f\"/data2/tyfei/trainresults/ionChannels/ESMCActiveLearning/nodomain/{i}_3/test_last.txt\")\n",
    "    d2.append(stats.spearmanr(a, range(len(a)))[0])\n",
    "d2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'd0' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m d \u001b[38;5;241m=\u001b[39m [] \n\u001b[0;32m----> 2\u001b[0m d\u001b[38;5;241m.\u001b[39mextend(\u001b[43md0\u001b[49m)\n\u001b[1;32m      3\u001b[0m d\u001b[38;5;241m.\u001b[39mextend(d1)\n\u001b[1;32m      4\u001b[0m d\u001b[38;5;241m.\u001b[39mextend(d2)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'd0' is not defined"
     ]
    }
   ],
   "source": [
    "d = [] \n",
    "d.extend(d0)\n",
    "d.extend(d1)\n",
    "d.extend(d2)\n",
    "f = [] \n",
    "f.extend([\"0\"]*5)\n",
    "f.extend([\"1\"]*5)\n",
    "f.extend([\"2\"]*5)\n",
    "df = pd.DataFrame({\"d\": d, \"f\": f}) \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='f', ylabel='d'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.boxplot(x=\"f\", y=\"d\", data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "esm3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
