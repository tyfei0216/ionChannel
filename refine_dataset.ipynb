{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "s = r\"TM-(?P<start>\\d+)-(?P<end>\\d+)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as L \n",
    "class T(L.Callback):\n",
    "    def __init__(self):\n",
    "        super().__init__() \n",
    "        \n",
    "    def on_train_epoch_end(self, trainer, pl_module):\n",
    "        return super().on_train_epoch_end(trainer, pl_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['randomseed', 'model', 'id', 'ori_seq', 'seq_t', 'structure_t', 'second_t', 'sasa_t', 'coordinates'])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd \n",
    "with open(\"/data/tyfei/datasets/ion_channel/Interpro_v2/kingdom/Archaea1.pkl\", \"rb\") as f:\n",
    "    q = pickle.load(f)\n",
    "df = pd.DataFrame()\n",
    "q[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"/data/tyfei/datasets/ion_channel/Interprot/annotation.xlsx\", index_col=0)\n",
    "df.head()\n",
    "df[\"Ion_pendoplasmic_reticulummeability_label\"] = df[\"Ion_pendoplasmic_reticulummeability_label\"].astype(str)\n",
    "df[\"Location\"] = df[\"Location\"].astype(str)\n",
    "df[\"Gating\"] = df[\"Gating\"].astype(str)\n",
    "# np.unique(df[\"Ion_pendoplasmic_reticulummeability_label\"]), np.unique(df[\"Location\"]), np.unique(df[\"Gating\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name                                               Potassium channel domain-containing protein\n",
       "ScientificName                               uncultured marine group II/III euryarchaeote K...\n",
       "Protein_length                                                                             114\n",
       "Entry_accession                                                                      IPR003280\n",
       "Family_name                                                  Two pore domain potassium channel\n",
       "Gating                                                                            Ligand-gated\n",
       "Ion_pendoplasmic_reticulummeability_label                                Potassium selectivity\n",
       "Location                                                                       plasma membrane\n",
       "Source_database                                                                       interpro\n",
       "TaxId                                                                                  1457970\n",
       "Taxonomy                                     Archaea;Euryarchaeota;;;;;uncultured marine gr...\n",
       "TMH Count                                                                                    2\n",
       "TMhelix Ranges                                                                TM-7-29,TM-62-84\n",
       "Name: A0A075GRZ2, dtype: object"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[q[0][\"id\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(7, 29), (62, 84)]\n",
      "[(21, 43)]\n",
      "[(23, 45), (78, 100)]\n",
      "[(9, 31), (64, 86)]\n",
      "[(27, 49), (81, 103)]\n",
      "[(27, 49), (59, 78), (91, 113)]\n",
      "[(4, 26), (39, 61)]\n",
      "[(10, 29), (36, 58), (73, 95)]\n",
      "[(21, 43), (47, 69)]\n",
      "[(7, 26), (31, 53), (65, 86), (96, 118)]\n",
      "[(13, 30), (45, 62), (74, 93), (97, 114), (126, 148), (185, 202)]\n",
      "[(2, 21), (31, 49), (62, 84)]\n",
      "[(35, 57), (70, 92), (97, 116), (129, 151)]\n",
      "[(106, 128), (132, 154)]\n",
      "[(21, 43), (79, 101)]\n",
      "[(7, 29), (44, 66), (96, 118)]\n",
      "[(7, 24), (39, 61), (66, 88), (98, 120)]\n",
      "[(7, 29), (39, 61), (68, 90), (95, 117)]\n",
      "[(24, 43), (50, 72), (76, 98), (111, 133)]\n",
      "[(20, 39), (52, 71), (75, 97), (109, 131)]\n",
      "[(7, 26), (36, 58), (65, 87), (102, 124)]\n",
      "[(7, 29)]\n",
      "[(167, 189), (199, 218)]\n",
      "[(13, 35), (45, 62), (69, 91)]\n",
      "[(21, 43)]\n",
      "[(5, 27), (63, 85)]\n",
      "[(7, 26), (64, 86)]\n",
      "[(7, 29), (61, 83)]\n",
      "[(22, 44)]\n",
      "[(224, 246), (253, 275)]\n",
      "[(20, 42)]\n",
      "[(29, 51), (64, 86)]\n",
      "[(27, 49)]\n",
      "[(264, 283), (298, 320)]\n",
      "[(266, 288), (303, 322)]\n",
      "[(223, 245), (260, 279)]\n",
      "[(269, 291), (306, 328)]\n",
      "[(307, 329), (339, 361)]\n",
      "[(187, 209), (219, 241)]\n",
      "[(93, 115), (120, 142)]\n",
      "[(31, 53), (58, 80)]\n",
      "[(27, 49), (85, 107)]\n",
      "[(5, 22), (174, 196), (203, 225), (240, 262), (275, 294)]\n",
      "[(269, 291), (296, 318), (338, 360)]\n",
      "[(44, 66), (102, 124)]\n",
      "[(45, 67)]\n",
      "[(4, 26), (33, 55), (59, 81), (94, 116), (136, 158), (165, 182), (192, 214), (219, 238), (253, 275)]\n",
      "[(223, 243), (253, 275)]\n",
      "[(32, 54), (61, 83), (98, 120)]\n",
      "[(2, 19), (29, 48), (55, 77), (87, 109)]\n",
      "[(5, 27), (37, 59)]\n",
      "[(5, 22), (32, 54), (63, 85), (95, 117)]\n",
      "[(7, 29), (44, 63), (70, 92), (96, 118), (130, 152)]\n",
      "[(259, 278), (288, 310)]\n",
      "[(4, 21), (28, 50)]\n",
      "[(29, 51), (58, 80), (95, 117)]\n",
      "[(274, 296), (306, 328)]\n",
      "[(257, 279), (294, 311)]\n",
      "[(118, 137), (147, 169)]\n",
      "[(47, 69), (79, 101)]\n",
      "[(267, 289), (299, 318)]\n",
      "[(13, 35)]\n",
      "[(196, 215), (225, 244)]\n",
      "[(257, 279), (289, 309)]\n",
      "[(11, 33), (48, 70)]\n",
      "[(12, 34), (56, 78), (104, 126), (146, 168), (493, 512), (522, 544)]\n",
      "[(20, 39), (67, 89)]\n",
      "[(5, 27), (203, 225), (232, 254), (269, 291), (303, 322)]\n",
      "[(26, 48), (55, 77), (92, 114), (145, 167), (200, 222)]\n",
      "[(5, 27), (47, 69)]\n",
      "[(53, 75)]\n",
      "[(69, 91), (101, 123)]\n",
      "[(10, 32), (37, 54), (58, 80), (93, 115)]\n",
      "[(12, 31), (36, 58), (71, 93), (98, 117)]\n",
      "[(232, 254), (261, 279), (294, 316), (329, 351)]\n",
      "[(20, 42), (73, 95), (128, 150), (155, 177)]\n",
      "[(23, 42), (78, 100)]\n",
      "[(4, 21), (33, 52), (56, 78), (90, 112)]\n",
      "[(5, 22), (35, 57), (62, 81), (102, 121)]\n",
      "[(60, 82), (97, 114)]\n",
      "[(62, 81), (85, 107), (119, 141)]\n",
      "[(21, 40), (45, 67), (88, 110), (115, 137)]\n",
      "[(7, 25), (35, 57), (64, 81), (96, 118)]\n",
      "[(26, 48), (52, 69), (76, 95), (105, 127)]\n",
      "[(13, 30), (34, 56)]\n",
      "[(29, 48), (52, 74)]\n",
      "[(21, 40), (68, 90)]\n",
      "[(2, 20), (30, 52)]\n",
      "[(10, 32), (39, 57), (72, 94)]\n",
      "[(7, 29), (62, 84)]\n",
      "[(29, 51), (76, 98)]\n",
      "[(29, 51)]\n",
      "[(13, 32)]\n",
      "[(13, 35), (65, 87)]\n",
      "[(13, 35), (65, 87)]\n",
      "[(37, 59), (92, 114)]\n",
      "[(7, 29), (34, 51), (63, 85)]\n",
      "[(7, 29), (62, 84)]\n",
      "[(41, 63), (91, 113)]\n",
      "[(35, 54), (69, 91), (98, 120)]\n",
      "[(35, 54), (69, 91), (98, 120)]\n",
      "[(12, 34), (66, 88)]\n",
      "[(26, 45), (79, 98)]\n",
      "[(7, 29), (310, 332), (344, 366), (371, 390), (403, 425), (435, 452)]\n",
      "[(212, 234), (247, 269), (273, 292), (313, 332), (337, 356)]\n",
      "[(282, 304), (314, 333)]\n",
      "[(164, 186), (196, 218)]\n",
      "[(263, 285), (295, 317)]\n",
      "[(188, 207), (217, 239)]\n",
      "[(164, 183), (193, 211)]\n",
      "[(228, 247), (262, 284)]\n",
      "[(265, 284), (299, 321)]\n",
      "[(260, 282), (297, 319)]\n",
      "[(92, 111), (121, 143)]\n",
      "[(110, 129), (144, 166)]\n",
      "[(186, 208), (218, 240)]\n",
      "[(127, 146), (156, 178)]\n",
      "[(38, 60)]\n",
      "[(7, 29), (34, 56), (61, 80), (95, 117)]\n",
      "[(7, 24), (34, 56)]\n",
      "[(157, 176), (186, 208)]\n",
      "[(5, 27)]\n",
      "[(7, 26), (30, 52)]\n",
      "[(5, 27), (37, 59), (66, 88), (98, 120)]\n",
      "[(37, 56), (69, 91), (96, 115), (128, 150)]\n",
      "[(21, 40), (50, 72), (77, 96), (111, 133)]\n",
      "[(5, 27), (37, 59), (66, 83), (98, 120)]\n",
      "[(13, 35), (40, 62)]\n",
      "[(28, 50), (55, 77), (87, 109)]\n",
      "[(15, 37), (44, 64), (79, 101)]\n",
      "[(7, 26), (36, 58)]\n",
      "[(21, 41), (56, 78), (83, 105), (115, 134)]\n",
      "[(13, 35), (50, 72)]\n",
      "[(5, 22), (32, 54), (66, 88), (93, 115)]\n",
      "[(4, 21), (28, 50), (55, 77)]\n",
      "[(4, 23), (35, 54), (58, 77), (90, 112)]\n",
      "[(265, 287), (300, 322)]\n",
      "[(216, 235), (245, 267)]\n",
      "[(184, 203), (213, 235)]\n",
      "[(20, 42), (46, 65), (78, 100)]\n",
      "[(5, 22)]\n",
      "[(5, 27), (36, 55), (60, 82), (94, 116)]\n",
      "[(7, 24), (34, 53)]\n",
      "[(77, 99), (111, 130)]\n",
      "[(33, 55), (62, 84), (94, 116)]\n",
      "[(5, 23), (33, 55), (62, 84), (94, 116)]\n",
      "[(5, 27), (31, 53)]\n",
      "[(15, 34), (41, 63)]\n",
      "[(5, 27), (34, 56), (61, 83), (96, 118)]\n",
      "[(7, 29), (33, 55), (62, 82), (92, 111), (118, 140), (150, 172)]\n",
      "[(5, 27), (34, 56), (60, 82)]\n",
      "[(30, 52), (57, 79), (94, 116)]\n",
      "[(13, 32), (506, 528), (535, 553), (568, 585), (605, 624)]\n",
      "[(98, 120), (132, 154), (158, 180)]\n",
      "[(10, 32), (39, 56), (66, 85)]\n",
      "[(7, 29), (51, 73), (86, 108), (113, 135), (217, 234), (247, 269), (290, 312), (322, 344), (353, 375), (385, 407), (414, 436)]\n",
      "[(29, 51), (61, 82), (102, 124), (168, 190), (197, 216), (231, 253), (330, 352), (367, 384), (411, 433), (443, 465), (472, 494), (509, 531), (536, 558)]\n",
      "[(21, 43), (73, 95)]\n",
      "[(21, 43), (76, 98)]\n",
      "[(5, 27), (63, 85)]\n",
      "[(7, 26), (59, 81)]\n",
      "[(26, 48)]\n",
      "[(28, 47), (83, 105)]\n",
      "[(7, 29), (64, 86)]\n",
      "[(5, 22), (32, 53), (60, 79), (89, 111)]\n",
      "[(40, 58), (73, 95), (100, 122), (132, 154)]\n",
      "[(64, 82), (97, 119), (124, 143), (153, 175)]\n",
      "[(68, 87), (97, 119), (126, 147), (157, 179)]\n",
      "[(54, 71), (81, 99), (106, 125), (140, 162)]\n",
      "[(13, 35), (102, 124), (129, 151), (161, 183)]\n",
      "[(26, 48), (58, 80), (85, 104), (114, 136)]\n",
      "[(170, 192), (212, 234), (241, 263), (273, 292)]\n",
      "[(5, 22), (32, 54), (61, 81), (91, 113)]\n",
      "[(7, 29), (39, 61), (66, 88), (103, 125)]\n",
      "[(31, 53), (66, 88), (93, 112), (125, 144)]\n",
      "[(46, 68), (78, 100), (107, 126), (136, 158)]\n",
      "[(36, 58), (71, 93), (103, 122), (135, 154)]\n",
      "[(21, 43), (47, 69)]\n",
      "[(88, 110), (115, 137), (152, 171), (191, 208)]\n",
      "[(276, 298), (305, 327), (337, 359)]\n",
      "[(20, 42)]\n",
      "[(21, 43), (85, 107)]\n",
      "[(17, 39), (72, 91)]\n",
      "[(32, 54), (58, 75), (88, 108), (118, 140), (147, 169), (189, 211), (224, 243), (253, 275), (311, 333), (379, 401)]\n",
      "[(15, 33), (38, 57), (72, 94)]\n",
      "[(2, 19), (24, 46), (53, 70), (80, 102)]\n",
      "[(30, 52), (88, 110)]\n",
      "[(12, 34), (73, 95)]\n",
      "[(7, 26), (56, 78), (85, 102), (112, 134)]\n",
      "[(24, 46), (75, 97)]\n",
      "[(7, 29), (59, 81)]\n",
      "[(21, 43), (79, 101)]\n",
      "[(7, 29), (65, 87)]\n",
      "[(21, 38), (48, 70)]\n",
      "[(16, 38), (71, 90)]\n",
      "[(5, 24), (57, 79)]\n",
      "[(7, 29), (61, 83)]\n",
      "[(5, 27), (63, 85)]\n",
      "[(16, 38), (69, 91)]\n",
      "[(24, 41), (48, 70), (74, 96)]\n",
      "[(12, 34), (61, 83)]\n",
      "[(7, 29), (64, 86)]\n",
      "[(7, 29), (61, 83)]\n",
      "[(13, 35), (70, 92)]\n",
      "[(238, 260), (280, 299)]\n",
      "[(10, 32)]\n",
      "[(247, 269), (279, 301)]\n",
      "[(5, 22), (34, 53), (57, 79), (91, 113)]\n",
      "[(43, 65), (90, 112)]\n",
      "[(13, 35), (62, 84)]\n",
      "[(33, 55), (62, 84), (94, 116)]\n",
      "[(7, 29), (42, 64), (71, 93), (103, 125)]\n",
      "[(12, 31), (35, 57), (70, 92), (102, 124)]\n",
      "[(7, 29), (65, 87)]\n",
      "[(7, 29), (65, 87)]\n",
      "[(59, 81), (86, 103), (126, 148), (169, 191), (230, 252)]\n",
      "[(45, 67), (94, 116)]\n",
      "[(40, 62), (93, 115)]\n",
      "[(7, 29), (64, 86)]\n",
      "[(2, 24), (50, 68)]\n",
      "[(5, 27), (37, 59), (64, 83), (98, 120)]\n",
      "[(10, 29), (36, 53), (68, 89), (96, 118)]\n",
      "[(48, 70), (75, 97), (110, 129), (139, 161)]\n",
      "[(13, 31), (36, 58), (71, 93)]\n",
      "[(103, 120), (135, 154), (161, 183), (188, 210)]\n",
      "[(20, 39), (46, 68), (83, 105)]\n",
      "[(4, 23), (36, 58), (62, 84), (97, 119)]\n",
      "[(77, 99), (104, 126), (133, 152), (162, 184)]\n",
      "[(32, 54), (66, 88), (93, 112)]\n",
      "[(7, 29), (39, 61), (74, 96), (130, 152), (157, 179), (184, 206)]\n",
      "[(247, 269), (284, 306)]\n",
      "[(235, 257), (267, 289)]\n",
      "[(296, 318), (328, 350)]\n",
      "[(29, 51), (56, 78)]\n",
      "[(107, 129), (139, 158)]\n",
      "[(228, 250), (270, 292)]\n",
      "[(131, 153), (168, 185)]\n",
      "[(13, 35), (50, 69)]\n",
      "[(217, 235), (245, 267)]\n",
      "[(7, 29), (52, 74), (87, 109)]\n",
      "[(25, 47), (68, 87), (92, 114)]\n",
      "[(7, 29), (60, 79)]\n",
      "[(7, 25), (30, 52), (65, 87)]\n",
      "[(16, 38), (73, 95)]\n",
      "[(21, 39), (49, 71), (130, 152), (167, 186), (193, 212)]\n",
      "[(26, 48), (53, 75), (96, 118), (133, 155)]\n",
      "[(15, 37), (49, 71), (86, 105), (126, 148)]\n",
      "[(37, 59), (68, 85), (95, 117), (137, 156)]\n",
      "[(13, 35), (199, 221), (228, 246), (256, 278), (299, 321)]\n",
      "[(44, 66), (76, 93), (100, 122)]\n",
      "[(4, 26), (31, 50), (65, 87)]\n",
      "[(15, 34), (41, 60), (80, 102), (133, 155), (195, 217)]\n",
      "[(7, 29), (63, 85)]\n",
      "[(7, 29), (62, 83)]\n",
      "[(12, 31), (195, 217), (224, 246), (261, 278), (298, 315)]\n",
      "[(20, 42), (80, 102)]\n",
      "[(258, 275), (285, 307)]\n",
      "[(45, 67), (98, 120)]\n",
      "[(21, 40), (50, 69), (81, 103), (108, 127), (140, 162), (214, 236)]\n",
      "[(21, 39), (49, 71), (84, 106), (136, 158), (170, 192), (197, 219)]\n",
      "[(20, 42), (49, 71), (75, 97), (110, 132), (147, 169), (176, 198)]\n",
      "[(2, 24), (49, 71)]\n",
      "[(7, 29), (34, 56), (69, 88), (98, 120)]\n",
      "[(55, 74), (81, 103), (113, 132), (151, 168)]\n",
      "[(10, 28), (35, 57), (67, 89)]\n",
      "[(38, 55), (70, 92), (99, 118), (133, 155)]\n",
      "[(12, 34), (44, 63)]\n",
      "[(12, 34), (39, 58), (71, 90), (94, 113), (126, 148)]\n",
      "[(2, 19), (29, 51), (58, 80), (95, 117)]\n",
      "[(12, 31), (41, 63), (70, 92), (97, 116)]\n",
      "[(44, 66), (81, 98), (105, 127)]\n",
      "[(17, 39), (43, 62), (74, 96)]\n",
      "[(7, 29), (64, 85)]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "newq = []\n",
    "cnt = 0\n",
    "for i in q:\n",
    "    try:\n",
    "        t = df.loc[i[\"id\"]]\n",
    "        thm = t[\"TMhelix Ranges\"] \n",
    "        s = r\"TM-(?P<start>\\d+)-(?P<end>\\d+)\"\n",
    "        # print(thm) \n",
    "        res = re.findall(s, thm) \n",
    "        # print(\"2\")\n",
    "        ranges = [] \n",
    "        for j in res:\n",
    "            ranges.append((int(j[0]), int(j[1])))\n",
    "        print(ranges)\n",
    "        i[\"Tmranges\"] = ranges \n",
    "        classes = {}\n",
    "        if \"Non-selective cation\" in t[\"Ion_pendoplasmic_reticulummeability_label\"]:\n",
    "            classes[\"Non-selective cation\"] = 1 \n",
    "        else:\n",
    "            classes[\"Non-selective cation\"] = -1\n",
    "        cnt += 1\n",
    "        if \"Non-selective anion\" in t[\"Ion_pendoplasmic_reticulummeability_label\"]:\n",
    "            classes[\"Non-selective anion\"] = cnt\n",
    "        else:\n",
    "            classes[\"Non-selective anion\"] = cnt\n",
    "        i[\"classes\"] = classes\n",
    "        newq.append(i) \n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/data/tyfei/datasets/ion_channel/test_Archaea1.pkl\", \"wb\") as f:\n",
    "    q = pickle.dump(newq, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': array([1, 2, 3])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import copy \n",
    "import numpy as np \n",
    "a = {\"a\":np.array([1,2,3])}\n",
    "b = {}\n",
    "b[\"a\"] = a[\"a\"].copy()\n",
    "b[\"a\"][2]=1 \n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "import torch \n",
    "# cri = torch.nn.BCEWithLogitsLoss(weight=torch.tensor((0.5, 1))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn((3, 2)) \n",
    "b = torch.tensor(((1, 0), (1, 1), (0, 1)), dtype=torch.float32) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5987)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.functional.binary_cross_entropy_with_logits(a, b, weight=torch.tensor((0.5, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4985,  0.6607],\n",
       "        [-0.3487,  0.1797],\n",
       "        [ 1.5595,  0.8565]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = a[:, None, :].repeat(1, 2, 1)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tyfei/anaconda3/envs/esm3/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import json\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import trainUtils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A():\n",
    "    pass\n",
    "args = A()\n",
    "args.path = \"/home/tyfei/ionChannel/ckptsesm3/testconfig/\" \n",
    "args.devices = [1] \n",
    "args.checkpoint = None\n",
    "args.name = \"ion_test\"\n",
    "args.strategy = \"auto\"\n",
    "# args.path = \"/home/tyfei/ionChannel/ckptsesm3/testconfig/\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = args.path\n",
    "with open(os.path.join(path, \"config.json\"), \"r\") as f:\n",
    "    configs = json.load(f)\n",
    "json_formatted_str = json.dumps(configs, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': {'save': 2,\n",
       "  'epoch': 4,\n",
       "  'batch_size': 1,\n",
       "  'accumulate_grad_batches': 8,\n",
       "  'gradient_clip_val': 1.0,\n",
       "  'seed': 1509},\n",
       " 'augmentation': {'step_points': [4, 3000],\n",
       "  'maskp': [0.3, 0.15],\n",
       "  'maskpc': [0.3, 0.1],\n",
       "  'crop': [0.5, 0.8],\n",
       "  'tracks': {'seq_t': 1.0,\n",
       "   'structure_t': 1.0,\n",
       "   'sasa_t': 1.0,\n",
       "   'second_t': 1.0}},\n",
       " 'dataset': {'type': 'balancedesm3',\n",
       "  'dataset_train_sample': [[10], [10]],\n",
       "  'dataset_val_sample': [[10], [10]],\n",
       "  'seed': 1509,\n",
       "  'tracks': ['seq_t', 'structure_t', 'sasa_t', 'second_t'],\n",
       "  'train_test_ratio': [0.85, 0.15],\n",
       "  'pos': ['/data/tyfei/datasets/ion_channel/test_Archaea1.pkl'],\n",
       "  'neg': ['/data/tyfei/datasets/ion_channel/Bacteria1_test.pkl'],\n",
       "  'test': ['/data/tyfei/datasets/ion_channel/test_Archaea1.pkl'],\n",
       "  'required_labels': ['Non-selective anion', 'Non-selective cation']},\n",
       " 'pretrain_model': {'model': 'esm3',\n",
       "  'unfix_layers': [],\n",
       "  'add_lora': [40, 41, 42, 43, 44, 45, 46, 47],\n",
       "  'rank': [8, 8, 8, 8, 8, 8, 16, 32],\n",
       "  'alpha': [16, 16, 16, 16, 16, 16, 32, 64],\n",
       "  'unfreeze': {'steps': [2500, 2000, 1500, 1000, 500, 300, 100, 50],\n",
       "   'layers': [['lora', '40'],\n",
       "    ['lora', '41'],\n",
       "    ['lora', '42'],\n",
       "    ['lora', '43'],\n",
       "    ['lora', '44'],\n",
       "    ['lora', '45'],\n",
       "    ['lora', '46'],\n",
       "    ['lora', '47']]}},\n",
       " 'model': {'type': 'esm3',\n",
       "  'lambda_adapt': True,\n",
       "  'weight_decay': 0.005,\n",
       "  'strategy': {'warmup': 10000, 'check': 500},\n",
       "  'lambda_step': 1.5,\n",
       "  'lambda_ini': 0.1,\n",
       "  'lambda_thres': [0.9, 0.95],\n",
       "  'max_lambda': 6,\n",
       "  'dropout': 0.2,\n",
       "  'lr': 0.0005,\n",
       "  'clf': 'linear',\n",
       "  'clf_params': {'take_embed': 'first', 'p0': 0.2, 'output_dim': 3},\n",
       "  'dis': 'linear',\n",
       "  'additional_label_weights': [0.1, 0.1],\n",
       "  'dis_params': {'take_embed': 'first', 'p0': 0.2}}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrain_model = trainUtils.loadPretrainModel(configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformer.blocks.40.attn.layernorm_qkv.1.lora.A\n",
      "transformer.blocks.40.attn.layernorm_qkv.1.lora.B\n",
      "transformer.blocks.40.attn.out_proj.lora.A\n",
      "transformer.blocks.40.attn.out_proj.lora.B\n",
      "transformer.blocks.40.ffn.1.lora.A\n",
      "transformer.blocks.40.ffn.1.lora.B\n",
      "transformer.blocks.40.ffn.3.lora.A\n",
      "transformer.blocks.40.ffn.3.lora.B\n",
      "transformer.blocks.41.attn.layernorm_qkv.1.lora.A\n",
      "transformer.blocks.41.attn.layernorm_qkv.1.lora.B\n",
      "transformer.blocks.41.attn.out_proj.lora.A\n",
      "transformer.blocks.41.attn.out_proj.lora.B\n",
      "transformer.blocks.41.ffn.1.lora.A\n",
      "transformer.blocks.41.ffn.1.lora.B\n",
      "transformer.blocks.41.ffn.3.lora.A\n",
      "transformer.blocks.41.ffn.3.lora.B\n",
      "transformer.blocks.42.attn.layernorm_qkv.1.lora.A\n",
      "transformer.blocks.42.attn.layernorm_qkv.1.lora.B\n",
      "transformer.blocks.42.attn.out_proj.lora.A\n",
      "transformer.blocks.42.attn.out_proj.lora.B\n",
      "transformer.blocks.42.ffn.1.lora.A\n",
      "transformer.blocks.42.ffn.1.lora.B\n",
      "transformer.blocks.42.ffn.3.lora.A\n",
      "transformer.blocks.42.ffn.3.lora.B\n",
      "transformer.blocks.43.attn.layernorm_qkv.1.lora.A\n",
      "transformer.blocks.43.attn.layernorm_qkv.1.lora.B\n",
      "transformer.blocks.43.attn.out_proj.lora.A\n",
      "transformer.blocks.43.attn.out_proj.lora.B\n",
      "transformer.blocks.43.ffn.1.lora.A\n",
      "transformer.blocks.43.ffn.1.lora.B\n",
      "transformer.blocks.43.ffn.3.lora.A\n",
      "transformer.blocks.43.ffn.3.lora.B\n",
      "transformer.blocks.44.attn.layernorm_qkv.1.lora.A\n",
      "transformer.blocks.44.attn.layernorm_qkv.1.lora.B\n",
      "transformer.blocks.44.attn.out_proj.lora.A\n",
      "transformer.blocks.44.attn.out_proj.lora.B\n",
      "transformer.blocks.44.ffn.1.lora.A\n",
      "transformer.blocks.44.ffn.1.lora.B\n",
      "transformer.blocks.44.ffn.3.lora.A\n",
      "transformer.blocks.44.ffn.3.lora.B\n",
      "transformer.blocks.45.attn.layernorm_qkv.1.lora.A\n",
      "transformer.blocks.45.attn.layernorm_qkv.1.lora.B\n",
      "transformer.blocks.45.attn.out_proj.lora.A\n",
      "transformer.blocks.45.attn.out_proj.lora.B\n",
      "transformer.blocks.45.ffn.1.lora.A\n",
      "transformer.blocks.45.ffn.1.lora.B\n",
      "transformer.blocks.45.ffn.3.lora.A\n",
      "transformer.blocks.45.ffn.3.lora.B\n",
      "transformer.blocks.46.attn.layernorm_qkv.1.lora.A\n",
      "transformer.blocks.46.attn.layernorm_qkv.1.lora.B\n",
      "transformer.blocks.46.attn.out_proj.lora.A\n",
      "transformer.blocks.46.attn.out_proj.lora.B\n",
      "transformer.blocks.46.ffn.1.lora.A\n",
      "transformer.blocks.46.ffn.1.lora.B\n",
      "transformer.blocks.46.ffn.3.lora.A\n",
      "transformer.blocks.46.ffn.3.lora.B\n",
      "transformer.blocks.47.attn.layernorm_qkv.1.lora.A\n",
      "transformer.blocks.47.attn.layernorm_qkv.1.lora.B\n",
      "transformer.blocks.47.attn.out_proj.lora.A\n",
      "transformer.blocks.47.attn.out_proj.lora.B\n",
      "transformer.blocks.47.ffn.1.lora.A\n",
      "transformer.blocks.47.ffn.1.lora.B\n",
      "transformer.blocks.47.ffn.3.lora.A\n",
      "transformer.blocks.47.ffn.3.lora.B\n"
     ]
    }
   ],
   "source": [
    "for i, j in pretrain_model.named_parameters():\n",
    "    if j.requires_grad:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/IPython/core/formatters.py:711\u001b[0m, in \u001b[0;36mPlainTextFormatter.__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    704\u001b[0m stream \u001b[38;5;241m=\u001b[39m StringIO()\n\u001b[1;32m    705\u001b[0m printer \u001b[38;5;241m=\u001b[39m pretty\u001b[38;5;241m.\u001b[39mRepresentationPrinter(stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_width, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnewline,\n\u001b[1;32m    707\u001b[0m     max_seq_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_seq_length,\n\u001b[1;32m    708\u001b[0m     singleton_pprinters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msingleton_printers,\n\u001b[1;32m    709\u001b[0m     type_pprinters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtype_printers,\n\u001b[1;32m    710\u001b[0m     deferred_pprinters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeferred_printers)\n\u001b[0;32m--> 711\u001b[0m \u001b[43mprinter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpretty\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    712\u001b[0m printer\u001b[38;5;241m.\u001b[39mflush()\n\u001b[1;32m    713\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m stream\u001b[38;5;241m.\u001b[39mgetvalue()\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/IPython/lib/pretty.py:419\u001b[0m, in \u001b[0;36mRepresentationPrinter.pretty\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    408\u001b[0m                         \u001b[38;5;28;01mreturn\u001b[39;00m meth(obj, \u001b[38;5;28mself\u001b[39m, cycle)\n\u001b[1;32m    409\u001b[0m                 \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    410\u001b[0m                     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mobject\u001b[39m\n\u001b[1;32m    411\u001b[0m                     \u001b[38;5;66;03m# check if cls defines __repr__\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    417\u001b[0m                     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(_safe_getattr(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__repr__\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    418\u001b[0m                 ):\n\u001b[0;32m--> 419\u001b[0m                     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_repr_pprint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcycle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    421\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _default_pprint(obj, \u001b[38;5;28mself\u001b[39m, cycle)\n\u001b[1;32m    422\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/IPython/lib/pretty.py:787\u001b[0m, in \u001b[0;36m_repr_pprint\u001b[0;34m(obj, p, cycle)\u001b[0m\n\u001b[1;32m    785\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"A pprint that just redirects to the normal repr function.\"\"\"\u001b[39;00m\n\u001b[1;32m    786\u001b[0m \u001b[38;5;66;03m# Find newlines and replace them with p.break_()\u001b[39;00m\n\u001b[0;32m--> 787\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mrepr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    788\u001b[0m lines \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39msplitlines()\n\u001b[1;32m    789\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m p\u001b[38;5;241m.\u001b[39mgroup():\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/torch/nn/modules/module.py:2526\u001b[0m, in \u001b[0;36mModule.__repr__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2524\u001b[0m child_lines \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m   2525\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m-> 2526\u001b[0m     mod_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mrepr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2527\u001b[0m     mod_str \u001b[38;5;241m=\u001b[39m _addindent(mod_str, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m   2528\u001b[0m     child_lines\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m key \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m): \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m mod_str)\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/torch/nn/modules/module.py:2526\u001b[0m, in \u001b[0;36mModule.__repr__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2524\u001b[0m child_lines \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m   2525\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m-> 2526\u001b[0m     mod_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mrepr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2527\u001b[0m     mod_str \u001b[38;5;241m=\u001b[39m _addindent(mod_str, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m   2528\u001b[0m     child_lines\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m key \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m): \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m mod_str)\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/torch/nn/modules/module.py:2520\u001b[0m, in \u001b[0;36mModule.__repr__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2517\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__repr__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   2518\u001b[0m     \u001b[38;5;66;03m# We treat the extra repr like the sub-module, one item per line\u001b[39;00m\n\u001b[1;32m   2519\u001b[0m     extra_lines \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m-> 2520\u001b[0m     extra_repr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextra_repr\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2521\u001b[0m     \u001b[38;5;66;03m# empty string will be split into list ['']\u001b[39;00m\n\u001b[1;32m   2522\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m extra_repr:\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/torch/nn/modules/sparse.py:407\u001b[0m, in \u001b[0;36mEmbeddingBag.extra_repr\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_idx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    406\u001b[0m     s \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, padding_idx=\u001b[39m\u001b[38;5;132;01m{padding_idx}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 407\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m s\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{k: \u001b[38;5;28mrepr\u001b[39m(v) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m\u001b[38;5;241m.\u001b[39mitems()})\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/torch/nn/modules/sparse.py:407\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_idx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    406\u001b[0m     s \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, padding_idx=\u001b[39m\u001b[38;5;132;01m{padding_idx}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 407\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m s\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{k: \u001b[38;5;28;43mrepr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m\u001b[38;5;241m.\u001b[39mitems()})\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/torch/nn/parameter.py:64\u001b[0m, in \u001b[0;36mParameter.__repr__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__repr__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 64\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mParameter containing:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__repr__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/torch/_tensor.py:464\u001b[0m, in \u001b[0;36mTensor.__repr__\u001b[0;34m(self, tensor_contents)\u001b[0m\n\u001b[1;32m    460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    461\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__repr__\u001b[39m, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, tensor_contents\u001b[38;5;241m=\u001b[39mtensor_contents\n\u001b[1;32m    462\u001b[0m     )\n\u001b[1;32m    463\u001b[0m \u001b[38;5;66;03m# All strings are unicode in Python 3.\u001b[39;00m\n\u001b[0;32m--> 464\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tensor_str\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_str\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_contents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_contents\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/torch/_tensor_str.py:697\u001b[0m, in \u001b[0;36m_str\u001b[0;34m(self, tensor_contents)\u001b[0m\n\u001b[1;32m    695\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad(), torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39m_python_dispatch\u001b[38;5;241m.\u001b[39m_disable_current_modes():\n\u001b[1;32m    696\u001b[0m     guard \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_DisableFuncTorch()\n\u001b[0;32m--> 697\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_str_intern\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_contents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_contents\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/torch/_tensor_str.py:617\u001b[0m, in \u001b[0;36m_str_intern\u001b[0;34m(inp, tensor_contents)\u001b[0m\n\u001b[1;32m    615\u001b[0m                     tensor_str \u001b[38;5;241m=\u001b[39m _tensor_str(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_dense(), indent)\n\u001b[1;32m    616\u001b[0m                 \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 617\u001b[0m                     tensor_str \u001b[38;5;241m=\u001b[39m \u001b[43m_tensor_str\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    619\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayout \u001b[38;5;241m!=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstrided:\n\u001b[1;32m    620\u001b[0m     suffixes\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayout=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayout))\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/torch/_tensor_str.py:349\u001b[0m, in \u001b[0;36m_tensor_str\u001b[0;34m(self, indent)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _tensor_str_with_formatter(\n\u001b[1;32m    346\u001b[0m         \u001b[38;5;28mself\u001b[39m, indent, summarize, real_formatter, imag_formatter\n\u001b[1;32m    347\u001b[0m     )\n\u001b[1;32m    348\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 349\u001b[0m     formatter \u001b[38;5;241m=\u001b[39m _Formatter(\u001b[43mget_summarized_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m summarize \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    350\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _tensor_str_with_formatter(\u001b[38;5;28mself\u001b[39m, indent, summarize, formatter)\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/torch/_tensor_str.py:385\u001b[0m, in \u001b[0;36mget_summarized_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m     start \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, PRINT_OPTS\u001b[38;5;241m.\u001b[39medgeitems)]\n\u001b[1;32m    384\u001b[0m     end \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m PRINT_OPTS\u001b[38;5;241m.\u001b[39medgeitems, \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m))]\n\u001b[0;32m--> 385\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mstack([get_summarized_data(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m (start \u001b[38;5;241m+\u001b[39m end)])\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    387\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mstack([get_summarized_data(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/torch/_tensor_str.py:385\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    383\u001b[0m     start \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, PRINT_OPTS\u001b[38;5;241m.\u001b[39medgeitems)]\n\u001b[1;32m    384\u001b[0m     end \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m PRINT_OPTS\u001b[38;5;241m.\u001b[39medgeitems, \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m))]\n\u001b[0;32m--> 385\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mstack([\u001b[43mget_summarized_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m (start \u001b[38;5;241m+\u001b[39m end)])\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    387\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mstack([get_summarized_data(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/torch/_tensor_str.py:375\u001b[0m, in \u001b[0;36mget_summarized_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m PRINT_OPTS\u001b[38;5;241m.\u001b[39medgeitems:\n\u001b[0;32m--> 375\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    376\u001b[0m \u001b[43m            \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mPRINT_OPTS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medgeitems\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mPRINT_OPTS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medgeitems\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    378\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    379\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "pretrain_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = trainUtils.buildModel(configs, pretrain_model, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = trainUtils.loadDataset(configs)\n",
    "# ds.tra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 1509\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build lambda update callback\n",
      "build data augmentation callback\n",
      "build pretrain model unfreeze callback\n"
     ]
    }
   ],
   "source": [
    "trainer = trainUtils.buildTrainer(configs, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get train loader\n"
     ]
    }
   ],
   "source": [
    "dl = ds.train_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step dataset\n"
     ]
    }
   ],
   "source": [
    "dl.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1, 76, -1])\n",
      "tensor([ 1, 62, -1])\n",
      "tensor([ 1, 21, -1])\n",
      "tensor([  1, 188,  -1])\n",
      "tensor([  1, 251,  -1])\n",
      "tensor([ 1, 27, -1])\n",
      "tensor([ 1, 25, -1])\n",
      "tensor([ 1, 19, -1])\n",
      "tensor([  1, 136,  -1])\n",
      "tensor([ 1, 49, -1])\n",
      "tensor([ 1, 35, -1])\n",
      "tensor([ 1, 60, -1])\n",
      "tensor([ 1, 94, -1])\n",
      "tensor([  1, 260,  -1])\n",
      "tensor([  1, 142,  -1])\n",
      "tensor([  1, 164,  -1])\n",
      "tensor([ 1, 30, -1])\n",
      "tensor([  1, 117,  -1])\n",
      "tensor([  1, 190,  -1])\n",
      "tensor([  1, 172,  -1])\n",
      "tensor([  1, 170,  -1])\n",
      "tensor([  1, 119,  -1])\n",
      "tensor([ 1, 18, -1])\n",
      "tensor([  1, 171,  -1])\n",
      "tensor([  1, 189,  -1])\n",
      "tensor([  1, 267,  -1])\n",
      "tensor([  1, 218,  -1])\n",
      "tensor([ 1, 38, -1])\n",
      "tensor([  1, 152,  -1])\n",
      "tensor([ 1, 90, -1])\n",
      "tensor([  1, 159,  -1])\n",
      "tensor([ 1, 37, -1])\n",
      "tensor([ 1, 72, -1])\n",
      "tensor([ 1, 53, -1])\n",
      "tensor([  1, 183,  -1])\n",
      "tensor([ 1,  5, -1])\n",
      "tensor([  1, 208,  -1])\n",
      "tensor([  1, 247,  -1])\n",
      "tensor([ 1, 39, -1])\n",
      "tensor([  1, 262,  -1])\n",
      "tensor([  1, 268,  -1])\n",
      "tensor([  1, 173,  -1])\n",
      "tensor([ 1, 59, -1])\n",
      "tensor([ 1, 64, -1])\n",
      "tensor([  1, 246,  -1])\n",
      "tensor([  1, 259,  -1])\n",
      "tensor([  1, 252,  -1])\n",
      "tensor([ 1, 50, -1])\n",
      "tensor([ 1, 67, -1])\n",
      "tensor([  1, 220,  -1])\n",
      "tensor([  1, 158,  -1])\n",
      "tensor([ 1, 24, -1])\n",
      "tensor([  1, 211,  -1])\n",
      "tensor([ 1,  4, -1])\n",
      "tensor([  1, 154,  -1])\n",
      "tensor([  1, 169,  -1])\n",
      "tensor([  1, 186,  -1])\n",
      "tensor([  1, 195,  -1])\n",
      "tensor([  1, 102,  -1])\n",
      "tensor([  1, 219,  -1])\n",
      "tensor([ 1, 31, -1])\n",
      "tensor([ 1, 40, -1])\n",
      "tensor([ 1, 78, -1])\n",
      "tensor([  1, 230,  -1])\n",
      "tensor([ 1, 71, -1])\n",
      "tensor([  1, 139,  -1])\n",
      "tensor([ 1, 17, -1])\n",
      "tensor([ 1,  9, -1])\n",
      "tensor([  1, 202,  -1])\n",
      "tensor([  1, 201,  -1])\n",
      "tensor([  1, 105,   1])\n",
      "tensor([  1, 249,   1])\n",
      "tensor([ 1, 58, -1])\n",
      "tensor([  1, 179,  -1])\n",
      "tensor([  1, 107,  -1])\n",
      "tensor([ 1, 61, -1])\n",
      "tensor([  1, 101,  -1])\n",
      "tensor([  1, 130,  -1])\n",
      "tensor([  1, 264,  -1])\n",
      "tensor([  1, 213,  -1])\n",
      "tensor([  1, 131,  -1])\n",
      "tensor([  1, 231,  -1])\n",
      "tensor([  1, 243,  -1])\n",
      "tensor([  1, 106,  -1])\n",
      "tensor([  1, 199,  -1])\n",
      "tensor([  1, 212,  -1])\n",
      "tensor([ 1, 36, -1])\n",
      "tensor([  1, 223,  -1])\n",
      "tensor([  1, 153,   1])\n",
      "tensor([ 1, 95, -1])\n",
      "tensor([  1, 128,  -1])\n",
      "tensor([  1, 113,  -1])\n",
      "tensor([  1, 244,  -1])\n",
      "tensor([  1, 138,  -1])\n",
      "tensor([  1, 175,  -1])\n",
      "tensor([  1, 116,  -1])\n",
      "tensor([ 1,  3, -1])\n",
      "tensor([ 1, 66, -1])\n",
      "tensor([  1, 109,  -1])\n",
      "tensor([  1, 150,  -1])\n"
     ]
    }
   ],
   "source": [
    "res = []\n",
    "for i, j in enumerate(dl):\n",
    "    # print(j)\n",
    "    if (j[1][0][0] == 1).item():\n",
    "        print(j[1][0])\n",
    "        res.append(j[1][0][1].item())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 4]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1,2,3]\n",
    "a[2]+=1 \n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  3,   4,   5,   9,  17,  18,  19,  21,  24,  25,  27,  30,  31,\n",
       "        35,  36,  37,  38,  39,  40,  49,  50,  53,  58,  59,  60,  61,\n",
       "        62,  64,  66,  67,  71,  72,  76,  78,  90,  94,  95, 101, 102,\n",
       "       105, 106, 107, 109, 113, 116, 117, 119, 128, 130, 131, 136, 138,\n",
       "       139, 142, 150, 152, 153, 154, 158, 159, 164, 169, 170, 171, 172,\n",
       "       173, 175, 179, 183, 186, 188, 189, 190, 195, 199, 201, 202, 208,\n",
       "       211, 212, 213, 218, 219, 220, 223, 230, 231, 243, 244, 246, 247,\n",
       "       249, 251, 252, 259, 260, 262, 264, 267, 268])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1,   6,   8,  10,  14,  15,  16,  20,  26,  28,  32,  33,  34,\n",
       "        41,  43,  44,  46,  48,  51,  54,  56,  63,  69,  70,  73,  75,\n",
       "        77,  79,  80,  81,  83,  85,  86,  87,  89,  91,  97,  98,  99,\n",
       "       103, 108, 110, 111, 114, 115, 118, 121, 123, 132, 134, 135, 141,\n",
       "       143, 146, 148, 151, 155, 156, 157, 161, 162, 167, 174, 176, 181,\n",
       "       182, 185, 191, 192, 197, 198, 200, 204, 206, 210, 214, 216, 221,\n",
       "       222, 224, 227, 228, 229, 233, 235, 236, 237, 238, 239, 240, 242,\n",
       "       245, 256, 258, 261, 265, 266, 269, 270, 273])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "199"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7789])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.randn((4))\n",
    "t.dim()\n",
    "t[[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0.1000, 0.1000])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.additional_label_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 4090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "/home/tyfei/anaconda3/envs/esm3/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/tyfei/ionChannel/ckptsesm3/testconfig exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting training and freeze modules  ['esm_model.transformer.blocks.40.attn.layernorm_qkv.1.lora', 'esm_model.transformer.blocks.40.attn.out_proj.lora', 'esm_model.transformer.blocks.40.ffn.1.lora', 'esm_model.transformer.blocks.40.ffn.3.lora', 'esm_model.transformer.blocks.41.attn.layernorm_qkv.1.lora', 'esm_model.transformer.blocks.41.attn.out_proj.lora', 'esm_model.transformer.blocks.41.ffn.1.lora', 'esm_model.transformer.blocks.41.ffn.3.lora', 'esm_model.transformer.blocks.42.attn.layernorm_qkv.1.lora', 'esm_model.transformer.blocks.42.attn.out_proj.lora', 'esm_model.transformer.blocks.42.ffn.1.lora', 'esm_model.transformer.blocks.42.ffn.3.lora', 'esm_model.transformer.blocks.43.attn.layernorm_qkv.1.lora', 'esm_model.transformer.blocks.43.attn.out_proj.lora', 'esm_model.transformer.blocks.43.ffn.1.lora', 'esm_model.transformer.blocks.43.ffn.3.lora', 'esm_model.transformer.blocks.44.attn.layernorm_qkv.1.lora', 'esm_model.transformer.blocks.44.attn.out_proj.lora', 'esm_model.transformer.blocks.44.ffn.1.lora', 'esm_model.transformer.blocks.44.ffn.3.lora', 'esm_model.transformer.blocks.45.attn.layernorm_qkv.1.lora', 'esm_model.transformer.blocks.45.attn.out_proj.lora', 'esm_model.transformer.blocks.45.ffn.1.lora', 'esm_model.transformer.blocks.45.ffn.3.lora', 'esm_model.transformer.blocks.46.attn.layernorm_qkv.1.lora', 'esm_model.transformer.blocks.46.attn.out_proj.lora', 'esm_model.transformer.blocks.46.ffn.1.lora', 'esm_model.transformer.blocks.46.ffn.3.lora', 'esm_model.transformer.blocks.47.attn.layernorm_qkv.1.lora', 'esm_model.transformer.blocks.47.attn.out_proj.lora', 'esm_model.transformer.blocks.47.ffn.1.lora', 'esm_model.transformer.blocks.47.ffn.3.lora']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name         | Type             | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | acc          | BinaryAccuracy   | 0      | train\n",
      "1 | reverse      | GradientReversal | 0      | train\n",
      "2 | esm_model    | ESM3             | 1.4 B  | eval \n",
      "3 | clf          | Linearcls        | 1.5 M  | train\n",
      "4 | dis          | Linearcls        | 1.5 M  | train\n",
      "  | other params | n/a              | 2      | n/a  \n",
      "----------------------------------------------------------\n",
      "3.0 M     Trainable params\n",
      "1.4 B     Non-trainable params\n",
      "1.4 B     Total params\n",
      "5,628.210 Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get training optimizer\n",
      "Sanity Checking: |          | 0/? [00:00<?, ?it/s]get val loader\n",
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/conda-bld/pytorch_1716905979055/work/aten/src/ATen/native/cuda/Loss.cu:95: operator(): block: [0,0,0], thread: [0,0,0] Assertion `target_val >= zero && target_val <= one` failed.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:44\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:579\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    573\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    574\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[1;32m    575\u001b[0m     ckpt_path,\n\u001b[1;32m    576\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    577\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    578\u001b[0m )\n\u001b[0;32m--> 579\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    581\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:986\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    983\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    984\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m    985\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m--> 986\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    988\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    989\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m    990\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1028\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1027\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m isolate_rng():\n\u001b[0;32m-> 1028\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_sanity_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1029\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1057\u001b[0m, in \u001b[0;36mTrainer._run_sanity_check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1056\u001b[0m \u001b[38;5;66;03m# run eval step\u001b[39;00m\n\u001b[0;32m-> 1057\u001b[0m \u001b[43mval_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1059\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_callback_hooks(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_sanity_check_end\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/pytorch_lightning/loops/utilities.py:182\u001b[0m, in \u001b[0;36m_no_grad_context.<locals>._decorator\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context_manager():\n\u001b[0;32m--> 182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/pytorch_lightning/loops/evaluation_loop.py:135\u001b[0m, in \u001b[0;36m_EvaluationLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;66;03m# run step hooks\u001b[39;00m\n\u001b[0;32m--> 135\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluation_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;66;03m# this needs to wrap the `*_step` call too (not just `next`) for `dataloader_iter` support\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/pytorch_lightning/loops/evaluation_loop.py:396\u001b[0m, in \u001b[0;36m_EvaluationLoop._evaluation_step\u001b[0;34m(self, batch, batch_idx, dataloader_idx, dataloader_iter)\u001b[0m\n\u001b[1;32m    391\u001b[0m step_args \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_step_args_from_hook_kwargs(hook_kwargs, hook_name)\n\u001b[1;32m    393\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m using_dataloader_iter\n\u001b[1;32m    394\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m (dataloader_iter,)\n\u001b[1;32m    395\u001b[0m )\n\u001b[0;32m--> 396\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_strategy_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mstep_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mincrement_processed()\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:311\u001b[0m, in \u001b[0;36m_call_strategy_hook\u001b[0;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 311\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py:411\u001b[0m, in \u001b[0;36mStrategy.validation_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    410\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_redirection(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation_step\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 411\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlightning_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidation_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ionChannel/models.py:382\u001b[0m, in \u001b[0;36mIonBaseclf.validation_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m    380\u001b[0m loss, loss1, loss2, y_pre, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_common_training_step(batch)\n\u001b[0;32m--> 382\u001b[0m acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macc\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pre\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;66;03m# self.log_dict(\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;66;03m#     {\"predict loss\": loss1.item(), \"adversial loss\": loss2.item(), \"acc\": acc},\u001b[39;00m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;66;03m#     logger=True,\u001b[39;00m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;66;03m# )\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/torchmetrics/metric.py:311\u001b[0m, in \u001b[0;36mMetric.forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 311\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_reduce_state_update\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_cache\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/torchmetrics/metric.py:380\u001b[0m, in \u001b[0;36mMetric._forward_reduce_state_update\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;66;03m# calculate batch state and compute batch value\u001b[39;00m\n\u001b[0;32m--> 380\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    381\u001b[0m batch_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute()\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/torchmetrics/metric.py:492\u001b[0m, in \u001b[0;36mMetric._wrap_update.<locals>.wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    485\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    486\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered different devices in metric calculation (see stacktrace for details).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    487\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m This could be due to the metric class not being on the same device as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m device corresponds to the device of the input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    491\u001b[0m             ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m--> 492\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_on_cpu:\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/torchmetrics/metric.py:482\u001b[0m, in \u001b[0;36mMetric._wrap_update.<locals>.wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 482\u001b[0m     \u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/torchmetrics/classification/stat_scores.py:187\u001b[0m, in \u001b[0;36mBinaryStatScores.update\u001b[0;34m(self, preds, target)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidate_args:\n\u001b[0;32m--> 187\u001b[0m     \u001b[43m_binary_stat_scores_tensor_validation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmultidim_average\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    188\u001b[0m preds, target \u001b[38;5;241m=\u001b[39m _binary_stat_scores_format(preds, target, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mthreshold, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mignore_index)\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/torchmetrics/functional/classification/stat_scores.py:70\u001b[0m, in \u001b[0;36m_binary_stat_scores_tensor_validation\u001b[0;34m(preds, target, multidim_average, ignore_index)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# Check that target only contains [0,1] values or value in ignore_index\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m unique_values \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ignore_index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/torch/_jit_internal.py:497\u001b[0m, in \u001b[0;36mboolean_dispatch.<locals>.fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    496\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 497\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mif_false\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/torch/_jit_internal.py:497\u001b[0m, in \u001b[0;36mboolean_dispatch.<locals>.fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    496\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 497\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mif_false\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/torch/functional.py:996\u001b[0m, in \u001b[0;36m_return_output\u001b[0;34m(input, sorted, return_inverse, return_counts, dim)\u001b[0m\n\u001b[1;32m    994\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unique_impl(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28msorted\u001b[39m, return_inverse, return_counts, dim)\n\u001b[0;32m--> 996\u001b[0m output, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43m_unique_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43msorted\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_inverse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_counts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    997\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/torch/functional.py:910\u001b[0m, in \u001b[0;36m_unique_impl\u001b[0;34m(input, sorted, return_inverse, return_counts, dim)\u001b[0m\n\u001b[1;32m    909\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 910\u001b[0m     output, inverse_indices, counts \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_unique2\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    911\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    912\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43msorted\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43msorted\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    913\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_inverse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_inverse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    914\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_counts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_counts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    915\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output, inverse_indices, counts\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:543\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[1;32m    542\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 543\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    544\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:60\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[1;32m     59\u001b[0m     _interrupt(trainer, exception)\n\u001b[0;32m---> 60\u001b[0m     \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_teardown\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;66;03m# teardown might access the stage so we reset it after\u001b[39;00m\n\u001b[1;32m     62\u001b[0m     trainer\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstage \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1009\u001b[0m, in \u001b[0;36mTrainer._teardown\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_teardown\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1007\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"This is the Trainer's internal teardown, unrelated to the `teardown` hooks in LightningModule and Callback;\u001b[39;00m\n\u001b[1;32m   1008\u001b[0m \u001b[38;5;124;03m    those are handled by :meth:`_call_teardown_hook`.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1009\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mteardown\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1010\u001b[0m     loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_active_loop\n\u001b[1;32m   1011\u001b[0m     \u001b[38;5;66;03m# loop should never be `None` here but it can because we don't know the trainer stage with `ddp_spawn`\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py:535\u001b[0m, in \u001b[0;36mStrategy.teardown\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    533\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    534\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: moving model to CPU\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 535\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlightning_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprecision_plugin\u001b[38;5;241m.\u001b[39mteardown()\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/lightning_fabric/utilities/device_dtype_mixin.py:82\u001b[0m, in \u001b[0;36m_DeviceDtypeModuleMixin.cpu\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"See :meth:`torch.nn.Module.cpu`.\"\"\"\u001b[39;00m\n\u001b[1;32m     81\u001b[0m _update_properties(\u001b[38;5;28mself\u001b[39m, device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m---> 82\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/torch/nn/modules/module.py:964\u001b[0m, in \u001b[0;36mModule.cpu\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    955\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcpu\u001b[39m(\u001b[38;5;28mself\u001b[39m: T) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m    956\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Move all model parameters and buffers to the CPU.\u001b[39;00m\n\u001b[1;32m    957\u001b[0m \n\u001b[1;32m    958\u001b[0m \u001b[38;5;124;03m    .. note::\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    962\u001b[0m \u001b[38;5;124;03m        Module: self\u001b[39;00m\n\u001b[1;32m    963\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 964\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/torch/nn/modules/module.py:779\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    778\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 779\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    781\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    782\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    783\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    790\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/torchmetrics/metric.py:822\u001b[0m, in \u001b[0;36mMetric._apply\u001b[0;34m(self, fn, exclude_state)\u001b[0m\n\u001b[1;32m    819\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    821\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, Tensor):\n\u001b[0;32m--> 822\u001b[0m     this\u001b[38;5;241m.\u001b[39m_defaults[key] \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    823\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, Sequence):\n\u001b[1;32m    824\u001b[0m     this\u001b[38;5;241m.\u001b[39m_defaults[key] \u001b[38;5;241m=\u001b[39m [fn(v) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m value]\n",
      "File \u001b[0;32m~/anaconda3/envs/esm3/lib/python3.10/site-packages/torch/nn/modules/module.py:964\u001b[0m, in \u001b[0;36mModule.cpu.<locals>.<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    955\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcpu\u001b[39m(\u001b[38;5;28mself\u001b[39m: T) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m    956\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Move all model parameters and buffers to the CPU.\u001b[39;00m\n\u001b[1;32m    957\u001b[0m \n\u001b[1;32m    958\u001b[0m \u001b[38;5;124;03m    .. note::\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    962\u001b[0m \u001b[38;5;124;03m        Module: self\u001b[39;00m\n\u001b[1;32m    963\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 964\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply(\u001b[38;5;28;01mlambda\u001b[39;00m t: \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "esm3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
